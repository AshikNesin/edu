{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "profile.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSNqSWrZwp0oxBD3kkHq7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/lightning/performance/profile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNWiZEZDEDZZ"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6DYWHO6-TQu"
      },
      "source": [
        "# Profiling PyTorch Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K51AkIVornG"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb pytorch_lightning torch_tb_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6-iYDjooSvC"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torch.profiler import tensorboard_trace_handler\n",
        "import wandb\n",
        "\n",
        "# drop slow mirror from list of MNIST mirrors\n",
        "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
        "                                      if not mirror.startswith(\"http://yann.lecun.com\")]\n",
        "                                      \n",
        "# load tensorboard extension for Colab                                      \n",
        "%load_ext tensorboard\n",
        "\n",
        "# login to W&B\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhMGyoUFEu3S"
      },
      "source": [
        "# CNN Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRVCcrbzohY3"
      },
      "source": [
        "class Net(pl.LightningModule):\n",
        "  \"\"\"Very simple LeNet-style DNN, plus DropOut.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, idx):\n",
        "      inputs, labels = batch\n",
        "      outputs = model(inputs)\n",
        "      loss =  F.nll_loss(outputs, labels)\n",
        "\n",
        "      return {\"loss\": loss}\n",
        "      \n",
        "    def configure_optimizers(self):\n",
        "      return optim.Adadelta(self.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "class TorchTensorboardProfilerCallback(pl.Callback):\n",
        "  \"\"\"Quick-and-dirty Callback for invoking TensorboardProfiler during training.\n",
        "  \n",
        "  For greater robustness, extend the pl.profiler.profilers.BaseProfiler, see\n",
        "  https://pytorch-lightning.readthedocs.io/en/stable/advanced/profiler.html\"\"\"\n",
        "\n",
        "  def __init__(self, profiler):\n",
        "    super().__init__()\n",
        "    self.profiler = profiler \n",
        "    self.dir = dir\n",
        "\n",
        "  def on_train_batch_end(self, trainer, pl_module, outputs, *args, **kwargs):\n",
        "    self.profiler.step()\n",
        "    pl_module.log_dict(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y08oTYDvE05c"
      },
      "source": [
        "# Run Profiled Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHrkQKXBoUbR"
      },
      "source": [
        "# initial values are defaults, for all except batch_size, which has no default\n",
        "config = {\"batch_size\": 32,\n",
        "          \"num_workers\": 0,\n",
        "          \"pin_memory\": False,\n",
        "          \"precision\": 32,\n",
        "          }\n",
        "\n",
        "with wandb.init(entity=\"wandb\", project=\"profiler\", config=config) as run:\n",
        "\n",
        "    # Set up MNIST data\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "    dataset = datasets.MNIST('../data', train=True, download=True,\n",
        "                        transform=transform)\n",
        "\n",
        "    ## Using a raw DataLoader, rather than LightningDataModule, for greater transparency\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "      dataset,\n",
        "      # Key performance-relevant configuration parameters:\n",
        "      ## batch_size: how many datapoints are passed through the network at once?\n",
        "      batch_size=wandb.config.batch_size,  # larger batch sizes are more efficient, up to memory constraints\n",
        "      ##  num_workers: how many side processes to launch for dataloading (should be >0)\n",
        "      num_workers=wandb.config.num_workers,  # needs to be tuned given model/batch size/compute\n",
        "      ## pin_memory: should a fixed \"pinned\" memory block be allocated on the CPU?\n",
        "      pin_memory=wandb.config.pin_memory,  # should nearly always be True for GPU models, see https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
        "      )\n",
        "    \n",
        "    # Set up model\n",
        "    model = Net()\n",
        "\n",
        "    # Set up profiler\n",
        "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
        "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
        "    schedule =  torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=repeat)\n",
        "    profiler = torch.profiler.profile(schedule=schedule, on_trace_ready=tensorboard_trace_handler(\"wandb/latest-run/tbprofile\"), with_stack=True)\n",
        "\n",
        "    with profiler:\n",
        "        profiler_callback = TorchTensorboardProfilerCallback(profiler)\n",
        "\n",
        "        trainer = pl.Trainer(gpus=1, max_epochs=1,\n",
        "                             logger=pl.loggers.WandbLogger(log_model=True, save_code=True),\n",
        "                             callbacks=[profiler_callback], precision=wandb.config.precision)\n",
        "\n",
        "        trainer.fit(model, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJXwI072E3vT"
      },
      "source": [
        "# View PyTorch Profiler in Tensorboard\n",
        "\n",
        "_NOTE_: if you run into issues here, restart the Colab and try again.\n",
        "If issues persist, you may need to activate third-party cookies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5czxOZEyXpZl"
      },
      "source": [
        "# bash command to silently kill any old instances of tensorboard\n",
        "!ps | grep tensorboard | grep -Eo \"^\\s*[0-9]+\" | xargs kill 2> /dev/null\n",
        "\n",
        "# launch a new tensorboard pointed at the latest run\n",
        "## may take a minute\n",
        "%tensorboard --logdir wandb/latest-run/tbprofile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFHLJ_-X-xeD"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfZtMqj-55D"
      },
      "source": [
        "#### 1. Reading the Profiler \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt7fWTjdKIna"
      },
      "source": [
        "\n",
        "Run training with the default `config`uration\n",
        "and launch TensorBoard using the cell above.\n",
        "This TensorBoard instance contains a complete profiling trace\n",
        "of a few training steps for the network above,\n",
        "which we will use to understand the computations that happen\n",
        "during training and how to speed them up.\n",
        "\n",
        "The \"Overview\" tab appears first.\n",
        "Note the composition of the Execution Pie Chart.\n",
        "Which slice is the largest?\n",
        "\n",
        "At the bottom of the Overview tab,\n",
        "you'll see a \"Performance Recommendation\".\n",
        "It should report a percentage of time spent waiting on the `DataLoader`.\n",
        "A model is considered to be bottle-necked by the `DataLoader`\n",
        "if that step takes up at least 5% of the time.\n",
        "How much time does that step take with the default configuration?\n",
        "\n",
        "In the \"Views\" dropdown,\n",
        "head to the \"Operator\" tab.\n",
        "This tab lists which operations\n",
        "are taking the most time in the network.\n",
        "Review the \"Device Self Time\" pie chart.\n",
        "Which operations are taking the most time:\n",
        "convolutional operations (`conv` appears in the name)\n",
        "or the fully-connected operations (`add` or `mm` in the name)?\n",
        "\n",
        "Compare that to the parameter counts in the model's summary below.\n",
        "Is this counterintuitive?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdgOKk2bMmqo"
      },
      "source": [
        "model.summarize();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVSqdajyQW8C"
      },
      "source": [
        "Lastly, switch to the \"Trace\" tab using the \"Views\" dropdown.\n",
        "It may take up to several minutes for this tab to populate,\n",
        "and understanding the contents requires a deeper knowledge of\n",
        "neural networks and GPU-accelerated computation,\n",
        "so feel free to skip to the next section.\n",
        "\n",
        "The Trace tab shows which operations were running in each thread\n",
        "on the CPU and on the GPU.\n",
        "\n",
        "In the main thread (the one in which the Profiler Steps appear),\n",
        "locate the following steps:\n",
        "1. the loading of data (hint: look for `enumerate` on the CPU, nothing on the GPU)\n",
        "2. the forward pass to calculate the loss (hint: look for simultaneous activity on CPU+GPU,\n",
        "with `aten` in the operation names)\n",
        "3. the backward pass to calculate the gradient of the loss (hint: look for simultaneous activity on CPU+GPU, with `backward` in the operation names).\n",
        "\n",
        "Notice that these are all run sequentially,\n",
        "meaning that between loading one batch\n",
        "and loading the next,\n",
        "the `DataLoader` is effectively idling.\n",
        "\n",
        "See the next section for the solution to this issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIqrgkrSGR1w"
      },
      "source": [
        "#### 2. Critical Improvement: `num_workers>0`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFtSSDGpKHl_"
      },
      "source": [
        "The \"Performance Recommendation\" should include a suggestion to change `num_workers`.\n",
        "\n",
        "While the default value of `0`,\n",
        "which disables multiprocessing for data-loading,\n",
        "is almost always a bad choice,\n",
        "even for models run entirely on the CPU,\n",
        "there's not an alternative that's always better.\n",
        "\n",
        "A decent but rough rule-of-thumb for the number of workers is that it should be\n",
        "equal to the number of processors in the CPU, or perhaps less.\n",
        "\n",
        "Run the cell below to determine the number of processors available\n",
        "(on Colab it's typically 2).\n",
        "Try with this as the value for `num_workers` and observe the effect on total runtime (printed to the command line by `wandb` in the Run Summary;\n",
        "also available on the Run Page, in the Overview section).\n",
        "\n",
        "Then try with half as many (but no less than 1!) and with twice as many.\n",
        "It's common to tune this parameter based on runtime results\n",
        "for individual architectures, datasets, and training algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O71GgyteLCAl"
      },
      "source": [
        "!nproc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR8zPLRYUuxi"
      },
      "source": [
        "Review the \"Overview\" tab in the TensorBoard Profiler again.\n",
        "\n",
        "You should see that the `DataLoader` is no longer\n",
        "the largest slice of the pie chart.\n",
        "\n",
        "Ideally, the GPU kernel operations are the largest slice --\n",
        "indicating that the real meat of the network computation\n",
        "is where the majority of time is spent.\n",
        "This may or may not occur,\n",
        "depending on hardware and implementation details.\n",
        "The next section indicates\n",
        "some additional optimizations that can tip the scales\n",
        "more clearly in the direction of GPU operations.\n",
        "\n",
        "_Note_: if you looked through the \"Trace\" tab\n",
        "for the default configuration,\n",
        "look at it again with `num_workers=2`.\n",
        "\n",
        "What you see may depend on the precise\n",
        "hardware and implementation you are using\n",
        "(which varies across Colab sessions),\n",
        "but in general the `DataLoader` code no longer\n",
        "blocks the forward and backward passes,\n",
        "and so the GPU threads should be more densely filled\n",
        "with operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG2WoPfwRI49"
      },
      "source": [
        "#### 3. Marginal Further Improvements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwFXNsxUrwp"
      },
      "source": [
        "The speedup from introducing `num_workers>0`\n",
        "is often 2x (and can be higher with CPUs with more processors).\n",
        "The following improvements are generally smaller.\n",
        "\n",
        "If you reviewed the \"Trace\" tab in the first exercise,\n",
        "then you may have noticed a number of simultaneous CPU operations\n",
        "matching the GPU operations in the forward and backward passes.\n",
        "These include setup and other computations that must be performed\n",
        "with each operation,\n",
        "but which have constant cost as the size of the actual array computation\n",
        "increases.\n",
        "\n",
        "If we increase the sizes of the tensors in our network,\n",
        "we can spread that cost over a larger operation.\n",
        "This can be done either by increasing the network size\n",
        "or by increasing the `batch_size`.\n",
        "\n",
        "Try with a batch size of `10_000`\n",
        "(or `50_000`, which may crash the instance by consuming too much RAM,\n",
        "especially with `num_workers=0`;\n",
        "if `10_000` also crashes your machine, reduce to `1024`).\n",
        "Do you see a faster runtime?\n",
        "\n",
        "Another easy but small win comes from changing the\n",
        "`pin_memory` parameter of the `DataLoader` to `True`.\n",
        "The details of how this works are out-of-scope for this notebook\n",
        "([see this NVIDIA blogpost for more](https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/)),\n",
        "but effectively this increases CPU RAM cost\n",
        "to decrease the latency for transferring\n",
        "data from CPU to GPU.\n",
        "This is almost always a good trade.\n",
        "\n",
        "Finally,\n",
        "the runtime can be improved by reducing the bit depth or `precision`\n",
        "of the floating point numbers used in the matrix math that makes up our network.\n",
        "The capacity to use varying precision is built into PyTorch\n",
        "and made easy by PyTorch Lightning: just pass `precision=k`\n",
        "to the `Trainer`, for `k` one of `64` (\"double\"; default in Python/NumPy), `32` (\"single\"; default in PyTorch), or `16` (\"half\").\n",
        "\n",
        "Try running your model at half precision.\n",
        "\n",
        "_Note_: this often doesn't have a large direct effect on runtime;\n",
        "instead it allows for larger models and batch sizes to run on fixed hardware.\n",
        "Try re-running a batch size that crashed with the default `precision=32` at `precision=16`. Does this model run faster than others?\n",
        "\n",
        "For more on improving the performance of PyTorch code,\n",
        "including more details on the optimizations above,\n",
        "check out\n",
        "[this excellent talk from NVIDIA's Szymon Migacz](https://www.youtube.com/watch?v=9mS1fIYj1So)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiFtbsQEfJc_"
      },
      "source": [
        "#### Endnote\n",
        "\n",
        "You may have noticed that the losses for networks with larger\n",
        "batch sizes are generally higher than those with lower batch sizes,\n",
        "because the increased batch sizes mean there are fewer gradient updates\n",
        "in an epoch.\n",
        "\n",
        "To take full advantage of the speedup given by a larger batch size,\n",
        "you would also need to scale the learning rate up,\n",
        "(either\n",
        "[linearly or with the square root](https://stackoverflow.com/questions/53033556/how-should-the-learning-rate-change-as-the-batch-size-change/53046624)),\n",
        "this increasing the rate at which the weights change per update.\n",
        "The choice of batch size may have an impact\n",
        "on generalization performance as well,\n",
        "but reports in the literature vary."
      ]
    }
  ]
}