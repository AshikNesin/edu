{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pruning_cnn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FVlqBmx6T_VE",
        "MmaWxnFmUIqh",
        "scMcj2y3UMir",
        "0gDNySgGhXiE"
      ],
      "authorship_tag": "ABX9TyPzxESJWOjgKF82jaJvXWPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/lightning/performance/pruning_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-OIk3rBv_Sk"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ1MKJxHqRNb"
      },
      "source": [
        "# Pruning and Sparsity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVT4qCkhC6gU"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install wandb pytorch_lightning==1.3.2 torchviz\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/wandb/edu/main/\"\n",
        "utils_path = \"lightning/utils.py\"\n",
        "# Download a util file of helper methods for this notebook\n",
        "!curl {repo_url + utils_path} > utils.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew38zmQXEZic"
      },
      "source": [
        "import math\n",
        "\n",
        "# usual DL imports\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "\n",
        "# special import for pruning with Lightning\n",
        "from pytorch_lightning.callbacks import ModelPruning\n",
        "\n",
        "# utilities for PyTorch Lightning and wandb\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WerKfa-DK4Bc"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhJAtK5MpvDP"
      },
      "source": [
        "# Utilities for Tracking and Logging Sparsity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yA_3i01qFTL"
      },
      "source": [
        "_Note_: The methods and classes in this section just handle details of logging\n",
        "pruned networks. These details are subject to change as the `torch.nn.prune`\n",
        "library develops, and are not important to understanding pruning and sparsity in neural networks.\n",
        "This section may be safely skipped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_h9xzp1iUN"
      },
      "source": [
        "class SparsityLogCallback(pl.Callback):\n",
        "  \"\"\"PyTorch Lightning Callback for logging the sparsity of weight tensors in a PyTorch Module.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def on_validation_epoch_end(self, trainer, module):\n",
        "    self.log_sparsities(trainer, module)\n",
        "\n",
        "  def get_sparsities(self, module):\n",
        "    weights = self.get_weights(module)\n",
        "    names = [\".\".join(name.split(\".\")[:-1]) for name, _ in module.named_parameters()\n",
        "             if \"weight\" in name.split(\".\")[-1]]\n",
        "    sparsities = [torch.sum(weight == 0) / weight.numel() for weight in weights]\n",
        "\n",
        "    return {\"sparsity/\" + name: sparsity for name, sparsity in zip(names, sparsities)}\n",
        "\n",
        "  def log_sparsities(self, trainer, module):\n",
        "    sparsities = self.get_sparsities(module)\n",
        "    sparsities[\"sparsity/total\"] = 1 - fraction_nonzero(module)\n",
        "    sparsities[\"global_step\"] = trainer.global_step\n",
        "    trainer.logger.experiment.log(sparsities)\n",
        "\n",
        "\n",
        "@staticmethod\n",
        "def get_weights(module):\n",
        "  weights = [parameter for name, parameter in module.named_parameters()\n",
        "             if \"weight\" in name.split(\".\")[-1]]\n",
        "  masks = [mask for name, mask in module.named_buffers()\n",
        "             if \"weight_mask\" in name.split(\".\")[-1]]\n",
        "  if masks:\n",
        "    with torch.no_grad():\n",
        "      weights = [mask * weight for mask, weight in zip(masks, weights)]\n",
        "\n",
        "  return weights\n",
        "\n",
        "SparsityLogCallback.get_weights = get_weights\n",
        "# patches the FilterLogCallback for compatibility with networks during pruning\n",
        "utils.FilterLogCallback.get_weights = get_weights\n",
        "\n",
        "\n",
        "def count_nonzero(module):\n",
        "  \"\"\"Counts the total number of non-zero parameters in a module.\n",
        "  \n",
        "  For compatibility with networks with active torch.nn.utils.prune methods,\n",
        "  checks for _mask tensors, which are applied during forward passes and so\n",
        "  represent the actual sparsity of the networks.\"\"\"\n",
        "  if module.named_buffers():\n",
        "    masks = {name[:-5]: mask_tensor for name, mask_tensor in module.named_buffers()\n",
        "             if name.endswith(\"_mask\")}\n",
        "  else:\n",
        "    masks = {}\n",
        "\n",
        "  nparams = 0\n",
        "  with torch.no_grad():\n",
        "    for name, tensor in module.named_parameters():\n",
        "      if name[:-5] in masks.keys():\n",
        "        tensor = masks[name[:-5]]\n",
        "      nparams += int(torch.sum(tensor != 0))\n",
        "\n",
        "  return nparams\n",
        "\n",
        "\n",
        "def fraction_nonzero(lit_module):\n",
        "  \"\"\"Gives the fraction of parameters that are non-zero in a module.\"\"\"\n",
        "\n",
        "  return count_nonzero(lit_module) / lit_module.count_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69zZvfIBISuW"
      },
      "source": [
        "# Setup Code: Model, Data, and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB-j1oCsET-t"
      },
      "source": [
        "class FullyConnected(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, in_features, out_features, activation=None, dropout=0.):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(in_features, out_features)\n",
        "    if activation is None:  # defaults to passing inputs unchanged\n",
        "      activation = torch.nn.Identity()\n",
        "    self.activation = activation\n",
        "\n",
        "    if dropout:\n",
        "      self.post_act = torch.nn.Dropout(dropout)\n",
        "    else:\n",
        "      self.post_act = torch.nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.post_act(self.activation(self.linear(x)))\n",
        "    \n",
        "    \n",
        "class Convolution(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size,\n",
        "               activation=None, dropout=0.):\n",
        "    super().__init__()\n",
        "    self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size)\n",
        "    if activation is None:\n",
        "      activation = torch.nn.Identity()  # defaults to passing inputs unchanged\n",
        "    self.activation = activation\n",
        "\n",
        "    if dropout:\n",
        "      self.post_act = torch.nn.Dropout2d(dropout)\n",
        "    else:\n",
        "      self.post_act = torch.nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.post_act(self.activation(self.conv2d(x)))\n",
        "\n",
        "\n",
        "class LitCNN(utils.LoggedImageClassifierModule):\n",
        "  \"\"\"A simple CNN Model, with under-the-hood wandb\n",
        "  and pytorch-lightning features (logging, metrics, etc.).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config, max_images_to_display=32):  # make the model\n",
        "    super().__init__(max_images_to_display=max_images_to_display)\n",
        "\n",
        "    # first, convolutional component\n",
        "    self.conv_layers = torch.nn.Sequential(\n",
        "      # hidden conv layer\n",
        "      Convolution(in_channels=1, kernel_size=config[\"kernel_size\"],\n",
        "                  activation=config[\"activation\"],\n",
        "                  out_channels=config[\"conv.channels\"][0],\n",
        "                  dropout=config[\"conv.dropout\"]),\n",
        "      # hidden conv layer\n",
        "      Convolution(in_channels=config[\"conv.channels\"][0], kernel_size=config[\"kernel_size\"],\n",
        "                  activation=config[\"activation\"],\n",
        "                  out_channels=config[\"conv.channels\"][1],\n",
        "                  dropout=config[\"conv.dropout\"]),\n",
        "      # pooling often follows 2 convs\n",
        "      torch.nn.MaxPool2d(config[\"pool_size\"]),\n",
        "    )\n",
        "\n",
        "    # need a fixed-size input for fully-connected component,\n",
        "    #  so apply a \"re-sizing\" layer, to size set in config\n",
        "    self.resize_layer = torch.nn.AdaptiveAvgPool2d(\n",
        "      (config[\"final_height\"], config[\"final_width\"]))\n",
        "\n",
        "    # now, we can apply our fully-connected component\n",
        "    final_size = config[\"final_height\"] * config[\"final_width\"] * config[\"conv.channels\"][-1]\n",
        "    self.fc_layers = torch.nn.Sequential( # specify our LEGOs. edit this by adding to the list!\n",
        "      FullyConnected(in_features=final_size, activation=config[\"activation\"],\n",
        "                     out_features=config[\"fc1.size\"],\n",
        "                     dropout=config[\"fc.dropout\"]),\n",
        "      FullyConnected(in_features=config[\"fc1.size\"], activation=config[\"activation\"],\n",
        "                     out_features=config[\"fc2.size\"],\n",
        "                     dropout=config[\"fc.dropout\"]),\n",
        "      FullyConnected(in_features=config[\"fc2.size\"],  # \"read-out\" layer\n",
        "                     out_features=10),\n",
        "    )\n",
        "\n",
        "    self.loss = config[\"loss\"]\n",
        "    self.optimizer = config[\"optimizer\"]\n",
        "    self.optimizer_params = config[\"optimizer.params\"]\n",
        "    config.update({f\"channels_{ii}\": channels\n",
        "                   for ii, channels in enumerate(config[\"conv.channels\"])})\n",
        "\n",
        "  def forward(self, x):  # produce outputs\n",
        "    # first apply convolutional layers\n",
        "    for layer in self.conv_layers: \n",
        "      x = layer(x)\n",
        "\n",
        "    # then convert to a fixed-size vector\n",
        "    x = self.resize_layer(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "    # then apply the fully-connected layers\n",
        "    for layer in self.fc_layers: # snap together the LEGOs\n",
        "      x = layer(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1)  # compute log of softmax, for numerical reasons\n",
        "\n",
        "  def configure_optimizers(self):  # ⚡: setup for .fit\n",
        "    return self.optimizer(self.parameters(), **self.optimizer_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWFQ0CTTfpu"
      },
      "source": [
        "config = {  # basic config, without pruning\n",
        "  \"batch_size\": 512,\n",
        "  \"max_epochs\": 5,\n",
        "  \"kernel_size\": 9,\n",
        "  \"conv.channels\": [128, 256],\n",
        "  \"conv.dropout\": 0.5,\n",
        "  \"pool_size\": 2,\n",
        "  \"final_height\": 10,\n",
        "  \"final_width\": 10,\n",
        "  \"fc1.size\": 1024,\n",
        "  \"fc2.size\": 512,\n",
        "  \"fc.dropout\": 0.5,\n",
        "  \"activation\": torch.nn.ReLU(),\n",
        "  \"loss\": torch.nn.NLLLoss(),  # cross-entropy loss\n",
        "  \"optimizer\": torch.optim.Adam,\n",
        "  \"optimizer.params\": {\"lr\": 0.0001,\n",
        "                       \"weight_decay\": 5e-3}  # weight decay makes weights decay to 0\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwnUlDECEGW0"
      },
      "source": [
        "# 📸 set up the dataset of images\n",
        "dmodule = utils.MNISTDataModule(batch_size=config[\"batch_size\"])\n",
        "dmodule.prepare_data()\n",
        "dmodule.setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0xSbB4oI5jS"
      },
      "source": [
        "# Training Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOi6dvhjI60P"
      },
      "source": [
        "def train(network, dmodule, config):\n",
        "\n",
        "  with wandb.init(config=config, entity=\"wandb\", project=\"prune\", job_type=\"profile\") as run:\n",
        "    \n",
        "    callbacks = []\n",
        "    # Pruning:\n",
        "    #  if doing model pruning, add in callbacks\n",
        "    for prune_config in config[\"pruning\"].values():\n",
        "      callbacks.append(make_pruner(prune_config, network, n_epochs=config[\"max_epochs\"]))\n",
        "\n",
        "    filter_logger_callback = utils.FilterLogCallback(\n",
        "      image_size=[], log_input=True, log_output=False)\n",
        "    sparsity_logger_callback = SparsityLogCallback()\n",
        "\n",
        "    callbacks.extend([filter_logger_callback, sparsity_logger_callback])\n",
        "\n",
        "    # 👟 configure Trainer \n",
        "    trainer = pl.Trainer(\n",
        "        precision=16,  # use half-precision floats\n",
        "        gpus=1,  # use the GPU for .forward\n",
        "        logger=pl.loggers.WandbLogger(\n",
        "          log_model=True, save_code=True),  # log to Weights & Biases\n",
        "        callbacks=callbacks,\n",
        "        max_epochs=config[\"max_epochs\"], log_every_n_steps=1,\n",
        "        progress_bar_refresh_rate=50)\n",
        "                        \n",
        "    # 🏃‍♀️ run the Trainer on the model\n",
        "    trainer.fit(network, dmodule)\n",
        "    \n",
        "  return network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-l5iQJqIgEX"
      },
      "source": [
        "# Baseline: No Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKRtvG-lEnE9"
      },
      "source": [
        "# 🥅 instantiate the network\n",
        "network = LitCNN(config)\n",
        "\n",
        "config[\"pruning\"] = {}\n",
        "network = train(network, dmodule, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jtNeHahsMt6"
      },
      "source": [
        "# Pruning Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqgEN5aUsI3P"
      },
      "source": [
        "## Pruning Callbacks: Global and Local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm8lfPjyMMkl"
      },
      "source": [
        "# Helper functions for building ModelPruning Callbacks\n",
        "#  details here are mostly unimportant; see the docs for ModelPruning\n",
        "#  for more on how pruning works and is configured\n",
        "\n",
        "def make_pruner(prune_config, network=None, n_epochs=None):\n",
        "  \"\"\"Builds a ModelPruning PyTorchLightning Callback from a dictionary.\n",
        "\n",
        "  Aside from the keyword arguments to pl.Callbacks.ModelPruning, this dictionary\n",
        "  may contain the keys \"target_sparsity\"\n",
        "  \n",
        "  target_sparsity is combined with n_epochs to determine the value of the\n",
        "  \"amount\" keyword argument to ModelPruning, which specifies how much pruning to\n",
        "  do on each epoch.\n",
        "\n",
        "  parameters can be None, \"conv\", or \"linear\". It is used to fetch the\n",
        "  paarameters which are to be pruned from the provided network. See\n",
        "  get_parameters_to_prune for details. Note that None corresponds to pruning\n",
        "  all parameters.\n",
        "  \"\"\"\n",
        "  if \"target_sparsity\" in prune_config.keys():\n",
        "    target = prune_config.pop(\"target_sparsity\")\n",
        "    assert n_epochs is not None, \"when specifying target sparsity, must provide number of epochs\"\n",
        "    prune_config[\"amount\"] = compute_iterative_prune(target, n_epochs)\n",
        "\n",
        "  assert \"amount\" in prune_config.keys(), \"must specify stepwise pruning amount or target\"\n",
        "\n",
        "  if \"parameters\" in prune_config.keys():\n",
        "    parameters = prune_config.pop(\"parameters\")\n",
        "    if parameters is not None:\n",
        "      assert network is not None, \"when specifying parameters, must provide network\"\n",
        "    prune_config[\"parameters_to_prune\"] = get_parameters_to_prune(parameters, network)\n",
        "\n",
        "  assert \"parameters_to_prune\" in prune_config.keys(), \"must specify which parameters to prune, or None\"\n",
        "\n",
        "  return ModelPruning(**prune_config)\n",
        "\n",
        "\n",
        "def get_parameters_to_prune(parameters, network):\n",
        "  \"\"\"Return the weights of network matching the parameters value.\n",
        "\n",
        "  Parameters must be one of \"conv\" or \"linear\", or None,\n",
        "  in which case None is also returned.\n",
        "  \"\"\"\n",
        "  if parameters == \"conv\":\n",
        "    return [(layer.conv2d, \"weight\") for layer in network.conv_layers\n",
        "            if isinstance(layer, Convolution)]\n",
        "  elif parameters == \"linear\":\n",
        "    return [(layer.linear, \"weight\") for layer in network.fc_layers\n",
        "            if isinstance(layer, FullyConnected)]\n",
        "  elif parameters is None:\n",
        "    return\n",
        "  else:\n",
        "    raise ValueError(f\"could not understand parameters value: {parameters}\")\n",
        "\n",
        "def compute_iterative_prune(target_sparsity, n_epochs):\n",
        "  return 1 - math.pow(1 - target_sparsity, 1 / n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnQ_6l3bMdnF"
      },
      "source": [
        "global_prune_config = {  # config for applying pruning to the entire network\n",
        "  \"parameters\": None,\n",
        "  \"pruning_fn\": \"l1_unstructured\",\n",
        "  \"target_sparsity\": 0.9,  # target sparsity level for this pruner\n",
        "  \"use_global_unstructured\": True,\n",
        "  \"pruning_dim\": None,\n",
        "  \"pruning_norm\": None,\n",
        "}\n",
        "\n",
        "conv_prune_config = {  # config for applying pruning channelwise to conv layers\n",
        "  \"parameters\": \"conv\", \n",
        "  \"pruning_fn\": \"ln_structured\",\n",
        "  \"target_sparsity\": 0.9,\n",
        "  \"use_global_unstructured\": False,\n",
        "  \"pruning_dim\": 0,\n",
        "  \"pruning_norm\": 1,\n",
        "}\n",
        "\n",
        "linear_prune_config = {  # config for applying pruning featurewise to linear layers\n",
        "  \"parameters\": \"linear\",\n",
        "  \"pruning_fn\": \"ln_structured\",\n",
        "  \"target_sparsity\": 0.9,\n",
        "  \"use_global_unstructured\": False,\n",
        "  \"pruning_dim\": 1,\n",
        "  \"pruning_norm\": 1,\n",
        "}\n",
        "\n",
        "pnetwork = LitCNN(config)\n",
        "\n",
        "config[\"pruning\"] = {}\n",
        "config[\"pruning\"][\"global\"] = global_prune_config  # comment to remove global pruning\n",
        "config[\"pruning\"][\"conv\"] = conv_prune_config  # comment to remove channelwise pruning in conv layers\n",
        "config[\"pruning\"][\"linear\"] = linear_prune_config  # comment to remove featurewise pruning in linear layers\n",
        "\n",
        "pnetwork = train(pnetwork, dmodule, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcTDkPlmT-JN"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVlqBmx6T_VE"
      },
      "source": [
        "#### 1. Training a Network with 99% Sparsity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfUCpGFtUUP0"
      },
      "source": [
        "With the default settings above\n",
        "(unstructured pruning applied globally\n",
        "and feature-wise pruning applied to linear and convolutional layers,\n",
        "each with a target sparsity of `0.9`),\n",
        "typical final sparsities are close to 99%.\n",
        "\n",
        "Review the Weights & Biases dashboard for a training run with these settings.\n",
        "\n",
        "Do you notice anything interesting in the loss and accuracy traces?\n",
        "Especially on the training set, these are typically monotonic.\n",
        "\n",
        "The \"sparsity\" section tracks the degree of sparsity for\n",
        "each layer and for the network as a whole.\n",
        "\n",
        "With a typical multiplicative, iterative pruning strategy,\n",
        "the largest absolute increase in sparsity is at the end of the first epoch,\n",
        "when it increases from `0` to `0.33`,\n",
        "while the fraction of remaining weights pruned\n",
        "remains constant.\n",
        "The magnitude of pruned weights in each step\n",
        "generally increases throughout training.\n",
        "\n",
        "Based on training set performance,\n",
        "does the accuracy hit caused by pruning track\n",
        "a) the absolute increase in sparsity,\n",
        "b) the relative increase in sparsity,\n",
        "(the fraction of remaining weights pruned),\n",
        "or c) the magnitude of the pruned weights?\n",
        "\n",
        "The weights in the input layer are visualized as images\n",
        "alongside the training and validation metrics\n",
        "(the step index, on the x axis, is shared between the charts).\n",
        "Each patch, separated by black bars from the other patches,\n",
        "represents the kernel for a single unit in the convolutional layer.\n",
        "During training, weights are pruned by being set to 0,\n",
        "which is rendered as gray here.\n",
        "Notice that some kernels are entirely gray,\n",
        "that by the end almost all of the kernels are either fully or primarily gray.\n",
        "Relate these and other features of this chart to the sparsity over time curves\n",
        "and to the pruning strategies employed.\n",
        "Try removing the convolutional pruning\n",
        "(`config[\"pruning\"][\"conv\"]`),\n",
        "re-running training,\n",
        "and note the differences.\n",
        "\n",
        "It can be helpful to additionally compare these weights\n",
        "with the weights learned in the baseline,\n",
        "with no pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmaWxnFmUIqh"
      },
      "source": [
        "#### 2. Train Longer, Get Sparser?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjS0KpF1UTEL"
      },
      "source": [
        "In typical pruning stategies,\n",
        "pruning is applied epochwise.\n",
        "\n",
        "When epochs are shorter (smaller `batch_size`)\n",
        "or when there are fewer of them (smaller `max_epochs`),\n",
        "the impact of pruning on accuracy can be greater.\n",
        "\n",
        "Test out this statement by checking for\n",
        "- reduced performance with smaller `max_epochs` (2-3) and/or larger `batch_size` (2x to 4x larger)\n",
        "- improved performance with larger `max_epochs` (up to 50) and/or smaller `batch_size` (2x to 8x smaller)\n",
        "\n",
        "Can you find a setting of the parameters for which\n",
        "the final network is approximately 99% sparse\n",
        "but where validation accuracy is 95% or higher?\n",
        "Note that 24 out of every 25 parameters\n",
        "are in the linear layers.\n",
        "\n",
        "Networks with large numbers of epochs may end up with training losses\n",
        "significantly higher than final validation loss,\n",
        "especially when feature-wise pruning,\n",
        "as in the `linear` and `conv` pruners,\n",
        "is turned on.\n",
        "Why might this be?\n",
        "\n",
        "_Hint_: DropOut is disabled during validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scMcj2y3UMir"
      },
      "source": [
        "#### 3. Structured Pruning Considered Harmful"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUUg8j38UQpt"
      },
      "source": [
        "Structured pruning,\n",
        "which removes entire input or output channels,\n",
        "leads more easily to performance gains:\n",
        "simply create a new network with all of the pruned\n",
        "neurons removed\n",
        "(effectively reducing the number of neurons in each layer).\n",
        "This is not easy, but it can be done in a straightforward manner\n",
        "to achieve acceleration of inference on commodity CPU/GPU hardware.\n",
        "\n",
        "By comparison, unstructured pruning,\n",
        "which removes specific weights,\n",
        "can only lead to performance gains \n",
        "when using special-purpose hardware and software for sparse matrix\n",
        "multiplication that is,\n",
        "as of early 2021,\n",
        "not widely used and available.\n",
        "\n",
        "However, structured pruning can have more deleterious effects on training.\n",
        "\n",
        "Turn off the structured pruners\n",
        "(featurewise `linear` and channelwise `conv`)\n",
        "and increase the global sparsity target to `0.99`.\n",
        "This will train a network that only has global unstructured pruning\n",
        "to the same sparsity level as one with the original default settings\n",
        "(sparsity target `0.9` for each pruner separately).\n",
        "\n",
        "Compare the final validation performance\n",
        "of the two networks\n",
        "(and make sure the other hyperparameters are the same!).\n",
        "Which network does better?\n",
        "\n",
        "_Note_: though the distinction between, say, 94% accuracy and 97% accuracy\n",
        "is small in absolute terms, it represents a reduction by half of\n",
        "the number of errors -- more akin to the difference between 33% and 66% accuracy\n",
        "than between 33% and 36%.\n",
        "These seemingly marginal improvements are indeed worth fighting over,\n",
        "provided accuracy is in fact the correct model metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gDNySgGhXiE"
      },
      "source": [
        "#### Challenge: DropOut and Sparsity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jShiCRjiesG"
      },
      "source": [
        "\n",
        "DropOut is effectively a form of random\n",
        "feature-wise pruning, applied at each training step.\n",
        "\n",
        "It seems plausible that including DropOut during training\n",
        "might reduce the magnitude of the \"jumps\" in the loss\n",
        "caused by pruning -- the network has already learned a strategy\n",
        "that is robust to random pruning, so perhaps it is also more robust\n",
        "to structured pruning.\n",
        "\n",
        "Test this hypothesis by running a series\n",
        "of runs with varying pruning strategies\n",
        "with and then without DropOut\n",
        "(you can turn off dropout by reducing the `.dropout` hyperparameters to `0.`).\n",
        "\n",
        "Does it hold up?"
      ]
    }
  ]
}