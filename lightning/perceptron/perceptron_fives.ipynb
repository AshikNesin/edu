{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron-fives.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/lightning/perceptron/perceptron_fives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c216tB5gbTG8"
      },
      "source": [
        "# A Perceptron for Detecting Fives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN1M5zGebb9J"
      },
      "source": [
        "## Installing and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu5Gebw6uvDF"
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch-lightning torchviz wandb\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/wandb/edu/main/\"\n",
        "utils_path = \"lightning/utils.py\"\n",
        "# Download a util file of helper methods for this notebook\n",
        "!curl {repo_url + utils_path} --output utils.py\n",
        "\n",
        "import math\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets\n",
        "import wandb\n",
        "\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1iZhbQbfyy"
      },
      "source": [
        "## Defining the `Model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElHWRKqcu8oL"
      },
      "source": [
        "class LitPerceptronModel(utils.LoggedImageClassifierModule):\n",
        "  \"\"\"A simple Perceptron Model, with under-the-hood wandb\n",
        "  and pytorch-lightning features (logging, metrics, etc.).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, max_images_to_display=32):  # make the model\n",
        "    super().__init__(max_images_to_display=max_images_to_display)\n",
        "    self.perceptron = torch.nn.Linear(in_features=28 * 28, out_features=1)\n",
        "    self.loss = torch.nn.MSELoss()\n",
        "\n",
        "  def forward(self, x):  # produce outputs\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    return self.perceptron(x)\n",
        "\n",
        "  def configure_optimizers(self):  # ‚ö°: setup for .fit\n",
        "    return torch.optim.Adam(self.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-0WwC57bigK"
      },
      "source": [
        "## Defining a `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7InOksIvsTK"
      },
      "source": [
        "class PerceptronDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, batch_size=64):\n",
        "    super().__init__()  # ‚ö°: we inherit from LightningDataModule\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def prepare_data(self): # ‚ö°: how do we set up the data?\n",
        "    # download the data from the internet\n",
        "    mnist = torchvision.datasets.MNIST(\".\", train=True, download=True)\n",
        "\n",
        "    # set up shapes and types\n",
        "    self.digits, self.is_5 = mnist.data.float(), (mnist.targets == 5)[:, None].float()\n",
        "    self.dataset = torch.utils.data.TensorDataset(self.digits, self.is_5)\n",
        "\n",
        "  def train_dataloader(self):  # ‚ö°: how do we go from dataset to dataloader?\n",
        "    \"\"\"The DataLoaders returned by a DataModule produce data for a model.\n",
        "    \n",
        "    This DataLoader is used during training.\"\"\"\n",
        "    return DataLoader(self.dataset, batch_size=self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq_qDw3Ubv8d"
      },
      "source": [
        "## Building and Training the `Model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaYToi8Z5WlQ"
      },
      "source": [
        "dmodule  = PerceptronDataModule(batch_size=256)\n",
        "lp = LitPerceptronModel(max_images_to_display=32)\n",
        "\n",
        "dmodule.prepare_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8E52qNDr8O0"
      },
      "source": [
        "### Debugging Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu5EIhmrrxxO"
      },
      "source": [
        "# for debugging purposes (checking shapes, etc.), make these available\n",
        "dloader = dmodule.train_dataloader()\n",
        "\n",
        "example_batch = next(iter(dloader))\n",
        "example_x, example_y = example_batch[0].to(\"cuda\"), example_batch[1].to(\"cuda\")\n",
        "\n",
        "print(f\"Input Shape: {example_x.shape}\")\n",
        "print(f\"Target Shape: {example_y.shape}\")\n",
        "\n",
        "lp.to(\"cuda\")\n",
        "outputs = lp.forward(example_x)\n",
        "print(f\"Output Shape: {outputs.shape}\")\n",
        "print(f\"Loss : {lp.loss(outputs, example_y)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm_uxxIyr_j9"
      },
      "source": [
        "### Running `.fit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0RIrZI-LNeN"
      },
      "source": [
        "# üëü configure Trainer \n",
        "trainer = pl.Trainer(gpus=1,  # use the GPU for .forward\n",
        "                     logger=pl.loggers.WandbLogger(\n",
        "                       project=\"lit-perceptron\", entity=\"wandb\",\n",
        "                       save_code=True),  # log to Weights & Biases\n",
        "                     max_epochs=10, log_every_n_steps=1)\n",
        "\n",
        "# üèÉ‚Äç‚ôÄÔ∏è run the Trainer on the model\n",
        "trainer.fit(lp, dmodule)\n",
        "\n",
        "# üèÅ close out the run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}