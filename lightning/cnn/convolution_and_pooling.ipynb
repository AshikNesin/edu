{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolution-and-pooling.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6LZIthrf2rSo0SS0/2mDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/lightning/cnn/convolution_and_pooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y07MHvx0tXk4"
      },
      "source": [
        "# Convolution and Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PYCubMsoU29"
      },
      "source": [
        "## Utility Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuKpkzbOQFeH"
      },
      "source": [
        "%%capture\n",
        "import torch\n",
        "import torch.tensor as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "\n",
        "# pull down images\n",
        "!wget https://raw.githubusercontent.com/wandb/edu/main/lightning/cnn/ims/smiley.png\n",
        "!wget https://raw.githubusercontent.com/wandb/edu/main/lightning/cnn/ims/dog.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSdJ4TBIg9fU"
      },
      "source": [
        "def prepare_kernel(kernel):\n",
        "    \"\"\"prepare a kernel for use with torch.conv2d\n",
        "    technical details not necessary for understanding convolutions\"\"\"\n",
        "    kernel = kernel.double()  # cast to double precision\n",
        "    kernel -= torch.mean(kernel)  # standardize: centered at 0\n",
        "    kernel /= torch.linalg.norm(kernel)  # standardize: unit \"length\"\n",
        "    kernel = kernel[None, :, :]  # conv2d has an input channel dimension\n",
        "    kernel = kernel[None, :, :, :]  # conv2d expects a bank of filters \n",
        "    return kernel\n",
        "\n",
        "def imshow(im):\n",
        "    \"\"\"convenience function for plotting images\"\"\"\n",
        "    plt.imshow(torch.atleast_2d(torch.squeeze(im)), cmap=\"Greys\")\n",
        "    plt.axis(\"off\"); plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFweQsZaoRnj"
      },
      "source": [
        "## Load an Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHoJ6EgjS19y"
      },
      "source": [
        "impath = \"smiley.png\"  # options: dog.jpg, smiley.png\n",
        "raw_image = io.imread(impath, as_gray=True)\n",
        "image = T(raw_image)[None, None, :, :]  # detail: conv2d expects batches of images with multiple channels\n",
        "image = -1 * (image - torch.mean(image))\n",
        "\n",
        "imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4rDxHGPoW03"
      },
      "source": [
        "## Define a convolution kernel and view it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2qXOvhjhho"
      },
      "source": [
        "kernel = T([[0, 0, 1],  # change this around to define your own kernels!\n",
        "            [0, 1, 1],  # see exercises for a suggestion\n",
        "            [1, 1, 1]])\n",
        "# kernel = 1 - kernel  # try this to flip the kernel: dark edges to light edges, etc.\n",
        "t_kernel = prepare_kernel(kernel)\n",
        "\n",
        "imshow(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqADg93GoZKv"
      },
      "source": [
        "## Apply the kernel and see the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKNCEMi7haJn"
      },
      "source": [
        "features = torch.conv2d(image, t_kernel)\n",
        "\n",
        "# exercise code goes here; see below\n",
        "\n",
        "imshow(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98IrHQr4lntx"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "#### **Exercise**: Convolutions are usually followed by nonlinearities. Add `torch.relu` to the operations above. How does the output change?\n",
        "\n",
        "#### **Exercise**: CNNs use pooling to reduce the size of representations passing through the network. Add `torch.max_pool2d` to the operations above (after the non-linearity, if you have one). How does the output change? _Note_: `max_pool2d` requires two arguments: the array to apply the pooling to, and a `kernel_size` for the pooling. Reasonable values might be between 2 and 5.\n",
        "\n",
        "#### **Exercise**: The [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator) can be used as a rough detector for edges in any direction. One piece of it, $G_x$ (defined below), makes for a nice horizontal edge detector as a convolution kernel. Try it out as a `kernel` above.\n",
        "\n",
        "$$\n",
        "G_x = \\left[\\begin{array}{ccc}\n",
        "    1 & 2 & 1 \\\\\n",
        "    0 & 0 & 0 \\\\\n",
        "    -1 & 2 & -1\n",
        "    \\end{array}\\right]\n",
        "$$"
      ]
    }
  ]
}