{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/lightning/cnn/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c216tB5gbTG8"
      },
      "source": [
        "# A Convolutional Network for MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN1M5zGebb9J"
      },
      "source": [
        "## Installing and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu5Gebw6uvDF"
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch-lightning wandb\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/wandb/edu/main/\"\n",
        "utils_path = \"lightning/utils.py\"\n",
        "# Download a util file of helper methods for this notebook\n",
        "!curl {repo_url + utils_path} --output utils.py\n",
        "\n",
        "import math\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets\n",
        "import wandb\n",
        "\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1iZhbQbfyy"
      },
      "source": [
        "## Defining the `Model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElHWRKqcu8oL"
      },
      "source": [
        "class FullyConnected(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, in_features, out_features, activation=None):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(in_features, out_features)\n",
        "    if activation is None:\n",
        "      activation = torch.nn.Identity()  # defaults to passing inputs unchanged\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.activation(self.linear(x))\n",
        "\n",
        "\n",
        "class Convolution(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size,\n",
        "               activation=lambda xs: xs):\n",
        "    super().__init__()\n",
        "    self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size)\n",
        "    self.activation = activation  # defaults to passing inputs unchanged\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.activation(self.conv2d(x))\n",
        "\n",
        "class LitCNN(utils.LoggedImageClassifierModule):\n",
        "  \"\"\"A simple CNN Model, with under-the-hood wandb\n",
        "  and pytorch-lightning channels (logging, metrics, etc.).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config, max_images_to_display=32):  # make the model\n",
        "    super().__init__(max_images_to_display=max_images_to_display)\n",
        "\n",
        "    self.conv_layers = torch.nn.ModuleList([  # specify our LEGOs. edit this by adding to the list!\n",
        "      # hidden conv layer\n",
        "      Convolution(in_channels=1, kernel_size=config[\"kernel_size\"],\n",
        "                  activation=config[\"activation\"],\n",
        "                  out_channels=config[\"conv.channels\"][0]),\n",
        "      # hidden conv layer\n",
        "      Convolution(in_channels=config[\"conv.channels\"][0], kernel_size=config[\"kernel_size\"],\n",
        "                  activation=config[\"activation\"],\n",
        "                  out_channels=config[\"conv.channels\"][1]),\n",
        "      # pooling often follows 2 convs\n",
        "      torch.nn.MaxPool2d(config[\"pool_size\"]),\n",
        "    ])\n",
        "\n",
        "\n",
        "    # need a fixed-size input for fully-connected component,\n",
        "    #  so apply a \"re-sizing\" layer, to size set in config\n",
        "    self.resize_layer = torch.nn.AdaptiveAvgPool2d(\n",
        "      (config[\"final_height\"], config[\"final_width\"]))\n",
        "\n",
        "    final_size = config[\"final_height\"] * config[\"final_width\"] * config[\"conv.channels\"][-1]\n",
        "    self.fc_layers = torch.nn.ModuleList([ # specify our LEGOs. edit this by adding to the list!\n",
        "      FullyConnected(in_features=final_size, activation=config[\"activation\"],\n",
        "                     out_features=config[\"fc1.size\"]),\n",
        "      FullyConnected(in_features=config[\"fc1.size\"],  # \"read-out\" layer\n",
        "                     out_features=10),\n",
        "    ])\n",
        "\n",
        "    self.loss = config[\"loss\"]\n",
        "    self.optimizer = config[\"optimizer\"]\n",
        "    self.optimizer_params = config[\"optimizer.params\"]\n",
        "\n",
        "  def forward(self, x):  # produce outputs\n",
        "    x = torch.unsqueeze(x, 1)  # adding singleton channel dimension\n",
        "    # first apply convolutional layers\n",
        "    for layer in self.conv_layers: \n",
        "      x = layer(x)\n",
        "\n",
        "    # then convert to a fixed-size vector\n",
        "    x = self.resize_layer(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "    # then apply the fully-connected layers\n",
        "    for layer in self.fc_layers: # snap together the LEGOs\n",
        "      x = layer(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1)  # compute log of softmax, for numerical reasons\n",
        "\n",
        "  def configure_optimizers(self):  # ⚡: setup for .fit\n",
        "    return self.optimizer(self.parameters(), **self.optimizer_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-0WwC57bigK"
      },
      "source": [
        "## Defining the `DataModule` & `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7InOksIvsTK"
      },
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, batch_size=64):\n",
        "    super().__init__()  # ⚡: we inherit from LightningDataModule\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def prepare_data(self, validation_size=10_000): # ⚡: how do we set up the data?\n",
        "    # download the data from the internet\n",
        "    mnist = torchvision.datasets.MNIST(\".\", train=True, download=True)\n",
        "\n",
        "    # set up shapes and types\n",
        "    self.digits, self.labels = mnist.data.float(), mnist.targets\n",
        "    self.digits = torch.divide(self.digits, 255.)\n",
        "\n",
        "    self.training_data = torch.utils.data.TensorDataset(self.digits[:-validation_size],\n",
        "                                                        self.labels[:-validation_size])\n",
        "    self.validation_data = torch.utils.data.TensorDataset(self.digits[-validation_size:],\n",
        "                                                          self.labels[-validation_size:])\n",
        "    self.validation_size = validation_size\n",
        "\n",
        "  def train_dataloader(self):  # ⚡: how do we go from dataset to dataloader?\n",
        "    \"\"\"The DataLoaders returned by a DataModule produce data for a model.\n",
        "    \n",
        "    This DataLoader is used during training.\"\"\"\n",
        "    return DataLoader(self.training_data, batch_size=self.batch_size)\n",
        "\n",
        "  def val_dataloader(self):  # ⚡: what about during validation?\n",
        "    \"\"\"The DataLoaders returned by a DataModule produce data for a model.\n",
        "    \n",
        "    This DataLoader is used during validation, at the end of each epoch.\"\"\"\n",
        "    return DataLoader(self.validation_data, batch_size=self.validation_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq_qDw3Ubv8d"
      },
      "source": [
        "## Building and Training the `Model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUXHdz2BPko3"
      },
      "source": [
        "config = {\n",
        "  \"batch_size\": 256,\n",
        "  \"max_epochs\": 2,\n",
        "  \"kernel_size\": 3,\n",
        "  \"conv.channels\": [16, 16],\n",
        "  \"pool_size\": 2,\n",
        "  \"final_height\": 8,\n",
        "  \"final_width\": 8,\n",
        "  \"fc1.size\": 256,\n",
        "  \"activation\": torch.nn.ReLU(),\n",
        "  \"loss\": torch.nn.NLLLoss(),  # cross-entropy loss\n",
        "  \"optimizer\": torch.optim.Adam,\n",
        "  \"optimizer.params\": {\"lr\": 0.001},\n",
        "}\n",
        "\n",
        "dmodule  = MNISTDataModule(batch_size=config[\"batch_size\"])\n",
        "lcnn = LitCNN(config, max_images_to_display=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo9wuMQZe4y2"
      },
      "source": [
        "### Model Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDfyzjo_dPtc"
      },
      "source": [
        "print(lcnn)\n",
        "print(f\"Parameter Count: {lcnn.count_params()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVoS6dMzlaE9"
      },
      "source": [
        "# for debugging purposes (checking shapes, etc.), make these available\n",
        "dmodule.prepare_data()\n",
        "dloader = dmodule.train_dataloader()\n",
        "\n",
        "example_batch = next(iter(dloader))\n",
        "example_x, example_y = example_batch[0].to(\"cuda\"), example_batch[1].to(\"cuda\")\n",
        "\n",
        "print(f\"Input Shape: {example_x.shape}\")\n",
        "print(f\"Target Shape: {example_y.shape}\")\n",
        "\n",
        "lcnn.to(\"cuda\")\n",
        "outputs = lcnn.forward(example_x)\n",
        "print(f\"Output Shape: {outputs.shape}\")\n",
        "print(f\"Loss : {lcnn.loss(outputs, example_y)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi1VaHnue9jX"
      },
      "source": [
        "### Running `.fit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0RIrZI-LNeN"
      },
      "source": [
        "# 👟 configure Trainer \n",
        "trainer = pl.Trainer(gpus=1,  # use the GPU for .forward\n",
        "                     logger=pl.loggers.WandbLogger(\n",
        "                       project=\"lit-cnn\", entity=\"wandb\", config=config,\n",
        "                       save_code=True),  # log to Weights & Biases\n",
        "                     max_epochs=config[\"max_epochs\"], log_every_n_steps=1)\n",
        "\n",
        "# 🏃‍♀️ run the Trainer on the model\n",
        "trainer.fit(lcnn, dmodule)\n",
        "\n",
        "# 💾 save the model\n",
        "torch.save(lcnn, \"model.pt\")\n",
        "wandb.save(\"model.pt\")\n",
        "\n",
        "# 🏁 close out the run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}