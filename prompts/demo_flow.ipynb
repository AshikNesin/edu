{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "339aa6c8",
   "metadata": {},
   "source": [
    "# Querying a Database with Natural Language\n",
    "## Experimentation with Weights & Biases \n",
    "\n",
    "In this notebook, we will use LLMs to generate SQL with natural language. The development process of LLM apps requires experimentation, for example with chain architecture and prompt engineering. We will use W&B Prompts Tracer to log our experiments and debug errors. After running the code, you should see a screen like this one in your W&B dashboard: \n",
    "\n",
    "![prompts.jpg](prompts.jpg)\n",
    "\n",
    "### Data\n",
    "- [TPCH_SF1](https://docs.snowflake.com/en/user-guide/sample-data-tpch) - Contains data related to **orders, customers, suppliers, and inventory** in a manufacturing and distribution business environment.\n",
    "- See [TPC Benchmark H](https://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.1.pdf) for details\n",
    "- Available in Snowflake or via [SQLite download from here](https://github.com/lovasoa/TPCH-sqlite/releases/tag/v1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d0f10",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b77e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install openai \n",
    "!pip install langchain==v0.0.147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebc7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import TransformChain, LLMChain, SequentialChain\n",
    "\n",
    "from utils import SQLConnector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88806907",
   "metadata": {},
   "source": [
    "Create a basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    WANDB_PROJECT=\"mt-pocono\",\n",
    "    WANDB_ENTITY=None, # Your W&B Team if you have one, e.g. \"prompt-eng\",\n",
    "    WANDB_JOB_TYPE=\"production\",\n",
    "    SNOWFLAKE_WAREHOUSE='COMPUTE_WH',\n",
    "    SNOWFLAKE_DATABASE='SNOWFLAKE_SAMPLE_DATA',\n",
    "    SNOWFLAKE_DATABASE_PREFIX='TPCH_SF1',\n",
    "    SNOWFLAKE_SCHEMA='INFORMATION_SCHEMA',\n",
    "    SQLITE_DB_PATH='data/TPC-H-small.db'  # Downloaded from https://github.com/lovasoa/TPCH-sqlite\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1783945d",
   "metadata": {},
   "source": [
    "Configure OpenAI api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459eda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df54e0e4",
   "metadata": {},
   "source": [
    "Configure Database\n",
    "- You can select either 'sqlite' or 'snowflake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70884761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set whether you're using Snowflake or SQLite database file in ./data\n",
    "config.DB_TYPE = 'sqlite'  # 'sqlite' or 'snowflake'\n",
    "\n",
    "# If using Snowflake, set your Snowflake credentials here\n",
    "config.SNOWFLAKE_PASSWORD = os.environ.get('SNOWFLAKE_PASSWORD')\n",
    "config.SNOWFLAKE_ACCOUNT = os.environ.get('SNOWFLAKE_ACCOUNT')  # ORG-ACCOUNT\n",
    "config.SNOWFLAKE_USER = os.environ.get('SNOWFLAKE_USER')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca243964",
   "metadata": {},
   "source": [
    "## Start W&B Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168483e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.langchain import WandbTracer\n",
    "\n",
    "WandbTracer.init({\"project\": config.WANDB_PROJECT, \"entity\": config.WANDB_ENTITY})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "883cb909",
   "metadata": {},
   "source": [
    "### Set Up Database\n",
    "- Set either `DB_TYPE = 'sqlite'` or `DB_TYPE = 'snowflake'` \n",
    "- Connect to our SQL database\n",
    "- Pull the database schema for the relevant Tables, this will be used as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ad570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conn = SQLConnector(config, db_type=config.DB_TYPE)  # db_type can be 'sqlite' or 'snowflake'\n",
    "# sql_conn(f\"select * from {config.SNOWFLAKE_DATABASE_PREFIX}.ORDERS limit 1\")  # Test the SQL connection\n",
    "\n",
    "# Get the schema for every Table in the SQLite database\n",
    "if config.DB_TYPE == 'sqlite':\n",
    "    schema_str = sql_conn.get_schema(database_name=\"TPC-H-small\", verbose=False)\n",
    "elif config.DB_TYPE == 'snowflake':\n",
    "    schema_str = sql_conn.get_schema(config.SNOWFLAKE_DATABASE, config.SNOWFLAKE_DATABASE_PREFIX, verbose=False)\n",
    "\n",
    "# schema_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524958b",
   "metadata": {},
   "source": [
    "## 1. Question -> SQL generation\n",
    "- Add basic schema info about a limited set of Tables to a simple prompt\n",
    "- Call SQL on Snowflake and log the success/fail result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 1: Generate SQL query from a user question\n",
    "llm = OpenAI(openai_api_key=os.environ.get('OPENAI_API_KEY'), \n",
    "             model_name = \"text-davinci-003\",\n",
    "             temperature=0, \n",
    "             verbose=True)\n",
    "\n",
    "template = f\"Here is a {config.DB_TYPE} database schema: {{schema_str}}.{{question}}\"\n",
    "\n",
    "generate_sql_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=PromptTemplate(input_variables=[\"schema_str\", \"question\"], template=template), \n",
    "    output_key=\"sql\",\n",
    "    verbose=True)\n",
    "\n",
    "# Chain 2: Run the SQL query\n",
    "def run_sql(inputs: dict) -> dict:\n",
    "    return {\"sql_result\": sql_conn(inputs[\"sql\"])}\n",
    "\n",
    "run_sql_chain = TransformChain(\n",
    "    input_variables=[\"sql\"], \n",
    "    output_variables=[\"sql_result\"], \n",
    "    transform=run_sql, \n",
    "    verbose=True)\n",
    "\n",
    "# Wrap the two chains into a SequentialChain\n",
    "sql_chain = SequentialChain(\n",
    "    chains=[generate_sql_chain, run_sql_chain], \n",
    "    input_variables=[\"schema_str\", \"question\"], \n",
    "    output_variables=[\"sql_result\", \"sql\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbf7e2",
   "metadata": {},
   "source": [
    "### Run the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = f\"Write a {config.DB_TYPE} sql query to find the most recent ship date for every customer\"\n",
    "question = f\"Write a {config.DB_TYPE} sql query to find the id of the first product we sent every customer, only return the first 10 rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71c38a",
   "metadata": {},
   "source": [
    "- Lets try run the chain with our basic user question.\n",
    "- If there is an error we can inspect what happened in Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sql_chain({\"question\": question, \"schema_str\": schema_str})\n",
    "except Exception as e:\n",
    "    print(f'\\nError running the chain:\\n{e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75212c",
   "metadata": {},
   "source": [
    "#### Lets run a few more queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "        \"Find the top 10 customers who have spent the most money\",\n",
    "        \"Get my last 10 orders\",\n",
    "        \"What is my best performing region?\",\n",
    "        \"Find the top 1 customer who has spent the most money\"\n",
    "    ]\n",
    "\n",
    "outputs = []\n",
    "for q in questions:\n",
    "    try:\n",
    "        outputs.append(sql_chain({\"question\": q, \"schema_str\": schema_str}))\n",
    "    except Exception as e:\n",
    "        print(f'\\nError running the chain:\\n{e}')\n",
    "\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc540de3",
   "metadata": {},
   "source": [
    "## LLM Self Correction\n",
    "- The output SQL is malformed, can we get the LLM to correct itself?\n",
    "- We can see that in some cases, the LLM tries to complete the question before generating the SQL\n",
    "- Lets explore whether we get get valid SQL from either:\n",
    "  - (A) using the LLM to simply clean up the output text, fixing the SQL and removing extraneous characters\n",
    "  - (B) using the LLM to just clarify the users input to generate the correct SQL or\n",
    "- Lets chain these calls together using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c098d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain Step 2: Cleanup and Format SQL: {raw_sql} -> {clean_sql}\n",
    "clean_sql_template = f\"\"\"Please correct any syntax errors in the following SQL and format it nicely: \n",
    "\n",
    "{{raw_sql}}\n",
    "\n",
    "Correct SQL:\"\"\"\n",
    "\n",
    "generate_sql_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=PromptTemplate(input_variables=[\"schema_str\", \"question\"], template=template), \n",
    "    output_key=\"raw_sql\",\n",
    "    verbose=True)\n",
    "\n",
    "clean_sql_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=PromptTemplate(input_variables=[\"raw_sql\"], template=clean_sql_template), \n",
    "    output_key=\"sql\",\n",
    "    verbose=True)\n",
    "\n",
    "run_sql_chain = TransformChain(\n",
    "    input_variables=[\"sql\"], \n",
    "    output_variables=[\"sql_result\"], \n",
    "    transform=run_sql, \n",
    "    verbose=True)\n",
    "\n",
    "# Wrap the two chains into a SequentialChain\n",
    "sql_chain = SequentialChain(\n",
    "    chains=[generate_sql_chain, clean_sql_chain, run_sql_chain], \n",
    "    input_variables=[\"schema_str\", \"question\"], \n",
    "    output_variables=[\"sql_result\", \"sql\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18844b31",
   "metadata": {},
   "source": [
    "Run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clean_sql_output = sql_chain({\"question\": question, \"schema_str\": schema_str})\n",
    "except Exception as e:\n",
    "    print(f'\\nError running the chain:\\n{e}')\n",
    "    clean_sql_output = None\n",
    "\n",
    "# clean_sql_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c2638",
   "metadata": {},
   "source": [
    "## LLM Question Clarification\n",
    "\n",
    "Lets try another approch; we'll ask the LLM to clarify the users' question, and see if the resulting SQL code can be run without any cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain Step 1.b: Clarify the users question: {user_input} -> {clarified_user_input}\n",
    "clarify_template = f\"\"\"Please re-write this user request, if needed, to better clarify the SQL question they are asking.\\\n",
    "    Please also make sure to include the word \"sql\" in the question. Add any additional context you think is necessary.\\\n",
    "    Add any punctuation you think is necessary.:\n",
    "\n",
    "{{raw_question}}\n",
    "\n",
    "A better request would be:\"\"\"\n",
    "\n",
    "\n",
    "clarify_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=PromptTemplate(input_variables=[\"raw_question\"], template=clarify_template), \n",
    "    output_key=\"question\",\n",
    "    verbose=True)\n",
    "\n",
    "generate_sql_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=PromptTemplate(input_variables=[\"schema_str\", \"question\"], template=template), \n",
    "    output_key=\"sql\",\n",
    "    verbose=True)\n",
    "\n",
    "run_sql_chain = TransformChain(\n",
    "    input_variables=[\"sql\"], \n",
    "    output_variables=[\"sql_result\"], \n",
    "    transform=run_sql, \n",
    "    verbose=True)\n",
    "\n",
    "# Wrap the two chains into a SequentialChain\n",
    "sql_chain = SequentialChain(\n",
    "    chains=[clarify_chain, generate_sql_chain, run_sql_chain], \n",
    "    input_variables=[\"schema_str\", \"raw_question\"], \n",
    "    output_variables=[\"sql_result\", \"sql\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65692b18",
   "metadata": {},
   "source": [
    "Run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clarify_output = sql_chain({\"raw_question\": question, \"schema_str\": schema_str})\n",
    "except Exception as e:\n",
    "    print(f'\\nError running the chain:\\n{e}')\n",
    "    clarify_output = None\n",
    "\n",
    "# clarify_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93340182",
   "metadata": {},
   "source": [
    "## 3. Iterate on the Prompt Template\n",
    "\n",
    "Taking our learnings back to improve the original prompt template and reduce the number of calls to the LLM service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, this was our old template\n",
    "# template = f\"Here is a snowflake database schema: {{schema_str}}.{{question}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_template = f\"\"\"You are a data analyst working on a {config.DB_TYPE} database with the following schema: {{schema_str}}\n",
    "\n",
    "Please produce a sql query to answer the following question from a colleague in the business: {{question}}\n",
    "\n",
    "Please ensure to use only correct SQL syntax without errors or strange punctuation. Only return SQL and please format it nicely: \n",
    "\n",
    "Correct SQL:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a05c8",
   "metadata": {},
   "source": [
    "Re-instantiate our SQL chain with the new prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sql_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=PromptTemplate(input_variables=[\"schema_str\", \"question\"], template=new_template), \n",
    "    output_key=\"sql\",\n",
    "    verbose=True)\n",
    "\n",
    "run_sql_chain = TransformChain(\n",
    "    input_variables=[\"sql\"], \n",
    "    output_variables=[\"sql_result\"], \n",
    "    transform=run_sql, \n",
    "    verbose=True)\n",
    "\n",
    "# Wrap the two chains into a SequentialChain\n",
    "sql_chain = SequentialChain(\n",
    "    chains=[generate_sql_chain, run_sql_chain], \n",
    "    input_variables=[\"schema_str\", \"question\"], \n",
    "    output_variables=[\"sql_result\", \"sql\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same question as before\n",
    "question = f\"Write a {config.DB_TYPE} sql query to find the id of the first product we sent every customer, only return the first 10 rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea4577",
   "metadata": {},
   "source": [
    "Run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a88f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_prompt_output = sql_chain({\"question\": question, \"schema_str\": schema_str})\n",
    "# better_prompt_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f9938",
   "metadata": {},
   "source": [
    "### Testing on More User Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d895987",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "        \"Find the top 10 customers who have spent the most money\",\n",
    "        \"Get my last 10 orders\",\n",
    "        \"What is my best performing region?\",\n",
    "        \"Find the top 1 customer who has spent the most money\"\n",
    "    ]\n",
    "\n",
    "outputs = []\n",
    "for q in questions:\n",
    "    outputs.append(sql_chain({\"question\": q, \"schema_str\": schema_str}))\n",
    "# # outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd9cd8f8",
   "metadata": {},
   "source": [
    "#### Finally, once you're finished, it is best practice to call `WandbTracer.stop_watch` to close the wandb process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WandbTracer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9634508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "09485bb77fe0556060c156ef69b4ea160bb58a9b1c0ced04eb38c4cd1e1d69ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
