{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torcheval.metrics import Mean, BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"pis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults\n",
    "cfg = SimpleNamespace(\n",
    "    img_size = 256,\n",
    "    target_column = 'mold',\n",
    "    bs = 16,\n",
    "    seed = 42,\n",
    "    epochs = 2,\n",
    "    lr = 2e-3,\n",
    "    wd=1e-5,\n",
    "    arch = 'resnet18',\n",
    "    log_model = False,\n",
    "    PROJECT_NAME = params.PROJECT_NAME,\n",
    "    ENTITY = params.ENTITY,\n",
    "    PROCESSED_DATA_AT = f'{params.DATA_AT}:latest',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(PROCESSED_DATA_AT):\n",
    "    \"Get/Download the datasets\"\n",
    "    processed_data_at = wandb.use_artifact(PROCESSED_DATA_AT)\n",
    "    processed_dataset_dir = Path(processed_data_at.download())\n",
    "    df = pd.read_csv(processed_dataset_dir / 'data_split.csv')\n",
    "    df = df[df.stage != 'test'].reset_index(drop=True)\n",
    "    df['valid'] = df.stage == 'valid'\n",
    "    return df, processed_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/edu/pyimagesearch/wandb/run-20230316_135816-vguipdsk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/pis/runs/vguipdsk\" target=\"_blank\">celestial-music-17</a></strong> to <a href=\"https://wandb.ai/capecape/pis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/capecape/pis\" target=\"_blank\">https://wandb.ai/capecape/pis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/capecape/pis/runs/vguipdsk\" target=\"_blank\">https://wandb.ai/capecape/pis/runs/vguipdsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact lemon_data:latest, 137.77MB. 2692 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2692 of 2692 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-music-17</strong> at: <a href=\"https://wandb.ai/capecape/pis/runs/vguipdsk\" target=\"_blank\">https://wandb.ai/capecape/pis/runs/vguipdsk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230316_135816-vguipdsk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=PROJECT_NAME):\n",
    "    df, processed_dataset_dir = prepare_data(cfg.PROCESSED_DATA_AT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>mold</th>\n",
       "      <th>file_name</th>\n",
       "      <th>fruit_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>stage</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[9, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>images/0001_A_H_0_A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>[2, 5, 7]</td>\n",
       "      <td>False</td>\n",
       "      <td>images/0003_A_V_150_A.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>[9, 2, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>images/0003_A_V_15_A.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>[2, 5, 7]</td>\n",
       "      <td>False</td>\n",
       "      <td>images/0003_A_V_165_A.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>[9, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>images/0003_A_V_30_A.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id category_id   mold                  file_name  fruit_id  fold  \\\n",
       "0         0      [9, 5]  False    images/0001_A_H_0_A.jpg         1     3   \n",
       "1       100   [2, 5, 7]  False  images/0003_A_V_150_A.jpg         3     7   \n",
       "2       101   [9, 2, 5]  False   images/0003_A_V_15_A.jpg         3     7   \n",
       "3       102   [2, 5, 7]  False  images/0003_A_V_165_A.jpg         3     7   \n",
       "4       103      [9, 5]  False   images/0003_A_V_30_A.jpg         3     7   \n",
       "\n",
       "   stage  valid  \n",
       "0  train  False  \n",
       "1  train  False  \n",
       "2  train  False  \n",
       "3  train  False  \n",
       "4  train  False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset:\n",
    "    def __init__(self, dataframe, root_dir, transform=None, image_column='file_name', target_column='mold'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): DataFrame containing image filenames and labels.\n",
    "            root_dir (string): Directory containing the images.\n",
    "            transform (callable, optional): Optional transform to be applied on an image sample.\n",
    "            image_column (string, optional): Name of the column containing the image filenames.\n",
    "            target_column (string, optional): Name of the column containing the labels.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_column = image_column\n",
    "        self.target_column = target_column\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def loc(self, idx):\n",
    "        idx_of_image_column = self.dataframe.columns.get_loc(self.image_column)\n",
    "        idx_of_target_column = self.dataframe.columns.get_loc(self.target_column)\n",
    "        x = self.dataframe.iloc[idx, idx_of_image_column]\n",
    "        y = self.dataframe.iloc[idx, idx_of_target_column]\n",
    "        return x, y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name, label = self.loc(idx)\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, 1.0 if label else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2275, 210)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms = T.Compose([T.Resize(cfg.img_size), T.ToTensor()])\n",
    "\n",
    "train_ds = ImageDataset(df[~df.valid], processed_dataset_dir, transform=tfms)\n",
    "valid_ds = ImageDataset(df[df.valid], processed_dataset_dir, transform=tfms)\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, float)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = train_ds[0]\n",
    "type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=cfg.bs, shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=cfg.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Size([16, 3, 256, 256]), torch.Size([16]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(train_dataloader))\n",
    "type(x), type(y), x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(cfg.arch, pretrained=False, num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "loss = loss_func(out.squeeze(), y.squeeze().float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress import progress_bar\n",
    "from utils import PredsLogger, set_seed, to_device, model_size, get_class_name_in_snake_case as snake_case\n",
    "\n",
    "class ClassificationTrainer:\n",
    "    def __init__(self, train_dataloader, valid_dataloader,  model, metrics, device=\"cuda\"):\n",
    "        \n",
    "        self.device = torch.device(device)        \n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.train_metrics = [m(device=self.device) for m in metrics]\n",
    "        self.valid_metrics = [m(device=self.device) for m in metrics]\n",
    "        self.loss = Mean()\n",
    "    \n",
    "    def loss_func(self, x, y):\n",
    "        \"A flattened version of nn.BCEWithLogitsLoss\"\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "        return loss_func(x.squeeze(), y.squeeze().float())\n",
    "    \n",
    "    def compile(self, epochs=5, lr=2e-3, wd=0.01):\n",
    "        \"Keras style compile method\"\n",
    "        self.epochs = epochs\n",
    "        self.optim = AdamW(self.model.parameters(), lr=lr, weight_decay=wd)\n",
    "        self.schedule = OneCycleLR(self.optim, \n",
    "                                   max_lr=lr, \n",
    "                                   pct_start=0.1,\n",
    "                                   total_steps=epochs*len(self.train_dataloader))\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.loss.reset()\n",
    "        for m in self.train_metrics: m.reset()\n",
    "        for m in self.valid_metrics: m.reset()\n",
    "        \n",
    "    def train_step(self, loss):\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        self.schedule.step()\n",
    "        return loss\n",
    "        \n",
    "    def one_epoch(self, train=True):\n",
    "        if train: \n",
    "            self.model.train()\n",
    "            dl = self.train_dataloader\n",
    "        else: \n",
    "            self.model.eval()\n",
    "            dl = self.valid_dataloader\n",
    "        pbar = progress_bar(dl, leave=False)\n",
    "        preds = []\n",
    "        for b in pbar:\n",
    "            with (torch.inference_mode() if not train else torch.enable_grad()):\n",
    "                images, labels = to_device(b, self.device)\n",
    "                preds_b = self.model(images).squeeze()\n",
    "                loss = self.loss_func(preds_b, labels)\n",
    "                self.loss.update(loss.detach().cpu(), weight=len(images))\n",
    "                preds.append(preds_b)\n",
    "                if train:\n",
    "                    self.train_step(loss)\n",
    "                    for m in self.train_metrics:\n",
    "                        m.update(preds_b, labels.long())\n",
    "                    wandb.log({\"train_loss\": loss.item(),\n",
    "                               \"learning_rate\": self.schedule.get_last_lr()[0]})\n",
    "                else:\n",
    "                    for m in self.valid_metrics:\n",
    "                        m.update(preds_b, labels.long())\n",
    "            pbar.comment = f\"train_loss={loss.item():2.3f}\"      \n",
    "            \n",
    "        return torch.cat(preds, dim=0), self.loss.compute()\n",
    "    \n",
    "    def log_preds(self):\n",
    "        if wandb.run is not None:\n",
    "            preds_logger = PredsLogger(ds=self.valid_ds) \n",
    "            print(\"Logging model predictions on validation data\")\n",
    "            preds, _ = self.get_model_preds()\n",
    "            preds_logger.log(preds=preds)\n",
    "            \n",
    "    def print_metrics(self, epoch, train_loss, val_loss):\n",
    "        print(f\"Epoch {epoch+1}/{self.epochs} - train_loss: {train_loss.item():2.3f} - val_loss: {val_loss.item():2.3f}\")\n",
    "    \n",
    "    def fit(self, log_preds=False):      \n",
    "        wandb.log({\"model_size\":model_size(self.model)})   \n",
    "        for epoch in progress_bar(range(self.epochs), total=self.epochs, leave=True):\n",
    "            _, train_loss = self.one_epoch(train=True)\n",
    "            wandb.log({f\"train_{snake_case(m)}\": m.compute() for m in self.train_metrics})\n",
    "\n",
    "                            \n",
    "            ## validation\n",
    "            _, val_loss = self.one_epoch(train=False)\n",
    "            wandb.log({f\"valid_{snake_case(m)}\": m.compute() for m in self.valid_metrics}, commit=False)\n",
    "            wandb.log({\"valid_loss\": val_loss.item()}, commit=False)\n",
    "            self.print_metrics(epoch, train_loss, val_loss)\n",
    "            self.reset_metrics()\n",
    "        if log_preds:\n",
    "            self.log_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ClassificationTrainer(train_dataloader, valid_dataloader, model, \n",
    "                                metrics=[BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile(epochs=cfg.epochs, lr=cfg.lr, wd=cfg.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>▂▃▅████████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>model_size</td><td>▁</td></tr><tr><td>train_binary_accuracy</td><td>▁█</td></tr><tr><td>train_binary_f1_score</td><td>▁█</td></tr><tr><td>train_binary_precision</td><td>▁█</td></tr><tr><td>train_binary_recall</td><td>▁█</td></tr><tr><td>train_loss</td><td>▂▂▁▂▁▁██▂▁▁▃▅▁▂▁▃▁▁▃▁▂▁▂▁▃▄▁▁▂▁▂▃▁▁▁▁▁▁▇</td></tr><tr><td>valid_binary_accuracy</td><td>▁█</td></tr><tr><td>valid_binary_f1_score</td><td>▁█</td></tr><tr><td>valid_binary_precision</td><td>█▁</td></tr><tr><td>valid_binary_recall</td><td>▁█</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>model_size</td><td>11177025</td></tr><tr><td>train_binary_accuracy</td><td>0.97846</td></tr><tr><td>train_binary_f1_score</td><td>0.85879</td></tr><tr><td>train_binary_precision</td><td>0.98675</td></tr><tr><td>train_binary_recall</td><td>0.7602</td></tr><tr><td>train_loss</td><td>0.01266</td></tr><tr><td>valid_binary_accuracy</td><td>0.9</td></tr><tr><td>valid_binary_f1_score</td><td>0.60377</td></tr><tr><td>valid_binary_precision</td><td>0.61538</td></tr><tr><td>valid_binary_recall</td><td>0.59259</td></tr><tr><td>valid_loss</td><td>0.09105</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sea-20</strong> at: <a href=\"https://wandb.ai/capecape/pis/runs/mylszw38\" target=\"_blank\">https://wandb.ai/capecape/pis/runs/mylszw38</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230316_140902-mylszw38/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=PROJECT_NAME, config=cfg):\n",
    "    trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_preds(images, model_preds, targets):\n",
    "    # Initialize Weights and Biases\n",
    "    wandb.init(project=\"Your_Project_Name\")\n",
    "\n",
    "    # Create Table\n",
    "    wandb_table = wandb.Table(columns=[\"Input Images\", \"Model Predictions\", \"Ground Truth\"])\n",
    "\n",
    "    for image, pred, target in zip(images, model_preds, targets):\n",
    "        wandb_table.add_data(wandb.Image(image), pred, target)\n",
    "\n",
    "    # Log Table\n",
    "    wandb.log({\"Results\": wandb_table})\n",
    "\n",
    "    # Finish logging and clean up\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I can provide you with a Python function to log your model outputs using Weights and Biases. You'll need to install Weights and Biases by running:\n",
    "\n",
    "```bash\n",
    "pip install wandb\n",
    "```\n",
    "\n",
    "Here is the Python function:\n",
    "\n",
    "```python\n",
    "import wandb\n",
    "from wandb import DataLogger\n",
    "\n",
    "def log_preds(images, model_preds, targets):\n",
    "    # Initialize Weights and Biases\n",
    "    wandb.init(project=\"Your_Project_Name\")\n",
    "\n",
    "    # Create Table\n",
    "    wandb_table = wandb.Table(columns=[\"Input Images\", \"Model Predictions\", \"Ground Truth\"])\n",
    "\n",
    "    for image, pred, target in zip(images, model_preds, targets):\n",
    "        wandb_table.add_data(wandb.Image(image), pred, target)\n",
    "\n",
    "    # Log Table\n",
    "    wandb.log({\"Results\": wandb_table})\n",
    "\n",
    "    # Finish logging and clean up\n",
    "    wandb.finish()\n",
    "```\n",
    "\n",
    "Replace `Your_Project_Name` with the relevant project name.\n",
    "\n",
    "This `log_preds` function initializes Weights and Biases, creates a wandb.Table, and iteratively adds the images, model_preds, and targets to the table. Once all data is added to the table, it logs the table and\n",
    "finishes the Weights and Biases run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
