{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c0d4d6-3d2b-45e5-90fa-ba7953496ec2",
   "metadata": {},
   "source": [
    "# LLM Tracing with W&B\n",
    "\n",
    "## 1. Auto-logging\n",
    "\n",
    "In this section, we will call OpenAI LLM to generate names of our game assets. We will use W&B autologging, also available for other popular LLMs and libraries like ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d52240-af93-4c87-a11e-309b23bdae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wandb-addons, this will be added to wandb soon\n",
    "# !git clone https://github.com/soumik12345/wandb-addons.git\n",
    "# !pip install ./wandb-addons[prompts] openai wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512739b-fe35-4901-acb3-05df46b5ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "\n",
    "from rich.markdown import Markdown\n",
    "import pandas as pd\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, # for exponential backoff\n",
    ")  \n",
    "import wandb\n",
    "from wandb.integration.openai import autolog\n",
    "from wandb_addons.prompts import Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c304c2b-dcd8-463c-aba4-aa47094dc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autolog({\"project\":\"deeplearningai-llm\", \"job_type\": \"generation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab394b-295b-4cfa-aade-aa274003a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e62a1-188f-47e1-bda9-5e3619e7d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fe64f-5cca-4316-8842-588b948193de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print(system_prompt, user_prompt, n=5):\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    responses = completion_with_backoff(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        n = n,\n",
    "        )\n",
    "    for response in responses.choices:\n",
    "        generation = response.message.content\n",
    "        display(Markdown(generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a256e-834f-42ee-8680-0e5cc53903cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e6e0a-193b-41c8-86c4-526f8061dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a creative copywriter.\n",
    "You're given a category of game asset, and your goal is to design a name of that asset.\n",
    "The game is set in a fantasy world where everyone laughs and respects each other, while celebrating diversity.\"\"\"\n",
    "user_prompt = \"hero\"\n",
    "generate_and_print(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343121b-2d47-47d1-b343-ec2393b8f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"jewel\"\n",
    "generate_and_print(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d6d513-389d-4c67-a942-a922bce6ff1a",
   "metadata": {},
   "source": [
    "## 2. Using Tracer to log more complex chains\n",
    "\n",
    "How can we get more creative outputs? Let's design an LLM chain that will first randomly pick a fantasy world, and then generate character names. We will demonstrate how to use Tracer in such scenario. You can also use our native integration with libraries like Langchain or Llamaindex instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fd404-51fd-44cf-b41e-b81dc589a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = [\n",
    "    \"a mystic medieval island inhabited by intelligent and funny frogs\",\n",
    "    \"a modern castle sitting on top of a volcano in a faraway galaxy\",\n",
    "    \"a digital world inhabited by friendly machine learning engineers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d366dca-db12-4532-a98d-5b29fa8a0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(worlds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1e20a-87a8-4386-9a8d-727db9569cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your conifg\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.7\n",
    "system_message = \"\"\"You are a creative copywriter. \n",
    "You're given a category of game asset, a fantasy world, and your goal is to design a name of that asset.\n",
    "Provide the resulting name only, no additional description.\n",
    "Single name, max 3 words output, remember!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86f95e-ed0d-4989-8c1d-5b88cdac7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_creative_chain(query):\n",
    "    # part 1 - a chain is started...\n",
    "    start_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "\n",
    "    root_span = Trace(\n",
    "          name=\"MyCreativeChain\",\n",
    "          kind=\"agent\",\n",
    "          start_time_ms=start_time_ms,\n",
    "          metadata={\"user\": \"student_1\"})\n",
    "\n",
    "    # part 2 - The chain calls into a child chain..\n",
    "    chain_span = Trace(\n",
    "          name=\"MyChain\",\n",
    "          kind=\"chain\",\n",
    "          start_time_ms=start_time_ms)\n",
    "\n",
    "    # add the Chain span as a child of the root\n",
    "    root_span.add_child(chain_span)\n",
    "\n",
    "    # part 3 - your chain picks a fantasy world\n",
    "    time.sleep(3)\n",
    "    world = random.choice(worlds)\n",
    "    expanded_prompt = f'Game asset category: {query}; fantasy world description: {world}'\n",
    "    tool_end_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "\n",
    "    # create a Tool span \n",
    "    tool_span = Trace(\n",
    "          name=\"WorldPicker\",\n",
    "          kind=\"tool\",\n",
    "          status_code=\"success\",\n",
    "          start_time_ms=start_time_ms,\n",
    "          end_time_ms=tool_end_time_ms,\n",
    "          inputs={\"input\": query},\n",
    "          outputs={\"result\": expanded_prompt})\n",
    "\n",
    "    # add the TOOL span as a child of the root\n",
    "    chain_span.add_child(tool_span)\n",
    "\n",
    "    # part 4 - the LLMChain calls an OpenAI LLM...\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": expanded_prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=model_name,\n",
    "                                            messages=messages,\n",
    "                                            temperature=temperature)   \n",
    "\n",
    "    llm_end_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "    response_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    token_usage = response[\"usage\"].to_dict()\n",
    "\n",
    "    llm_span = Trace(\n",
    "          name=\"OpenAI\",\n",
    "          kind=\"llm\",\n",
    "          status_code=\"success\",\n",
    "          metadata={\"temperature\":temperature,\n",
    "                    \"token_usage\": token_usage, \n",
    "                    \"model_name\":model_name},\n",
    "          start_time_ms=tool_end_time_ms,\n",
    "          end_time_ms=llm_end_time_ms,\n",
    "          inputs={\"system_prompt\":system_message, \"query\":expanded_prompt},\n",
    "          outputs={\"response\": response_text},\n",
    "          )\n",
    "\n",
    "    # add the LLM span as a child of the Chain span...\n",
    "    chain_span.add_child(llm_span)\n",
    "\n",
    "    # update the end time of the Chain span\n",
    "    chain_span.add_inputs_and_outputs(\n",
    "          inputs={\"query\":query},\n",
    "          outputs={\"response\": response_text})\n",
    "\n",
    "    # update the Chain span's end time\n",
    "    chain_span._span.end_time_ms = llm_end_time_ms\n",
    "\n",
    "    # part 5 - the final results from the tool are added \n",
    "    root_span.add_inputs_and_outputs(inputs={\"query\": query},\n",
    "                                     outputs={\"result\": response_text})\n",
    "    root_span._span.end_time_ms = llm_end_time_ms\n",
    "\n",
    "    # part 6 - log all spans to W&B by logging the root span\n",
    "    root_span.log(name=\"creative_trace\")\n",
    "    print(f\"Result: {response_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8500843-6d4b-4fc6-93b9-4cadf5813e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "run_creative_chain(\"hero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d7bf3-4ae1-4b57-8a96-a34ea0614ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_creative_chain(\"jewel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc075f-32bf-4451-b7ad-ab2a49cc86b6",
   "metadata": {},
   "source": [
    "## Langchain agent\n",
    "\n",
    "WIP: add langchain agent - adding names and evaluating if they are good. Wrap a previous function as a langchain tool. \n",
    "\n",
    "Demonstrate W&B Tracer autologging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de1fb0-3630-4673-8ac0-0dffe0a52071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7ab14-4335-4649-95b4-35fb8023af1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
