{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ba792c-2baa-4c19-a132-2ed82a759e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803c37e2-7ff5-46a6-afb7-b80cb69f7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login() # uncomment if you want to login to wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4aad93-5819-4304-afb5-d962ee3f5fed",
   "metadata": {},
   "source": [
    "We will be running the notebook on `anonymous` mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51a9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 3 * 16 * 16\n",
    "OUTPUT_SIZE = 5\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_WORKERS = 2\n",
    "CLASSES = [\"hero\", \"non-hero\", \"food\", \"spell\", \"side-facing\"]\n",
    "DATA_DIR = Path('./data/')\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")\n",
    "\n",
    "def get_model(dropout):\n",
    "    \"Simple MLP with Dropout\"\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
    "        nn.BatchNorm1d(HIDDEN_SIZE),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8401cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
    "    \"Compute the performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels) * labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i == batch_idx and log_images:\n",
    "                log_image_predictions_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "\n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)\n",
    "\n",
    "\n",
    "def log_image_predictions_table(images, predicted, labels, probs):\n",
    "    \"Create a wandb Table to log images, labels, and predictions\"\n",
    "    columns = [\"image\", \"pred\", \"target\"] + [f\"score_{i}\" for i in range(OUTPUT_SIZE)]\n",
    "    table = wandb.Table(columns=columns)\n",
    "    \n",
    "    for img, pred, targ, prob in zip(images.cpu(), predicted.cpu(), labels.cpu(), probs.cpu()):\n",
    "        table.add_data(wandb.Image(img), CLASSES[pred], CLASSES[targ], *prob.numpy())\n",
    "    \n",
    "    wandb.log({\"predictions_table\": table}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5492ebb-2dfa-44ce-af6c-24655e45a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"Train a model with a given config\"\n",
    "    wandb.init(\n",
    "        project=\"intro\",\n",
    "        config=config,\n",
    "        anonymous=\"allow\",\n",
    "    )\n",
    "\n",
    "    # Get the data\n",
    "    train_dl, valid_dl = get_dataloaders(DATA_DIR, \n",
    "                                         config.batch_size, \n",
    "                                         config.slice_size, \n",
    "                                         config.valid_pct)\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "    # A simple MLP model\n",
    "    model = get_model(config.dropout)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "    example_ct = 0\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs), total=config.epochs):\n",
    "        model.train()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            example_ct += len(images)\n",
    "            metrics = {\n",
    "                \"train/train_loss\": train_loss,\n",
    "                \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch))/n_steps_per_epoch,\n",
    "                \"train/example_ct\": example_ct\n",
    "            }\n",
    "            wandb.log(metrics)\n",
    "\n",
    "        # compute validation metrics, log images on last epoch\n",
    "        val_loss, accuracy = validate_model(model, valid_dl, loss_func, \n",
    "                                            log_images=(epoch == (config.epochs - 1)))\n",
    "\n",
    "        # Log train and validation metrics to wandb\n",
    "        val_metrics = {\n",
    "            \"val/val_loss\": val_loss,\n",
    "            \"val/val_accuracy\": accuracy\n",
    "        }\n",
    "        wandb.log({**metrics, **val_metrics})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f33f739c-d7ef-4954-ae87-d5bdd6bf25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    epochs = 3,\n",
    "    batch_size = 128,\n",
    "    lr = 1e-3,\n",
    "    dropout = 0.1,\n",
    "    slice_size = 10_000,\n",
    "    valid_pct = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9423c964-f7e3-4d3b-8a24-e70f7f4414c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lskq5lst) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c174ee7503f14722bee9a4d0db66a179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.062 MB of 0.062 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-salad-10</strong> at: <a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/lskq5lst' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro/runs/lskq5lst</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_091843-lskq5lst/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lskq5lst). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2250f5729b647df90ebc0b6830c5d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670081783331625, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/work/edu/dlai/wandb/run-20230707_091936-7ibfofq5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/7ibfofq5' target=\"_blank\">ruby-voice-11</a></strong> to <a href='https://wandb.ai/deeplearning-ai-temp/intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-ai-temp/intro' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/7ibfofq5' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro/runs/7ibfofq5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprite shape: (89400, 16, 16, 3)\n",
      "labels shape: (89400,)\n",
      "sprite shape: (10000, 16, 16, 3)\n",
      "labels shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a9448faca44d53b9ae82b2db4ba30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁██</td></tr><tr><td>val/val_loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/example_ct</td><td>24000</td></tr><tr><td>train/train_loss</td><td>0.00699</td></tr><tr><td>val/val_accuracy</td><td>1.0</td></tr><tr><td>val/val_loss</td><td>0.00692</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-voice-11</strong> at: <a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/7ibfofq5' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro/runs/7ibfofq5</a><br/>Synced 7 W&B file(s), 1 media file(s), 122 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_091936-7ibfofq5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9ecf01d",
   "metadata": {},
   "source": [
    "Let's try with another value of dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f40520a-66f8-4415-9e36-174dda06aca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264ff7030aa5490daaab7d7f573f268d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670244300000074, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/work/edu/dlai/wandb/run-20230707_092004-5pt6qfs9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/5pt6qfs9' target=\"_blank\">zesty-oath-12</a></strong> to <a href='https://wandb.ai/deeplearning-ai-temp/intro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-ai-temp/intro' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/5pt6qfs9' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro/runs/5pt6qfs9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprite shape: (89400, 16, 16, 3)\n",
      "labels shape: (89400,)\n",
      "sprite shape: (10000, 16, 16, 3)\n",
      "labels shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d2c401c89f4eb797175dff9ddbf7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/example_ct</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/train_loss</td><td>█▅▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/val_accuracy</td><td>▁▆█</td></tr><tr><td>val/val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/example_ct</td><td>24000</td></tr><tr><td>train/train_loss</td><td>0.01679</td></tr><tr><td>val/val_accuracy</td><td>1.0</td></tr><tr><td>val/val_loss</td><td>0.00977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-oath-12</strong> at: <a href='https://wandb.ai/deeplearning-ai-temp/intro/runs/5pt6qfs9' target=\"_blank\">https://wandb.ai/deeplearning-ai-temp/intro/runs/5pt6qfs9</a><br/>Synced 7 W&B file(s), 1 media file(s), 124 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_092004-5pt6qfs9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.dropout = 0.5\n",
    "train_model(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
