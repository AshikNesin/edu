{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with a Tool Use approach\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wandb/edu/blob/main/rag-advanced/notebooks/rag_tooluse/rag_tooluse_v1.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "<!--- @wandbcode{rag-course-05-cohere} -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool use allows for greater flexibility in accessing and utilizing data sources, thus unlocking new use cases not possible with a standard RAG approach.\n",
    "\n",
    "In an enterprise setting where data sources are diverse with non-homogeneous formats (structured/semi-structured/unstructured), this approach becomes even more important.\n",
    "\n",
    "In this notebook, we'll look at how we can implement an agentic RAG system using a tool use approach. We'll do this by building a Weights & Biases assistant. The assistant can search for information about how to use the product, retrieve information from the internet, search code examples, and even perform data analysis.\n",
    "\n",
    "Concretely, we'll cover the following use cases:\n",
    "1. Tool routing\n",
    "2. Parallel tool use\n",
    "3. Multi-step tool use\n",
    "4. Self-correction\n",
    "5. Structured queries\n",
    "6. Structured data queries\n",
    "7. Action (plotting charts)\n",
    "\n",
    "We'll give the assistant access to the following tools:\n",
    "- `search_developer_docs`: Searches the Weights & Biases developer documentation\n",
    "- `search_internet`: Searches the internet for general queries\n",
    "- `search_code_examples`: Searches code examples and tutorials on using Weights & Biases\n",
    "- `analyze_evaluation_results`: Analyzes a table containing results from evaluating an LLM application\n",
    "\n",
    "Note that for simplicity, we are not implementing a full-fledge search. Instead, we'll use a mock datasets containing small, pre-defined data for each tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(\"COHERE_API_KEY\") # Get your free API key: https://dashboard.cohere.com/api-keys\"\n",
    "\n",
    "from tool_def_v1 import (\n",
    "    search_developer_docs,\n",
    "    search_internet,\n",
    "    search_code_examples,\n",
    "    analyze_evaluation_results,\n",
    "    search_tools,\n",
    "    analysis_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_map = {\n",
    "    \"search_developer_docs\": search_developer_docs,\n",
    "    \"search_internet\": search_internet,\n",
    "    \"search_code_examples\": search_code_examples,\n",
    "    \"analyze_evaluation_results\": analyze_evaluation_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble=\"\"\"## Task and Context\n",
    "You are an assistant who helps developers use Weights & Biases. The company is also referred to as Wandb or W&B for short. You are equipped with a number of tools that can provide different types of information. If you can't find the information you need from one tool, you should try other tools if there is a possibility that they could provide the information you need. Use the internet to search for information not available in the sources provided by Weights & Biases\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"command-r-plus-08-2024\"\n",
    "\n",
    "def run_agent(message, tools, chat_history=None):\n",
    "    \n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    # Step 1: Get user message\n",
    "    print(f\"Question:\\n{message}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Step 2: Generate tool calls (if any)    \n",
    "    response = co.chat(\n",
    "        message=message,\n",
    "        model=model,\n",
    "        preamble=preamble,\n",
    "        tools= tools,\n",
    "        chat_history=chat_history,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    while response.tool_calls:\n",
    "        tool_calls = response.tool_calls\n",
    "        \n",
    "        if response.text:\n",
    "            print(\"Tool plan:\")\n",
    "            print(response.text,\"\\n\")\n",
    "        print(\"Tool calls:\")\n",
    "        for call in tool_calls:            \n",
    "            ###############\n",
    "            if call.name == \"analyze_evaluation_results\":\n",
    "                print(f\"Tool name: {call.name}\")\n",
    "                print(f\"Code:\\n\")\n",
    "                tool_call_prettified = print(\"\\n\".join(f\"  {line}\" for line_num, line in enumerate(call.parameters[\"code\"].splitlines())))\n",
    "                print(tool_call_prettified)\n",
    "            else:\n",
    "                print(f\"Tool name: {call.name} | Parameters: {call.parameters}\")\n",
    "            ###############\n",
    "            \n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Step 3: Get tool results\n",
    "        tool_results = []\n",
    "        for tc in tool_calls:\n",
    "            tool_call = {\"name\": tc.name, \"parameters\": tc.parameters}\n",
    "            tool_output = functions_map[tc.name](**tc.parameters)\n",
    "            tool_results.append({\"call\": tool_call, \"outputs\": [tool_output]})\n",
    "        \n",
    "        # Step 4: Generate response and citations                \n",
    "        response = co.chat(\n",
    "            message=\"\",\n",
    "            model=model,\n",
    "            preamble=preamble,\n",
    "            tools=tools,\n",
    "            tool_results=tool_results,\n",
    "            chat_history=response.chat_history,\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "        # Append the current chat turn to the chat history\n",
    "        chat_history = response.chat_history\n",
    "        \n",
    "    # Print final response\n",
    "    print(\"Final response:\")\n",
    "    print(response.text)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Print citations (if any)\n",
    "    show_documents = False # set this to True to see the documents used for the response\n",
    "    if response.citations:\n",
    "        print(\"Citations:\")\n",
    "        for citation in response.citations:\n",
    "            print(citation)\n",
    "        if show_documents:\n",
    "            print(\"\\nCited Documents:\")\n",
    "            for document in response.documents:\n",
    "                print(document)\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Tool routing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tool routing, the agent decides which tool(s) to use based on the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Where can I find the output of a run\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will search for 'where to find output of a run' in the developer documentation. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_developer_docs | Parameters: {'query': 'where to find output of a run'}\n",
      "==================================================\n",
      "Final response:\n",
      "To view a run, navigate to the W&B App UI, select the relevant project, and then choose the run from the 'Runs' table.\n",
      "==================================================\n",
      "Citations:\n",
      "start=15 end=118 text=\"navigate to the W&B App UI, select the relevant project, and then choose the run from the 'Runs' table.\" document_ids=['search_developer_docs:0:2:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Where can I find the output of a run\", search_tools)\n",
    "# chooses search_developer_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Who are the co authors of the sentence transformer paper?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will search for the sentence transformer paper. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_internet | Parameters: {'query': 'sentence transformer paper'}\n",
      "==================================================\n",
      "Tool plan:\n",
      "I found a paper called 'Sentence Embeddings using Siamese BERT-Networks'. I will now search for the co-authors of this paper. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_internet | Parameters: {'query': 'co-authors of Sentence Embeddings using Siamese BERT-Networks'}\n",
      "==================================================\n",
      "Final response:\n",
      "The co-authors of the paper 'Sentence Embeddings using Siamese BERT-Networks' are Nils Reimers and Iryna Gurevych.\n",
      "==================================================\n",
      "Citations:\n",
      "start=28 end=77 text=\"'Sentence Embeddings using Siamese BERT-Networks'\" document_ids=['search_internet:0:2:0']\n",
      "start=82 end=86 text='Nils' document_ids=['search_internet:0:2:0']\n",
      "start=87 end=94 text='Reimers' document_ids=['search_internet:0:2:0', 'search_internet:0:4:0']\n",
      "start=99 end=104 text='Iryna' document_ids=['search_internet:0:4:0']\n",
      "start=105 end=114 text='Gurevych.' document_ids=['search_internet:0:4:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Who are the co authors of the sentence transformer paper?\", search_tools)\n",
    "# chooses search_internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Parallel tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent can call multiple tools in parallel. In this example, given that the user is asking about two different things in a single message, the agent generates two parallel tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Explain what is a W&B Run and how do I view a specific run\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will search for 'W&B Run' and 'view a specific run' in the developer documentation. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_developer_docs | Parameters: {'query': 'W&B Run'}\n",
      "Tool name: search_developer_docs | Parameters: {'query': 'view a specific run'}\n",
      "==================================================\n",
      "Final response:\n",
      "A W&B Run is a single unit of computation logged by W&B, representing an atomic element of your project.\n",
      "\n",
      "To view a specific run, navigate to the W&B App UI, select the relevant project, and then choose the run from the 'Runs' table.\n",
      "==================================================\n",
      "Citations:\n",
      "start=15 end=104 text='single unit of computation logged by W&B, representing an atomic element of your project.' document_ids=['search_developer_docs:0:2:0', 'search_developer_docs:1:2:0']\n",
      "start=130 end=233 text=\"navigate to the W&B App UI, select the relevant project, and then choose the run from the 'Runs' table.\" document_ids=['search_developer_docs:0:2:0', 'search_developer_docs:1:2:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Explain what is a W&B Run and how do I view a specific run\", search_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Multi-step tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be scenarios where tool calling needs to happen in a sequence. For example, when the output of one tool call is needed as input for another tool call.\n",
    "\n",
    "In this example, the agent first searches the developer docs for information about how to view a run. Then, it uses the information to search for a code example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What's that feature to automate hyperparameter search? Do you have some code tutorials?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will search for the feature to automate hyperparameter search. Then, I will search for code tutorials for this feature. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_developer_docs | Parameters: {'query': 'feature to automate hyperparameter search'}\n",
      "==================================================\n",
      "Tool plan:\n",
      "I have found that the feature to automate hyperparameter search is called W&B Sweeps. I will now search for code tutorials for W&B Sweeps. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_code_examples | Parameters: {'file_type': None, 'language': None, 'query': 'W&B Sweeps'}\n",
      "==================================================\n",
      "Final response:\n",
      "The feature to automate hyperparameter search is called W&B Sweeps. You can use W&B Sweeps to automate hyperparameter search and visualise rich, interactive experiment tracking.\n",
      "\n",
      "Here are some code tutorials for W&B Sweeps:\n",
      "- Selecting Hyperparameters with Sweeps (Keras)\n",
      "- Create a hyperparameter search with W&B PyTorch integration\n",
      "==================================================\n",
      "Citations:\n",
      "start=56 end=67 text='W&B Sweeps.' document_ids=['search_developer_docs:0:2:0']\n",
      "start=94 end=177 text='automate hyperparameter search and visualise rich, interactive experiment tracking.' document_ids=['search_developer_docs:0:2:0']\n",
      "start=226 end=271 text='Selecting Hyperparameters with Sweeps (Keras)' document_ids=['search_code_examples:0:4:0']\n",
      "start=274 end=333 text='Create a hyperparameter search with W&B PyTorch integration' document_ids=['search_code_examples:0:4:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "chat_history = run_agent(\"What's that feature to automate hyperparameter search? Do you have some code tutorials?\", search_tools)\n",
    "# Does two steps of tool use in a sequence\n",
    "# Returns code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Self-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of multi-step tool use can be extended to self-correction. Given the output of the current tool call, the agent may decide to change its plan i.e. self-correct. \n",
    "\n",
    "In this example, the agent doesn't find the information it's looking for in the developer docs. Thus, it generates a new tool call to search the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What is Wandb's weave solution?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will search for 'Wandb's weave solution' to find the answer. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_developer_docs | Parameters: {'query': \"Wandb's weave solution\"}\n",
      "==================================================\n",
      "Tool plan:\n",
      "I could not find any information about Wandb's weave solution. I will now search the internet for 'Wandb's weave solution' to find the answer. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_internet | Parameters: {'query': \"Wandb's weave solution\"}\n",
      "==================================================\n",
      "Final response:\n",
      "Weights & Biases Weave is a lightweight toolkit for software developers who want to deploy generative AI applications with confidence. It provides software developers with a system of record for the experimental large language model (LLM).\n",
      "\n",
      "Weave automatically captures all input and output data and builds a tree to help you understand how data flows through your application. It is designed with the developer experience in mind, providing capabilities for straightforward evaluation and debugging of GenAI applications.\n",
      "==================================================\n",
      "Citations:\n",
      "start=0 end=134 text='Weights & Biases Weave is a lightweight toolkit for software developers who want to deploy generative AI applications with confidence.' document_ids=['search_internet:0:4:0']\n",
      "start=174 end=238 text='system of record for the experimental large language model (LLM)' document_ids=['search_internet:0:4:0']\n",
      "start=247 end=377 text='automatically captures all input and output data and builds a tree to help you understand how data flows through your application.' document_ids=['search_internet:0:4:0']\n",
      "start=384 end=522 text='designed with the developer experience in mind, providing capabilities for straightforward evaluation and debugging of GenAI applications.' document_ids=['search_internet:0:4:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"What is Wandb's weave solution?\", search_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Structured queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool use setup can be leveraged to perform structured queries. For data sources that contain rich metadata, structured queries can be used to perform highly-specific queries, returning more accurate results.\n",
    "\n",
    "In this example, we can take advantage of metadata available in the code examples dataset such as the file type and language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Any jupyter notebook for Data Versioning with Artifacts?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will search for a Jupyter notebook for Data Versioning with Artifacts. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: search_code_examples | Parameters: {'file_type': 'ipynb', 'language': 'en', 'query': 'Data Versioning with Artifacts'}\n",
      "==================================================\n",
      "Final response:\n",
      "Yes, there is a Jupyter notebook for Data Versioning with Artifacts (PyTorch).\n",
      "==================================================\n",
      "Citations:\n",
      "start=16 end=77 text='Jupyter notebook for Data Versioning with Artifacts (PyTorch)' document_ids=['search_code_examples:0:2:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Any jupyter notebook for Data Versioning with Artifacts?\", search_tools)\n",
    "# Tool call: Searches search_code_examples with file_type = ipynb\n",
    "# Answer: Returns file - Model/Data Versioning with Artifacts (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Structured data queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent can generate queries against structured data sources, such as a CSV file or a database.\n",
    "\n",
    "In this example, we'll use a mock dataset containing LLM application evaluation results for different use cases and settings. Since it's a CSV file, we can create the `analyze_evaluation_results` tool to perform queries on the dataset using the pandas library, executed by a Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What's the average evaluation score in run A\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will use the 'analyze_evaluation_results' tool to find the average evaluation score in run A. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: analyze_evaluation_results\n",
      "Code:\n",
      "\n",
      "  import pandas as pd\n",
      "  \n",
      "  df = pd.read_csv(\"evaluation_results.csv\")\n",
      "  \n",
      "  # Filter the dataframe to only include rows where the 'run' column is 'A'\n",
      "  filtered_df = df[df['run'] == 'A']\n",
      "  \n",
      "  # Calculate the average 'score' for the filtered dataframe\n",
      "  average_score = filtered_df['score'].mean()\n",
      "  \n",
      "  print(f\"Average score in run A: {average_score}\")\n",
      "None\n",
      "==================================================\n",
      "Final response:\n",
      "The average evaluation score in run A is **0.63**.\n",
      "==================================================\n",
      "Citations:\n",
      "start=43 end=47 text='0.63' document_ids=['analyze_evaluation_results:0:2:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"What's the average evaluation score in run A\", analysis_tool)\n",
    "# Answer: 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What's the latency of the highest-scoring run for the summarize_article use case?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will use the analyze_evaluation_results tool to find the latency of the highest-scoring run for the summarize_article use case. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: analyze_evaluation_results\n",
      "Code:\n",
      "\n",
      "  import pandas as pd\n",
      "  \n",
      "  df = pd.read_csv(\"evaluation_results.csv\")\n",
      "  \n",
      "  # Filter for the summarize_article use case\n",
      "  filtered_df = df[df[\"usecase\"] == \"summarize_article\"]\n",
      "  \n",
      "  # Find the highest-scoring run\n",
      "  highest_score_run = filtered_df.loc[filtered_df[\"score\"].idxmax()]\n",
      "  \n",
      "  # Print the latency of the highest-scoring run\n",
      "  print(f\"The latency of the highest-scoring run for the summarize_article use case is {highest_score_run['latency']} seconds.\")\n",
      "None\n",
      "==================================================\n",
      "Final response:\n",
      "The latency of the highest-scoring run for the summarize_article use case is 4.8 seconds.\n",
      "==================================================\n",
      "Citations:\n",
      "start=77 end=89 text='4.8 seconds.' document_ids=['analyze_evaluation_results:0:2:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"What's the latency of the highest-scoring run for the summarize_article use case?\", analysis_tool)\n",
    "# Answer: 4.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which use case uses the least amount of tokens on average and what's the average token count?\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will use the 'analyze_evaluation_results' tool to find the use case that uses the least amount of tokens on average and the average token count. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: analyze_evaluation_results\n",
      "Code:\n",
      "\n",
      "  import pandas as pd\n",
      "  \n",
      "  df = pd.read_csv(\"evaluation_results.csv\")\n",
      "  \n",
      "  # Calculate the average number of tokens for each use case\n",
      "  average_tokens_per_usecase = df.groupby(\"usecase\")[\"tokens\"].mean()\n",
      "  \n",
      "  # Find the use case with the lowest average token count\n",
      "  min_tokens_usecase = average_tokens_per_usecase.idxmin()\n",
      "  min_tokens_count = average_tokens_per_usecase.min()\n",
      "  \n",
      "  print(f\"Use case with the lowest average token count: {min_tokens_usecase}\")\n",
      "  print(f\"Average token count for this use case: {min_tokens_count}\")\n",
      "None\n",
      "==================================================\n",
      "Final response:\n",
      "The use case with the lowest average token count is `extract_names`, with an average token count of 106.25.\n",
      "==================================================\n",
      "Citations:\n",
      "start=52 end=66 text='`extract_names' document_ids=['analyze_evaluation_results:0:2:0']\n",
      "start=100 end=107 text='106.25.' document_ids=['analyze_evaluation_results:0:2:0']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Which use case uses the least amount of tokens on average and what's the average token count?\", analysis_tool)\n",
    "# Answer: extract_names (106.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Action (plotting charts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have access to the Python interpreter, we can also use it to perform other tasks such as plotting charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Show a chart of the average evaluation score for each temperature setting for the extract_names use case.\n",
      "==================================================\n",
      "Tool plan:\n",
      "I will write Python code to generate a chart of the average evaluation score for each temperature setting for the extract_names use case. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: analyze_evaluation_results\n",
      "Code:\n",
      "\n",
      "  import pandas as pd\n",
      "  \n",
      "  df = pd.read_csv(\"evaluation_results.csv\")\n",
      "  \n",
      "  # Filter the dataframe to only include rows for the extract_names use case\n",
      "  filtered_df = df[df[\"usecase\"] == \"extract_names\"]\n",
      "  \n",
      "  # Group the dataframe by temperature and calculate the average score\n",
      "  average_scores = filtered_df.groupby(\"temperature\")[\"score\"].mean()\n",
      "  \n",
      "  # Plot the average scores\n",
      "  ax = average_scores.plot(kind=\"bar\")\n",
      "  ax.set_xlabel(\"Temperature\")\n",
      "  ax.set_ylabel(\"Average Score\")\n",
      "  \n",
      "  # Rotate x-axis labels for better readability\n",
      "  ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
      "  \n",
      "  # Save the plot as a PNG file\n",
      "  ax.figure.savefig(\"average_scores.png\")\n",
      "None\n",
      "==================================================\n",
      "Final response:\n",
      "Here is a chart of the average evaluation score for each temperature setting for the extract_names use case:\n",
      "\n",
      "![Average Evaluation Scores](\"average_scores.png\")\n",
      "==================================================\n",
      "Citations:\n",
      "start=110 end=160 text='![Average Evaluation Scores](\"average_scores.png\")' document_ids=['analyze_evaluation_results:0:2:0']\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = run_agent(\"Show a chart of the average evaluation score for each temperature setting for the extract_names use case.\", analysis_tool)\n",
    "# Answer: temp 0.3 (0.46 avg score) vs temp 0.5 (0.7 avg score). And draws a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook demonstrates how we can implement an agentic RAG system with tool use.\n",
    "\n",
    "We covered the following use cases:\n",
    "1. Tool routing\n",
    "2. Parallel tool use\n",
    "3. Multi-step tool use\n",
    "4. Self-correction\n",
    "5. Structured queries\n",
    "6. Structured data queries\n",
    "7. Action (plotting charts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
