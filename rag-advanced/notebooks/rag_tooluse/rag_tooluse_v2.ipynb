{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG with Tool Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool use allows for greater flexibility in accessing and utilizing data sources, thus unlocking new use cases not possible with a standard RAG approach.\n",
    "\n",
    "In an enterprise setting where data sources are diverse with non-homogeneous formats (structured/semi-structured/unstructured), this approach becomes even more important.\n",
    "\n",
    "In this notebook, we'll look at how we can implement an agentic RAG system using a tool use approach. We'll do this by building a Weights & Biases assistant. The assistant can search for information about how to use the product, retrieve information from the internet, search code examples, and even perform data analysis.\n",
    "\n",
    "Concretely, we'll cover the following use cases:\n",
    "1. Tool routing\n",
    "2. Parallel tool use\n",
    "3. Multi-step tool use\n",
    "4. Self-correction\n",
    "5. Structured queries\n",
    "6. Structured data queries\n",
    "\n",
    "We'll give the assistant access to the following tools:\n",
    "- `search_developer_docs`: Searches the Weights & Biases developer documentation\n",
    "- `search_internet`: Searches the internet for general queries\n",
    "- `search_code_examples`: Searches code examples and tutorials on using Weights & Biases\n",
    "- `analyze_evaluation_results`: Analyzes a table containing results from evaluating an LLM application\n",
    "\n",
    "Note that for simplicity, we are not implementing a full-fledge search. Instead, we'll use a mock datasets containing small, pre-defined data for each tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "To get started, first we need to install the `cohere` library and create a Cohere client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cohere\n",
    "from tool_def_v2 import (\n",
    "    analysis_tool,\n",
    "    analyze_evaluation_results,\n",
    "    search_code_examples,\n",
    "    search_developer_docs,\n",
    "    search_internet,\n",
    "    search_tools,\n",
    ")\n",
    "\n",
    "co = cohere.ClientV2(\n",
    "    api_key=os.environ[\"COHERE_API_KEY\"]\n",
    ")  # Get your free API key: https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U cohere pandas -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an agentic RAG system, each data source is represented as a \"tool\". A tool is broadly any function or service that can receive and send objects to the LLM. But in the case of RAG, this becomes a more specific case of a tool that takes a query as input and return a set of documents.\n",
    "\n",
    "Here, we are defining a Python function for each tool, but more broadly, the tool can be any function or service that can receive and send objects. \n",
    "\n",
    "Note: refer to the `tool_def_v2.py` file for the implementation of each tool.\n",
    "\n",
    "These functions are mapped to a dictionary called functions_map for easy access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_map = {\n",
    "    \"search_developer_docs\": search_developer_docs,\n",
    "    \"search_internet\": search_internet,\n",
    "    \"search_code_examples\": search_code_examples,\n",
    "    \"analyze_evaluation_results\": analyze_evaluation_results,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an agentic RAG workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run an agentic RAG workflow using a tool use approach. We can think of the system as consisting of four components:\n",
    "- The user\n",
    "- The application\n",
    "- The LLM\n",
    "- The tools\n",
    "\n",
    "At its most basic, these four components interact in a workflow through four steps:\n",
    "- **Step 1: Get user message** – The LLM gets the user message (via the application)\n",
    "- **Step 2: Tool planning and calling** – The LLM makes a decision on the tools to call (if any) and generates - the tool calls\n",
    "- **Step 3: Tool execution** - The application executes the tools and the results are sent to the LLM\n",
    "- **Step 4: Response and citation generation** – The LLM generates the response and citations to back to the user\n",
    "\n",
    "We wrap all these steps in a function called `run_agent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"## Task and Context\n",
    "You are an assistant who helps developers use Weights & Biases. The company is also referred to as Wandb or W&B for short. You are equipped with a number of tools that can provide different types of information. If you can't find the information you need from one tool, you should try other tools if there is a possibility that they could provide the information you need. Use the internet to search for information not available in the sources provided by Weights & Biases\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"command-r-08-2024\"\n",
    "\n",
    "\n",
    "def run_agent(query, tools, messages=None):\n",
    "    if messages is None:\n",
    "        messages = []\n",
    "\n",
    "    if \"system\" not in {m.get(\"role\") for m in messages}:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    # Step 1: get user message\n",
    "    print(f\"Question:\\n{query}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "\n",
    "    # Step 2: Generate tool calls (if any)\n",
    "    response = co.chat(model=model, messages=messages, tools=tools, temperature=0.1)\n",
    "\n",
    "    while response.message.tool_calls:\n",
    "        print(\"Tool plan:\")\n",
    "        print(response.message.tool_plan, \"\\n\")\n",
    "        print(\"Tool calls:\")\n",
    "        for tc in response.message.tool_calls:\n",
    "            if tc.function.name == \"analyze_evaluation_results\":\n",
    "                print(f\"Tool name: {tc.function.name}\")\n",
    "                tool_call_prettified = print(\n",
    "                    \"\\n\".join(\n",
    "                        f\"  {line}\"\n",
    "                        for line_num, line in enumerate(\n",
    "                            json.loads(tc.function.arguments)[\"code\"].splitlines()\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                print(tool_call_prettified)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\"\n",
    "                )\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": response.message.tool_calls,\n",
    "                \"tool_plan\": response.message.tool_plan,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Step 3: Get tool results\n",
    "        tool_content = []\n",
    "        for idx, tc in enumerate(response.message.tool_calls):\n",
    "            tool_result = functions_map[tc.function.name](\n",
    "                **json.loads(tc.function.arguments)\n",
    "            )\n",
    "            tool_content.append(json.dumps(tool_result))\n",
    "            messages.append(\n",
    "                {\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": tool_content}\n",
    "            )\n",
    "\n",
    "        # Step 4: Generate response and citations\n",
    "        response = co.chat(model=model, messages=messages, tools=tools, temperature=0.1)\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.message.content[0].text})\n",
    "\n",
    "    # Print final response\n",
    "    print(\"Response:\")\n",
    "    print(response.message.content[0].text)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Print citations (if any)\n",
    "    if response.message.citations:\n",
    "        print(\"\\nCITATIONS:\")\n",
    "        for citation in response.message.citations:\n",
    "            print(citation, \"\\n\")\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Tool routing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tool routing, the agent decides which tool(s) to use based on the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\"Where can I find the output of a run\", search_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\"Who are the authors of the sentence BERT paper?\", search_tools)\n",
    "# chooses search_internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Parallel tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent can call multiple tools in parallel. In this example, given that the user is asking about two different things in a single message, the agent generates two parallel tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\n",
    "    \"Explain what is a W&B Run and how do I view a specific run\", search_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Multi-step tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be scenarios where tool calling needs to happen in a sequence. For example, when the output of one tool call is needed as input for another tool call.\n",
    "\n",
    "In this example, the agent first searches the developer docs for information about how to view a run. Then, it uses the information to search for a code example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = run_agent(\n",
    "    \"What's that feature to automate hyperparameter search? Do you have some code tutorials?\",\n",
    "    search_tools,\n",
    ")\n",
    "# Does two steps of tool use in a sequence\n",
    "# Returns code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Self-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of multi-step tool use can be extended to self-correction. Given the output of the current tool call, the agent may decide to change its plan i.e. self-correct. \n",
    "\n",
    "In this example, the agent doesn't find the information it's looking for in the developer docs. Thus, it generates a new tool call to search the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\"What is Wandb's weave solution?\", search_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Structured queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool use setup can be leveraged to perform structured queries. For data sources that contain rich metadata, structured queries can be used to perform highly-specific queries, returning more accurate results.\n",
    "\n",
    "In this example, we can take advantage of metadata available in the code examples dataset such as the file type and language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\n",
    "    \"Any jupyter notebook for Data Versioning with Artifacts?\", search_tools\n",
    ")\n",
    "# Tool call: Searches search_code_examples with file_type = ipynb\n",
    "# Answer: Returns file - Model/Data Versioning with Artifacts (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Structured data queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent can generate queries against structured data sources, such as a CSV file or a database.\n",
    "\n",
    "In this example, we'll use a mock dataset containing LLM application evaluation results for different use cases and settings. Since it's a CSV file, we can create the `analyze_evaluation_results` tool to perform queries on the dataset using the pandas library, executed by a Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\"What's the average evaluation score in run A\", analysis_tool)\n",
    "# Answer: 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\n",
    "    \"What's the latency of the highest-scoring run for the summarize_article use case?\",\n",
    "    analysis_tool,\n",
    ")\n",
    "# Answer: 4.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = run_agent(\n",
    "    \"Which use case uses the least amount of tokens on average and what's the average token count?\",\n",
    "    analysis_tool,\n",
    ")\n",
    "# Answer: extract_names (106.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook demonstrates how we can implement an agentic RAG system with tool use.\n",
    "\n",
    "We covered the following use cases:\n",
    "1. Tool routing\n",
    "2. Parallel tool use\n",
    "3. Multi-step tool use\n",
    "4. Self-correction\n",
    "5. Structured queries\n",
    "6. Structured data queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
