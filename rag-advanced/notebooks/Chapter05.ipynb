{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5\n",
    "\n",
    "## Retrieval and Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "\n",
    "import wandb\n",
    "import weave\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mparambharat\u001b[0m (\u001b[33mrag-course\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/mugan/data/wandb/projects/edu/rag-advanced/notebooks/wandb/run-20240724_143748-mhmzzi2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rag-course/dev/runs/mhmzzi2w' target=\"_blank\">absurd-disco-95</a></strong> to <a href='https://wandb.ai/rag-course/dev' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rag-course/dev' target=\"_blank\">https://wandb.ai/rag-course/dev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rag-course/dev/runs/mhmzzi2w' target=\"_blank\">https://wandb.ai/rag-course/dev/runs/mhmzzi2w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: parambharat.\n",
      "View Weave data at https://wandb.ai/rag-course/dev/weave\n"
     ]
    }
   ],
   "source": [
    "WANDB_ENTITY = \"rag-course\"\n",
    "WANDB_PROJECT = \"dev\"\n",
    "\n",
    "wandb.require(\"core\")\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=WANDB_ENTITY,\n",
    "    project=WANDB_PROJECT,\n",
    "    group=\"Chapter 5\",\n",
    ")\n",
    "\n",
    "weave_client = weave.init(f\"{WANDB_ENTITY}/{WANDB_PROJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/24 14:37:51 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/rag-course/dev/j8uh2i2o/artifact/961260984/wandb_manifest.json?Expires=1721815671&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=L85mt%2BfEZ%2BQPimMZhhCXZ4cPBM8Owf8Wc5hFs%2BZFrAj29XqKF%2BmXyxKELLhYH46QYBoGnSwCjIdjtW4RLNNj9R0p3%2Flx2hEb%2FRPuyI0NYLvTBOWKUWH%2FlpzgFXzSCgA0ZCupQBWk%2F3dqtDwHZ3wMJNY0VZhsch07aKf8z4iznaqB858KKRHg7BwwqAJvhuYjBoVRunut0k3ybxPxvchQmLFPDFB%2FJ2B%2BaC%2B19wt27b%2FV7xLkl%2FCOTE1YZ3e9GeeFVX1JYuCLrpvt2iz%2Fbb%2Feo37zxx6CSiSYWJ4WCDll3gPTK3vjuLPkBb11nqLuhXl0K26BXbAkM8K7acVL%2Bllt5w%3D%3D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cleaned_content': 'Anonymous Mode Are you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first. Allow results to be logged in Anonymous Mode with wandb.init(anonymous=\"allow\") :::info Publishing a paper? Please cite W&B, and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n::: How does someone without an account see results? If someone runs your script and you have to set anonymous=\"allow\":  Auto-create temporary account: W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session. Log results quickly: The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI.\\nThese unclaimed anonymous runs will be available for 7 days. Claim data when it\\'s useful: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.  :::caution Anonymous run links are sensitive. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n::: What happens to users with existing accounts? If you set anonymous=\"allow\" in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\nWhat are features that aren\\'t available to anonymous users? No persistent data: Runs are only saved for 7 days in an anonymous account.\\nUsers can claim anonymous run data by saving it to a real account.',\n",
       "  'metadata': {'source': 'guides/app/features/anon.md', 'parsed_tokens': 468}},\n",
       " {'cleaned_content': \"No artifact logging: Runs will print a warning on the command line that you can't log an artifact to an anonymous run. No profile or settings pages: Certain pages aren't available in the UI, because they're only useful for real accounts.\",\n",
       "  'metadata': {'source': 'guides/app/features/anon.md', 'parsed_tokens': 49}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the data from Chapter 3\n",
    "chunked_artifact = run.use_artifact(\n",
    "    f\"{WANDB_ENTITY}/{WANDB_PROJECT}/chunked_data:latest\", type=\"dataset\"\n",
    ")\n",
    "artifact_dir = chunked_artifact.download()\n",
    "chunked_data_file = pathlib.Path(f\"{artifact_dir}/documents.jsonl\")\n",
    "chunked_data = list(map(json.loads, chunked_data_file.read_text().splitlines()))\n",
    "chunked_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll imporve the retriever by using dense retrieval using cohere embeddings.\n",
    "# We'll also use a reranker to improve the quality of the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">DenseRetriever</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Model):</span><span style=\"background-color: #272822\">                                                                            </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    vectorizer: Callable </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> sync_embed</span><span style=\"background-color: #272822\">                                                                         </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    index: np</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ndarray </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"background-color: #272822\">                                                                                  </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    data: list </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">index_data</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, data):</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">data </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> data</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        docs </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [doc[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"cleaned_content\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">] </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> doc </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> data]</span><span style=\"background-color: #272822\">                                                       </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        embeddings </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">vectorizer(docs)</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">index </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> np</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">array(embeddings)</span><span style=\"background-color: #272822\">                                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">op()</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">search</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, query, k</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">5</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">):</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        query_embedding </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">vectorizer([query], input_type</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"search_query\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        cosine_distances </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> cdist(query_embedding, self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">index, metric</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"cosine\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        top_k_indices </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> cosine_distances</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">argsort()[:k]</span><span style=\"background-color: #272822\">                                                        </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        output </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> []</span><span style=\"background-color: #272822\">                                                                                           </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> idx </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_k_indices:</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            output</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">append(</span><span style=\"background-color: #272822\">                                                                                    </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                {</span><span style=\"background-color: #272822\">                                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"source\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">data[idx][</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"metadata\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">][</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"source\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">],</span><span style=\"background-color: #272822\">                                           </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">22 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"text\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">data[idx][</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"cleaned_content\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">],</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">23 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"score\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> cosine_distances[idx],</span><span style=\"background-color: #272822\">                                                       </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">24 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                }</span><span style=\"background-color: #272822\">                                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">25 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            )</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">26 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> output</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">27 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">28 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">op()</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">29 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">predict</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, query: str, k: int):</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">30 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">search(query, k)</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">31 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mDenseRetriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mModel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvectorizer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mCallable\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msync_embed\u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mindex\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mndarray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlist\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mindex_data\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcleaned_content\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34membeddings\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvectorizer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mindex\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34marray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34membeddings\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m@weave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mop\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34msearch\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mk\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m5\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_embedding\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvectorizer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minput_type\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34msearch_query\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcosine_distances\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcdist\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery_embedding\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mindex\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmetric\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcosine\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k_indices\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcosine_distances\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margsort\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mk\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutput\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34midx\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k_indices\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutput\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mappend\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34msource\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34midx\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mmetadata\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34msource\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m22 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtext\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34midx\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcleaned_content\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m23 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mscore\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcosine_distances\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34midx\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m24 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m25 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m26 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutput\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m27 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m28 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m@weave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mop\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m29 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mpredict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstr\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mk\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m30 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msearch\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mk\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m31 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">CohereReranker</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Model):</span><span style=\"background-color: #272822\">                                                                            </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    model: str </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"rerank-english-v3.0\"</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">op()</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">rerank</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, query, docs, top_n</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">):</span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        client </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> cohere</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Client(os</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">environ[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"CO_API_KEY\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        documents </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [doc[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"text\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">] </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> doc </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> docs]</span><span style=\"background-color: #272822\">                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        response </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> client</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">rerank(</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            model</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">model, query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">query, documents</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">documents, top_n</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">top_n </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">or</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> len(docs)</span><span style=\"background-color: #272822\">                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        )</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        outputs </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> []</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> doc </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> response</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">results:</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            reranked_doc </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> docs[doc</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">index]</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            reranked_doc[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"relevance_score\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">] </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> doc</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">relevance_score</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            outputs</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">append(reranked_doc)</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> outputs[:top_n]</span><span style=\"background-color: #272822\">                                                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">op()</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">predict</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, query, docs, top_n</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">):</span><span style=\"background-color: #272822\">                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">rerank(query, docs, top_n)</span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">22 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mCohereReranker\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mModel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstr\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrerank-english-v3.0\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m@weave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mop\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mrerank\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mclient\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcohere\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mClient\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mos\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34menviron\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mCO_API_KEY\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocuments\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtext\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresponse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mclient\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrerank\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocuments\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocuments\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlen\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutputs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresponse\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresults\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranked_doc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mindex\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranked_doc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrelevance_score\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdoc\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevance_score\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutputs\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mappend\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranked_doc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutputs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m@weave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mop\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mpredict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrerank\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m22 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">DenseRetrieverWithReranker</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Model):</span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    retriever: DenseRetriever </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> DenseRetriever()</span><span style=\"background-color: #272822\">                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    reranker: CohereReranker </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> CohereReranker()</span><span style=\"background-color: #272822\">                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">index_data</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, data):</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">retriever</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">index_data(data)</span><span style=\"background-color: #272822\">                                                                       </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@weave</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">op()</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">predict</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, query: str, top_k: int </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, top_n: int </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">):</span><span style=\"background-color: #272822\">                                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_k </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">and</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">not</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_n:</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            top_n </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_k</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            top_k </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_k </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">elif</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_n </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">and</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">not</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_k:</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            top_k </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> top_n </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">else</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">:</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            top_k </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10</span><span style=\"background-color: #272822\">                                                                                        </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            top_n </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">5</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        retrievals </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">retriever</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">predict(query, top_k)</span><span style=\"background-color: #272822\">                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        reranked </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">reranker</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">predict(query, retrievals, top_n)</span><span style=\"background-color: #272822\">                                            </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> reranked</span><span style=\"background-color: #272822\">                                                                                       </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mDenseRetrieverWithReranker\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mModel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDenseRetriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDenseRetriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranker\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mCohereReranker\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mCohereReranker\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mindex_data\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mindex_data\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdata\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m@weave\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mop\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mpredict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstr\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mand\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mnot\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34melif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mand\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mnot\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34melse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m5\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretrievals\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_k\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranked\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranker\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretrievals\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtop_n\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreranked\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scripts.retriever import DenseRetriever, DenseRetrieverWithReranker\n",
    "from scripts.reranker import CohereReranker\n",
    "from scripts.utils import display_source\n",
    "\n",
    "display_source(DenseRetriever)\n",
    "display_source(CohereReranker)\n",
    "display_source(DenseRetrieverWithReranker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = DenseRetrieverWithReranker()\n",
    "dense_retriever.index_data(chunked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.retrieval_metrics import ALL_METRICS as RETRIEVAL_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = weave.ref(\n",
    "    \"weave:///rag-course/dev/object/Dataset:9O0EmmPINmYjgbXW3kucVrDxlTUQJQs0fVZYJj2mtOk\"\n",
    ").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WeaveDict({'question': 'How can I access the run object from the Lightning WandBLogger function?', 'answer': \"In PyTorch Lightning, the `WandbLogger` is used to log metrics, model weights, and other data to Weights & Biases during training. To access the `wandb.Run` object from within a `LightningModule` when using `WandbLogger`, you can use the `Trainer.logger.experiment` attribute. This attribute provides direct access to the underlying `wandb.Run` object, allowing you to interact with the Weights & Biases API directly.\\n\\nHere's how you can access the `wandb.Run` object using `WandbLogger` in PyTorch Lightning:\\n\\n```python\\nfrom pytorch_lightning import Trainer, LightningModule\\nfrom pytorch_lightning.loggers import WandbLogger\\n\\nclass MyModel(LightningModule):\\n    def training_step(self, batch, batch_idx):\\n        # Your training logic here\\n        loss = ...\\n\\n        # Log metrics\\n        self.log('train_loss', loss)\\n\\n        # Access the wandb.Run object\\n        run = self.trainer.logger.experiment\\n        # Now you can use `run` to interact with wandb API, e.g., to log additional data\\n        run.log({'additional_metric': value})\\n\\n        return loss\\n\\n# Setup the logger\\nwandb_logger = WandbLogger(project='my_project', entity='my_entity')\\n\\n# Setup the trainer\\ntrainer = Trainer(logger=wandb_logger)\\n\\n# Initialize your model\\nmodel = MyModel()\\n\\n# Train the model\\ntrainer.fit(model)\\n```\\n\\nIn this example:\\n- A `WandbLogger` is instantiated and passed to the `Trainer`.\\n- Inside the `LightningModule`, you can access the `wandb.Run` object via `self.trainer.logger.experiment`.\\n- You can then use this `run` object to log additional data or interact with the Weights & Biases API directly.\\n\\nThis approach allows you to leverage the full capabilities of Weights & Biases directly from your training loop in PyTorch Lightning.\", 'contexts': [{'content': 'Using PyTorch Lightning\\'s WandbLogger\\nPyTorch Lightning has multiple `WandbLogger` (Pytorch) (Fabric) classes that can be used to seamlessly log metrics, model weights, media and more. Just instantiate the WandbLogger and pass it to Lightning\\'s `Trainer` or `Fabric`.\\nwandb_logger = WandbLogger()\\ntrainer = Trainer(logger=wandb_logger)\\nfabric = L.Fabric(loggers=[wandb_logger])\\nfabric.launch()\\nfabric.log_dict({\\n    \"important_metric\": important_metric\\n})\\nLogger arguments\\nBelow are some of the most used parameters in WandbLogger, see the PyTorch Lightning for a full list and description\\n(Pytorch)\\n(Fabric)\\nParameter\\nDescription\\n`project`\\nDefine what wandb Project to log to\\n`name`\\nGive a name to your wandb run\\n`log_model`\\nLog all models if `log_model=\"all\"` or at end of training if `log_model=True`\\n`save_dir`\\nPath where data is saved\\nLog your hyperparameters\\nclass LitModule(LightningModule):\\n    def __init__(self, *args, **kwarg):\\n        self.save_hyperparameters()\\nwandb_logger.log_hyperparams(\\n    {\\n        \"hyperparameter_1\": hyperparameter_1,\\n        \"hyperparameter_2\": hyperparameter_2,\\n    }\\n)\\nLog additional config parameters\\n# add one parameter\\nwandb_logger.experiment.config[\"key\"] = value\\n# add multiple parameters\\nwandb_logger.experiment.config.update({key1: val1, key2: val2})\\n# use directly wandb module\\nwandb.config[\"key\"] = value\\nwandb.config.update()\\nLog gradients, parameter histogram and model topology\\nYou can pass your model object to `wandblogger.watch()` to monitor your models\\'s gradients and parameters as you train. See the PyTorch Lightning `WandbLogger` documentation', 'source': 'guides/integrations/lightning.md', 'score': 0.9996229999999999, 'relevance': 2}, {'content': 'PyTorch Lightning\\nTry in a Colab Notebook here →\\nPyTorch Lightning provides a lightweight wrapper for organizing your PyTorch code and easily adding advanced features such as distributed training and 16-bit precision. W&B provides a lightweight wrapper for logging your ML experiments. But you don\\'t need to combine the two yourself: Weights & Biases is incorporated directly into the PyTorch Lightning library via the WandbLogger.\\n⚡ Get going lightning-fast with just a few lines.\\nfrom lightning.pytorch.loggers import WandbLogger\\nfrom lightning.pytorch import Trainer\\nwandb_logger = WandbLogger(log_model=\"all\")\\ntrainer = Trainer(logger=wandb_logger)\\n:::info\\nUsing wandb.log(): Please note that the `WandbLogger` logs to W&B using the Trainer\\'s `global_step`. If you are making additional calls to `wandb.log` directly in your code, do not use the `step` argument in `wandb.log()`. \\nInstead, log the Trainer\\'s `global_step` like your other metrics, like so:\\n`wandb.log({\"accuracy\":0.99, \"trainer/global_step\": step})`\\n:::\\nimport lightning as L\\nfrom wandb.integration.lightning.fabric import WandbLogger\\nwandb_logger = WandbLogger(log_model=\"all\")\\nfabric = L.Fabric(loggers=[wandb_logger])\\nfabric.launch()\\nfabric.log_dict({\"important_metric\": important_metric})\\nSign up and Log in to wandb\\na) Sign up for a free account\\nb) Pip install the `wandb` library\\nc) To log in in your training script, you\\'ll need to be signed in to you account at www.wandb.ai, then you will find your API key on the Authorize page.\\nIf you are using Weights and Biases for the first time you might want to check out our quickstart\\npip install wandb\\nwandb login\\n!pip install wandb\\nimport wandb\\nwandb.login()', 'source': 'guides/integrations/lightning.md', 'score': 0.9393594, 'relevance': 2}, {'content': 'Check out interactive examples!\\nYou can follow along in our video tutorial with our tutorial colab here\\nFrequently Asked Questions\\nHow does W&B integrate with Lightning?\\nThe core integration is based on the Lightning loggers API, which lets you write much of your logging code in a framework-agnostic way. `Logger`s are passed to the Lightning Trainer and are triggered based on that API\\'s rich hook-and-callback system. This keeps your research code well-separated from engineering and logging code.\\nWhat does the integration log without any additional code?\\nWe\\'ll save your model checkpoints to W&B, where you can view them or download them for use in future runs. We\\'ll also capture system metrics, like GPU usage and network I/O, environment information, like hardware and OS information, code state (including git commit and diff patch, notebook contents and session history), and anything printed to the standard out.\\nWhat if I really need to use wandb.run in my training setup?\\nYou will have to essentially expand the scope of the variable you need to access yourself. In other words, making sure that the initial conditions are the same on all processes.\\nif os.environ.get(\"LOCAL_RANK\", None) is None:\\n    os.environ[\"WANDB_DIR\"] = wandb.run.dir\\nThen, you can use `os.environ[\"WANDB_DIR\"]` to set up the model checkpoints directory. This way, `wandb.run.dir` can be used by any non-zero rank processes as well.', 'source': 'guides/integrations/lightning.md', 'score': 0.9999046300000001, 'relevance': 1}, {'content': 'With implicit wandb integrations\\nIf you\\'re using a framework integration we support, you can also pass in the callback directly:\\n@wandb_log\\ndef train_model(\\n    train_dataloader_path: components.InputPath(\"dataloader\"),\\n    test_dataloader_path: components.InputPath(\"dataloader\"),\\n    model_path: components.OutputPath(\"pytorch_model\")\\n):\\n    from pytorch_lightning.loggers import WandbLogger\\n    from pytorch_lightning import Trainer\\n    trainer = Trainer(logger=WandbLogger())\\n    ...  # do training', 'source': 'guides/integrations/other/kubeflow-pipelines-kfp.md', 'score': 0.9520419, 'relevance': 1}, {'content': 'Log images, text and more\\nThe `WandbLogger` has `log_image`, `log_text` and `log_table` methods for logging media.\\nYou can also directly call `wandb.log` or `trainer.logger.experiment.log` to log other media types such as Audio, Molecules, Point Clouds, 3D Objects and more.\\n# using tensors, numpy arrays or PIL images\\nwandb_logger.log_image(key=\"samples\", images=[img1, img2])\\n# adding captions\\nwandb_logger.log_image(key=\"samples\", images=[img1, img2], caption=[\"tree\", \"person\"])\\n# using file path\\nwandb_logger.log_image(key=\"samples\", images=[\"img_1.jpg\", \"img_2.jpg\"])\\n# using .log in the trainer\\ntrainer.logger.experiment.log(\\n    {\"samples\": [wandb.Image(img, caption=caption) for (img, caption) in my_images]},\\n    step=current_trainer_global_step,\\n)\\n# data should be a list of lists\\ncolumns = [\"input\", \"label\", \"prediction\"]\\nmy_data = [[\"cheese\", \"english\", \"english\"], [\"fromage\", \"french\", \"spanish\"]]\\n# using columns and data\\nwandb_logger.log_text(key=\"my_samples\", columns=columns, data=my_data)\\n# using a pandas DataFrame\\nwandb_logger.log_text(key=\"my_samples\", dataframe=my_dataframe)\\n# log a W&B Table that has a text caption, an image and audio\\ncolumns = [\"caption\", \"image\", \"sound\"]\\n# data should be a list of lists\\nmy_data = [\\n    [\"cheese\", wandb.Image(img_1), wandb.Audio(snd_1)],\\n    [\"wine\", wandb.Image(img_2), wandb.Audio(snd_2)],\\n]\\n# log the Table\\nwandb_logger.log_table(key=\"my_samples\", columns=columns, data=data)\\nYou can use Lightning\\'s Callbacks system to control when you log to Weights & Biases via the WandbLogger, in this example we log a sample of our validation images and predictions:', 'source': 'guides/integrations/lightning.md', 'score': 0.8296300999999999, 'relevance': 1}, {'content': \"Run\\nView source on GitHub\\nA unit of computation logged by wandb. Typically, this is an ML experiment.\\nRun(\\n    settings: Settings,\\n    config: Optional[Dict[str, Any]] = None,\\n    sweep_config: Optional[Dict[str, Any]] = None,\\n    launch_config: Optional[Dict[str, Any]] = None\\n) -> None\\nCreate a run with `wandb.init()`:\\nimport wandb\\nrun = wandb.init()\\nThere is only ever at most one active `wandb.Run` in any process,\\nand it is accessible as `wandb.run`:\\nimport wandb\\nassert wandb.run is None\\nwandb.init()\\nassert wandb.run is not None\\nanything you log with `wandb.log` will be sent to that run.\\nIf you want to start more runs in the same script or notebook, you'll need to\\nfinish the run that is in-flight. Runs can be finished with `wandb.finish` or\\nby using them in a `with` block:\\nimport wandb\\nwandb.init()\\nwandb.finish()\\nassert wandb.run is None\\nwith wandb.init() as run:\\n    pass  # log data here\\nassert wandb.run is None\", 'source': 'ref/python/run.md', 'score': 0.99928474, 'relevance': 0}, {'content': 'Examples:\\nSet where the run is logged\\nYou can change where the run is logged, just like changing\\nthe organization, repository, and branch in git:\\nimport wandb\\nuser = \"geoff\"\\nproject = \"capsules\"\\ndisplay_name = \"experiment-2021-10-31\"\\nwandb.init(entity=user, project=project, name=display_name)\\nAdd metadata about the run to the config\\nPass a dictionary-style object as the `config` keyword argument to add\\nmetadata, like hyperparameters, to your run.\\nimport wandb\\nconfig = {\"lr\": 3e-4, \"batch_size\": 32}\\nconfig.update({\"architecture\": \"resnet\", \"depth\": 34})\\nwandb.init(config=config)\\nRaises\\n`Error`\\nif some unknown or internal error happened during the run initialization.\\n`AuthenticationError`\\nif the user failed to provide valid credentials.\\n`CommError`\\nif there was a problem communicating with the WandB server.\\n`UsageError`\\nif the user provided invalid arguments.\\n`KeyboardInterrupt`\\nif user interrupts the run.\\nReturns\\nA `Run` object.', 'source': 'ref/python/init.md', 'score': 0.99253935, 'relevance': 0}, {'content': 'Runs\\nA single unit of computation logged by W&B is called a run. You can think of a W&B run as an atomic element of your whole project. You should initiate a new run when you:\\nTrain a model\\nChange a hyperparameter\\nUse a different model\\nLog data or a model as a W&B Artifact\\nDownload a W&B Artifact\\nFor example, during a sweep, W&B explores a hyperparameter search space that you specify. Each new hyperparameter combination created by the sweep is implemented and recorded as a unique run. \\n:::tip\\nSome key things to consider when you create and manage runs:\\n* Anything you log with `wandb.log` is recorded in that run.  For more information on how log objects in W&B, see Log Media and Objects. \\n* Each run is associated to a specific W&B project.\\n* View runs and their properties within the run\\'s project workspace on the W&B App UI.\\n* There is only at most one active wandb.Run in any process,\\nand it is accessible as `wandb.run`.\\n:::\\nCreate a run\\nCreate a W&B run with wandb.init():\\nimport wandb\\nrun = wandb.init()\\nWe recommend you specify a project name and a W&B entity when you create a new run. W&B creates a new project (if the project does not already exist) within the W&B entity you provide. If the project already exists, W&B stores the run in that project.\\nFor example, the following code snippet initializes a run that is stored in a project called `model_registry_example` that is scoped within a `wandbee` entity:\\nimport wandb\\nrun = wandb.init(entity=\"wandbee\", \\\\\\n        project=\"model_registry_example\")\\nW&B prints the name of the run that is created along with a URL path to find out more information about that specific run. \\nFor example, the code snippet above produces this output:', 'source': 'guides/runs/intro.md', 'score': 0.9912548, 'relevance': 0}, {'content': 'Get the command that ran the run\\nEach run captures the command that launched it on the run overview page. To pull this command down from the API, you can run:\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nmeta = json.load(run.file(\"wandb-metadata.json\").download())\\nprogram = [\"python\"] + [meta[\"program\"]] + meta[\"args\"]', 'source': 'guides/track/public-api-guide.md', 'score': 0.9897908999999999, 'relevance': 0}, {'content': 'You can then log the parent_span to W&B like as below. \\nrun = wandb.init(name=\"manual_span_demo\", project=\"wandb_prompts_demo\")\\nrun.log({\"trace\": trace_tree.WBTraceTree(parent_span)})\\nrun.finish()\\nClicking on the W&B Run link generated will take you to a workspace where you can inspect the Trace created.', 'source': 'tutorials/prompts.md', 'score': 0.98942953, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'is there a method to auto delete log files from my disk once a log completes?', 'answer': 'Currently, Weights & Biases does not provide a built-in method to automatically delete local log files once a log completes directly through its API or settings. However, you can manage log files manually or implement a custom solution to handle this task.\\n\\nHere are a couple of approaches you might consider:\\n\\n### 1. Manual Cleanup\\nAfter your experiments are complete and you\\'ve ensured that all data is synced with the W&B servers, you can manually delete the log files from your disk.\\n\\n### 2. Custom Script for Automatic Cleanup\\nYou can write a custom script that runs at the end of your experiments to delete the log files. Here’s a simple example using Python:\\n\\n```python\\nimport os\\nimport shutil\\n\\ndef clean_log_dir(directory):\\n    if os.path.exists(directory):\\n        shutil.rmtree(directory)\\n        print(f\"Log directory {directory} has been removed\")\\n    else:\\n        print(\"Directory does not exist\")\\n\\n# Example usage\\nlog_directory = \\'./wandb\\'\\nclean_log_dir(log_directory)\\n```\\n\\nThis script checks if the directory exists and then removes it along with all its contents. You would need to call this function at the end of your experiment or training session.\\n\\n### 3. Using Python atexit\\nIf you want the cleanup to happen automatically when your Python script exits, you can use the `atexit` module which allows you to register cleanup functions. Here\\'s how you might integrate it:\\n\\n```python\\nimport atexit\\nimport shutil\\n\\ndef cleanup_logs():\\n    log_dir = \\'./wandb\\'\\n    if os.path.exists(log_dir):\\n        shutil.rmtree(log_dir)\\n        print(f\"Cleaned up {log_dir}\")\\n\\natexit.register(cleanup_logs)\\n```\\n\\nThis will ensure that the log directory is cleaned up whenever the Python interpreter terminates normally.\\n\\n### Best Practices\\n- **Ensure Data Integrity**: Always make sure that all your data is properly synced to the W&B servers before deleting any local files to avoid data loss.\\n- **Regular Monitoring**: Keep an eye on the disk space used by W&B logs, especially when running multiple or long-running experiments.\\n- **Use W&B Artifacts**: For managing outputs and datasets more systematically, consider using [W&B Artifacts](https://docs.wandb.ai/guides/artifacts) which also supports versioning and is integrated with the W&B dashboard.\\n\\nThese methods provide flexibility depending on your specific needs and environment.', 'contexts': [{'content': 'wandb artifact cache cleanup\\nUsage\\n`wandb artifact cache cleanup [OPTIONS] TARGET_SIZE`\\nSummary\\nClean up less frequently used files from the artifacts cache\\nOptions\\nOption\\nDescription\\n--remove-temp / --no-remove-temp\\nRemove temp files', 'source': 'ref/cli/wandb-artifact/wandb-artifact-cache/wandb-artifact-cache-cleanup.md', 'score': 0.0001323819, 'relevance': 2}, {'content': 'Log Media and Objects in Experiments\\nLog Media and Objects in Experiments\\nLog a dictionary of metrics, media, or custom objects to a step with the W&B Python SDK. W&B collects the key-value pairs during each step and stores them in one unified dictionary each time you log data with `wandb.log()`. Data logged from your script is saved locally to your machine in a directory called `wandb`, then synced to the W&B cloud or your private server. \\n:::info\\nKey-value pairs are stored in one unified dictionary only if you pass the same value for each step. W&B writes all of the collected keys and values to memory if you log a different value for `step`.\\n:::\\nEach call to `wandb.log` is a new `step` by default. W&B uses steps as the default x-axis when it creates charts and panels. You can optionally create and use a custom x-axis or capture a custom summary metric. For more information, see Customize log axes.\\n:::caution\\nUse `wandb.log()` to log consecutive values for each `step`: 0, 1, 2, and so on. It is not possible to write to a specific history step. W&B only writes to the \"current\" and \"next\" step.\\n:::\\nAutomatically logged data\\nW&B automatically logs the following information during a W&B Experiment:\\nSystem metrics: CPU and GPU utilization, network, etc. These are shown in the System tab on the run page. For the GPU, these are fetched with nvidia-smi.\\nCommand line: The stdout and stderr are picked up and show in the logs tab on the run page.\\nTurn on Code Saving in your account\\'s Settings page to log:\\nGit commit: Pick up the latest git commit and see it on the overview tab of the run page, as well as a `diff.patch` file if there are any uncommitted changes.\\nDependencies: The `requirements.txt` file will be uploaded and shown on the files tab of the run page, along with any files you save to the `wandb` directory for the run.', 'source': 'guides/track/log/intro.md', 'score': 1.35253e-05, 'relevance': 2}, {'content': \"Storage\\nIf you are approaching or exceeding your storage limit, there are multiple paths forward to manage your data. The path that's best for you will depend on your account type and your current project setup.\\nManage storage consumption\\nW&B offers different methods of optimizing your storage consumption:\\nUse\\xa0reference artifacts\\xa0to track files saved outside the W&B system, instead of uploading them to W&B storage.\\nUse an external cloud storage bucket for storage. (Enterprise only)\\nDelete data\\nYou can also choose to delete data to remain under your storage limit. There are several ways to do this:\\nDelete data interactively with the app UI.\\nSet a TTL policy on Artifacts so they are automatically deleted.\", 'source': 'guides/app/features/storage.md', 'score': 0.00024156630000000002, 'relevance': 1}, {'content': 'File count\\nKeep the total number of files uploaded for a single run under 1,000. You can use W&B Artifacts when you need to log a large number of files. Exceeding 1,000 files in a single run can slow down your run pages.\\nPython script performance\\nThere are a few ways that your performance of your python script is reduced:\\nThe size of your data is too large. Large data sizes could introduce a >1 ms overhead to the training loop.\\nThe speed of your network and the how the W&B backend is configured\\nCalling `wandb.log` more than a few times per second. This is due to a small latency added to the training loop every time `wandb.log` is called.\\n:::info\\nIs frequent logging slowing your training runs down? Check out this Colab for methods to get better performance by changing your logging strategy.\\n:::\\nW&B does not assert any limits beyond rate limiting. The W&B Python SDK automatically completes an exponential \"backoff\" and \"retry\" requests that exceed limits. W&B Python SDK responds with a “Network failure” on the command line. For unpaid accounts, W&B may reach out in extreme cases where usage exceeds reasonable thresholds.\\nRate limits\\nW&B SaaS Cloud API implements a rate limit to maintain system integrity and ensure availability. This measure prevents any single user from monopolizing available resources in the shared infrastructure, ensuring that the service remains accessible to all users. You may encounter a lower rate limit for a variety of reasons. \\n:::note\\nRate limits are subject to change.\\n:::\\nThe `wandb.log` calls in your script utilize a metrics logging API to log your training data to W&B. This API is engaged through either online or offline syncing. In either case, it imposes a rate limit quota limit in a rolling time window. This includes limits on total request size and request rate, where latter refers to the number of requests in a time duration. \\nRate limits are applied to each W&B project. So if you have 3 projects in a team, each project has its own rate limit quota. Users on Teams and Enterprise plans have higher rate limits than those on the Free plan.', 'source': 'guides/track/limits.md', 'score': 1.59366e-05, 'relevance': 1}, {'content': 'End a run\\nW&B automatically ends runs and logs data from that run to your W&B project. You can end a run manually with the run.finish command. For example:\\nimport wandb\\nrun = wandb.init()\\nrun.finish()\\n:::info\\nW&B suggests that you use the wandb.finish method at the end of the child process if you call wandb.init from a child process.\\n:::', 'source': 'guides/runs/intro.md', 'score': 0.0003500686, 'relevance': 0}, {'content': '3. View your OpenAI API inputs and responses\\nClick on the Weights & Biases run link generated by `autolog` in step 1. This will redirect you to your project workspace in the W&B App.\\nSelect a run you created to view the trace table, trace timeline and the model architecture of the OpenAI LLM used.\\n4. Disable autolog\\nWe recommend that you call `disable()` to close all W&B processes when you are finished using the OpenAI API.\\nautolog.disable()\\nNow your inputs and completions will be logged to Weights & Biases, ready for analysis or to be shared with colleagues.', 'source': 'guides/integrations/other/openai-api.md', 'score': 0.0002492325, 'relevance': 0}, {'content': 'log\\nView source\\nlog(\\n    data: Dict[str, Any],\\n    step: Optional[int] = None,\\n    commit: Optional[bool] = None,\\n    sync: Optional[bool] = None\\n) -> None', 'source': 'ref/python/run.md', 'score': 0.000179528, 'relevance': 0}, {'content': \"Audit logs\\nUse W&B Server audit logs to track user activity within your teams, and to conform to your enterprise governance requirements. The audit logs are JSON-formatted, and their access mechanism(s) depend on your W&B Server deployment type:\\nW&B Server Deployment type\\nAudit logs access mechanism(s)\\nSelf-managed\\nSynced to instance-level bucket every 10 minutes. Also available using the API.\\nDedicated Cloud with secure storage connector (BYOB)\\nSynced to instance-level bucket (BYOB) every 10 minutes. Also available using the API.\\nDedicated Cloud with W&B managed storage (without BYOB)\\nOnly available using the API.\\nOnce you've access to your audit logs, analyze those using your preferred tools, such as Pandas, Amazon Redshift, Google BigQuery, Microsoft Fabric, and more. You may need to transform the JSON-formatted audit logs into a format relevant to the tool before analysis. Information on how to transform your audit logs for specific tools is outside the scope of W&B documentation.\\n:::tip\\nAudit Log Retention: If a compliance, security or risk team in your organization requires audit logs to be retained for a specific period of time, W&B recommends to periodically transfer the logs from your instance-level bucket to a long-term retention storage. If you're instead using the API to access the audit logs, you can implement a simple script that runs periodically (like daily or every few days) to fetch any logs that may have been generated since the time of the last script run, and store those in a short-term storage for analysis or directly transfer to a long-term retention storage.\\n:::\\n:::note\\nAudit logs are not available for W&B Multi-tenant Cloud yet.\\n:::\", 'source': 'guides/hosting/monitoring-usage/audit-logging.md', 'score': 3.42685e-05, 'relevance': 0}, {'content': 'Examples of logging behavior\\nKind of Variable\\nbehavior\\nExample\\nData Type\\nInstance\\nAuto-logged\\n`self.accuracy`\\n`float`\\nInstance\\nLogged if `datasets=True`\\n`self.df`\\n`pd.DataFrame`\\nInstance\\nNot logged if `datasets=False`\\n`self.df`\\n`pd.DataFrame`\\nLocal\\nNever logged\\n`accuracy`\\n`float`\\nLocal\\nNever logged\\n`df`\\n`pd.DataFrame`\\nDoes this track artifact lineage?\\nYes! If you have an artifact that is an output of step A and an input to step B, we automatically construct the lineage DAG for you.\\nFor an example of this behavior, please see this notebook and its corresponding W&B Artifacts page', 'source': 'guides/integrations/other/metaflow.md', 'score': 2.90834e-05, 'relevance': 0}, {'content': 'Log Images, Tables, Text, Audio and More\\nIn addition to metrics, you can log plots, histograms, tables, text and media such as images, videos, audios, 3D and more.\\nSome considerations when logging data include:\\nHow often should the metric be logged? Should it be optional?\\nWhat type of data could be helpful in visualizing?\\nFor images, you can log sample predictions, segmentation masks etc to see the evolution over time.\\nFor text, you can log tables of sample predictions for later exploration.\\nRefer to Log Data with wandb.log for a full guide on logging media, objects, plots and more.\\nDistributed Training\\nFor frameworks supporting distributed environments, you can adapt any of the following workflows:\\nDetect which is the “main” process and only use `wandb` there. Any required data coming from other processes must be routed to the main process first. (This workflow is encouraged).\\nCall `wandb` in every process and auto-group them by giving them all the same unique `group` name\\nSee Log Distributed Training Experiments for more details\\nLogging Model Checkpoints And More\\nIf your framework uses or produces models or datasets, you can log them for full traceability and have wandb automatically monitor your entire pipeline through W&B Artifacts.\\nWhen using Artifacts, it might be useful but not necessary to let your users define:\\nThe ability to log model checkpoints or datasets (in case you want to make it optional)\\nThe path/reference of the artifact being used as input if any. For example “user/project/artifact”\\nThe frequency for logging Artifacts', 'source': 'guides/integrations/add-wandb-to-any-library.md', 'score': 1.92232e-05, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'Is it possible to group by tags within the UI?', 'answer': \"In Weights & Biases, while tags are very useful for labeling and organizing runs with specific features, the platform does not support grouping runs by tags directly in the UI. This limitation is due to the fact that a run can have multiple tags, which complicates the grouping logic.\\n\\nHowever, you can use tags in conjunction with other features to organize and filter your runs effectively. For example, you can use tags to mark runs and then filter the runs table in the UI to display only those with specific tags. This allows you to manually group and compare runs based on the tags they share.\\n\\nIf you need to group runs, it's recommended to use the `group` or `job_type` parameters in `wandb.init()` to organize runs into larger experiments or categories, which can then be grouped in the UI.\\n\\nFor more detailed information on how to use tags and other grouping methods in Weights & Biases, you can refer to the [guide on grouping runs](https://docs.wandb.ai/guides/runs/grouping).\", 'contexts': [{'content': \"Turn off grouping\\nClick the grouping button and clear group fields at any time, which returns the table and graphs to their ungrouped state.\\nGrouping graph settings\\nClick the edit button in the upper right corner of a graph and select the Advanced tab to change the line and shading. You can select the mean, minimum, or maximum value for the line in each group. For the shading, you can turn off shading, and show the min and max, the standard deviation, and the standard error.\\nCommon Questions\\nCan we group runs by tags?\\nBecause a run can have multiple tags we don't support grouping by this field. Our recommendation would be to add a value to the config object of these runs and then group by this config value. You can do this with our API.\", 'source': 'guides/runs/grouping.md', 'score': 0.9911183, 'relevance': 2}, {'content': 'Group Runs\\nGroup W&B Runs\\nGroup individual jobs into experiments by passing a unique group name to wandb.init().\\nUse Cases\\nDistributed training: Use grouping if your experiments are split up into different pieces with separate training and evaluation scripts that should be viewed as parts of a larger whole.\\nMultiple processes: Group multiple smaller processes together into an experiment.\\nK-fold cross-validation: Group together runs with different random seeds to see a larger experiment. Here\\'s an example of k-fold cross-validation with sweeps and grouping.\\nThere are three ways to set grouping:\\n1. Set group in your script\\nPass an optional group and job_type to wandb.init(). This gives you a dedicated group page for each experiment, which contains the individual runs. For example:`wandb.init(group=\"experiment_1\", job_type=\"eval\")`\\n2. Set a group environment variable\\nUse `WANDB_RUN_GROUP` to specify a group for your runs as an environment variable. For more on this, check our docs for Environment Variables. Group should be unique within your project and shared by all runs in the group. You can use `wandb.util.generate_id()` to generate a unique 8 character string to use in all your processes— for example, `os.environ[\"WANDB_RUN_GROUP\"] = \"experiment-\" + wandb.util.generate_id()`\\n3. Toggle grouping in the UI\\nYou can dynamically group by any config column. For example, if you use `wandb.config` to log batch size or learning rate, you can then group by those hyperparameters dynamically in the web app.\\nDistributed training with grouping\\nSuppose you set grouping in `wandb.init()`, we will group runs by default in the UI. You can toggle this on and off by clicking the Group button at the top of the table. Here\\'s an example project generated from sample code where we set grouping. You can click on each \"Group\" row in the sidebar to get to a dedicated group page for that experiment.\\nFrom the project page above, you can click a Group in the left sidebar to get to a dedicated page like this one:\\nGrouping dynamically in the UI\\nYou can group runs by any column, for example by hyperparameter. Here\\'s an example of what that looks like:\\nSidebar: Runs are grouped by the number of epochs.\\nGraphs: Each line represents the group\\'s mean, and the shading indicates the variance. This behavior can be changed in the graph settings.', 'source': 'guides/runs/grouping.md', 'score': 0.05877655700000001, 'relevance': 2}, {'content': '`job_type`\\n(str, optional) Specify the type of run, which is useful when you\\'re grouping runs together into larger experiments using group. For example, you might have multiple jobs in a group, with job types like train and eval. Setting this makes it easy to filter and group similar runs together in the UI so you can compare apples to apples.\\n`tags`\\n(list, optional) A list of strings, which will populate the list of tags on this run in the UI. Tags are useful for organizing runs together, or applying temporary labels like \"baseline\" or \"production\". It\\'s easy to add and remove tags in the UI, or filter down to just runs with a specific tag. If you are resuming a run, its tags will be overwritten by the tags you pass to `wandb.init()`. If you want to add tags to a resumed run without overwriting its existing tags, use `run.tags += [\"new_tag\"]` after `wandb.init()`.\\n`name`\\n(str, optional) A short display name for this run, which is how you\\'ll identify this run in the UI. By default, we generate a random two-word name that lets you easily cross-reference runs from the table to charts. Keeping these run names short makes the chart legends and tables easier to read. If you\\'re looking for a place to save your hyperparameters, we recommend saving those in config.\\n`notes`\\n(str, optional) A longer description of the run, like a `-m` commit message in git. This helps you remember what you were doing when you ran this run.\\n`dir`\\n(str or pathlib.Path, optional) An absolute path to a directory where metadata will be stored. When you call `download()` on an artifact, this is the directory where downloaded files will be saved. By default, this is the `./wandb` directory.', 'source': 'ref/python/init.md', 'score': 0.9863105400000001, 'relevance': 1}, {'content': 'Tags\\nTags can be used to label runs with particular features that might not be obvious from the logged metrics or Artifact data -- this run\\'s model is `in_production`, that run is `preemptible`, this run represents the `baseline`.\\nHow to add tags\\nYou can add tags to a run when it is created: `wandb.init(tags=[\"tag1\", \"tag2\"])` .\\nYou can also update the tags of a run during training (e.g. if a particular metrics crosses a pre-defined threshold):\\nrun = wandb.init(entity=\"entity\", project=\"capsules\", tags=[\"debug\"])\\n...\\nif current_loss < threshold:\\n    run.tags = run.tags + (\"release_candidate\",)\\nThere are also several ways to add tags after runs have been logged to W&B.\\nAfter a run is created, you can update tags using our public API like so:\\nrun = wandb.Api().run(\"{entity}/{project}/{run-id}\")\\nrun.tags.append(\"tag1\")  # you can choose tags based on run data here\\nrun.update()\\nYou can read more about how to use the Public API in the reference documentation or guide.\\nThis method is best suited to tagging large numbers of runs with the same tag or tags.\\nIn the runs sidebar of the Project Page,  click the table icon in the upper-right.  This will expand the sidebar into the full runs table.\\nHover over a run in the table to see a checkbox on the left or look in the header row for a checkbox that will allow you to select all runs.\\nClick the checkbox to enable bulk actions. Select the runs to which you\\'d like to apply your tag(s).\\nClick the Tag button above the rows of runs.\\nType a tag you\\'d like to add and click \"Add\" below the text box to add a new tag.\\nThis method is best suited to applying a tag or tags to a single run by hand.\\nIn the left sidebar of the Run Page, click the top Overview tab.\\nNext to \"Tags\" is a gray ➕ button. Click on that plus to add a tag.\\nType a tag you\\'d like to add and click \"Add\" below the text box to add a new tag.', 'source': 'guides/app/features/tags.md', 'score': 0.0049822700000000004, 'relevance': 1}, {'content': 'How to remove tags\\nTags can also be removed from runs via the UI.\\nThis method is best suited to removing tags from a large numbers of runs.\\nIn the runs sidebar of the Project Page,  click the table icon in the upper-right.  This will expand the sidebar into the full runs table.\\nHover over a run in the table to see a checkbox on the left or look in the header row for a checkbox that will allow you to select all runs.\\nClick either checkbox to enable bulk actions. Select the runs to from which you\\'d like to remove your tag(s).\\nClick the Tag button above the rows of runs.\\nClick the checkbox next to a tag to remove it from the run.\\nIn the left sidebar of the Run Page, click the top Overview tab. The tags on the run are visible here.\\nHover over a tag and click the \"x\" to remove it from the run.', 'source': 'guides/app/features/tags.md', 'score': 0.045948207000000005, 'relevance': 0}, {'content': 'Model tags\\nModel tags are keywords or labels that belong to one or more registered models.\\nUse model tags to organize registered models into categories and to search over those categories in the Model Registry\\'s search bar. Model tags appear at the top of the Registered Model Card. You might choose to use them to group your registered models by ML task, owning team, or priority. The same model tag can be added to multiple registered models to allow for grouping. \\n:::info\\nModel tags, which are labels applied to registered models for grouping and discoverability, are different from model aliases. Model aliases are unique identifiers or nicknames that you use to fetch a model version programatically. To learn more about using tags to organize the tasks in your Model Registry, see Organize models.\\n:::\\nModel artifact\\nA model artifact is a collection of logged model versions. Model versions are stored in a model artifact in the order they are logged to the model artifact. \\nA model artifact can contain one or more model versions. A model artifact can be empty if no model versions are logged to it. \\nFor example, suppose you create a model artifact. During model training, you periodically save your model during checkpoints. Each checkpoint corresponds to its own model version. All of the model versions created during your model training and checkpoint saving are stored in the same model artifact you created at the beginning of your training script.\\nThe proceeding image shows a model artifact that contains three model versions: v0, v1, and v2.\\nView an example model artifact here.\\nRegistered model\\nA registered model is a collection of pointers (links) to model versions. You can think of a registered model as a folder of \"bookmarks\" of candidate models for the same ML task. Each \"bookmark\" of a registered model is a pointer to a model version that belongs to a model artifact. You can use model tags to group your registered models. \\nRegistered models often represent candidate models for a single modeling use case or task. For example, you might create registered model for different image classification task based on the model you use: \"ImageClassifier-ResNet50\", \"ImageClassifier-VGG16\", \"DogBreedClassifier-MobileNetV2\" and so on. Model versions are assigned version numbers in the order in which they were linked to the registered model.\\nView an example Registered Model here.', 'source': 'guides/model_registry/model-management-concepts.md', 'score': 0.0282746, 'relevance': 0}, {'content': \"How can I log additional metrics after a run completes?\\nThere are several ways to do this.\\nFor complicated workflows, we recommend using multiple runs and setting group parameters in wandb.init to a unique value in all the processes that are run as part of a single experiment. The runs table will automatically group the table by the group ID and the visualizations will behave as expected. This will allow you to run multiple experiments and training runs as separate processes log all the results into a single place.\\nFor simpler workflows, you can call `wandb.init` with `resume=True` and `id=UNIQUE_ID` and then later call `wandb.init` with the same `id=UNIQUE_ID`. Then you can log normally with wandb.log or `wandb.summary` and the runs values will update.\\nPerformance\\nWill wandb slow down my training?\\nW&B should have a negligible effect on your training performance if you use it normally. Normal use of wandb means logging less than once a second and logging less than a few megabytes of data at each step. W&B runs in a separate process and the function calls don't block, so if the network goes down briefly or there are intermittent read write issues on disk it should not affect your performance. It is possible to log a huge amount of data quickly, and if you do that you might create disk I/O issues. If you have any questions, please don't hesitate to contact us.\\nHow many runs to create per project?\\nWe recommend you have roughly 10k runs per project max for performance reasons.\\nBest practices to organize hyperparameter searches\\nIf 10k runs per project (approx.) is a reasonable limit then our recommendation would be to set tags in `wandb.init()` and have a unique tag for each search. This means that you'll easily be able to filter the project down to a given search by clicking that tag in the Project Page in the Runs Table. For example `wandb.init(tags='your_tag')`  docs for this can be found here.\", 'source': 'guides/technical-faq/metrics-and-performance.md', 'score': 0.0036642202000000002, 'relevance': 0}, {'content': 'Organize models\\nUse model tags to organize registered models into categories and to search over those categories. \\nNavigate to the W&B Model Registry app at https://wandb.ai/registry/model.\\nSelect View details next to the name of the registered model you want to add a model tag to. \\n    \\nScroll to the Model card section.\\nClick the plus button (+) next to the Tags field.\\nType in the name for your tag or search for a pre-existing model tag.\\n    For example. the following image shows multiple model tags added to a registered model called FineTuned-Review-Autocompletion:', 'source': 'guides/model_registry/organize-models.md', 'score': 0.0032476764000000003, 'relevance': 0}, {'content': 'WANDB_IGNORE_GLOBS\\nSet this to a comma separated list of file globs to ignore. These files will not be synced to the cloud.\\nWANDB_JOB_NAME\\nSpecify a name for any jobs created by `wandb`. For more information, see create a job\\nWANDB_JOB_TYPE\\nSpecify the job type, like \"training\" or \"evaluation\" to indicate different types of runs. See grouping for more info.\\nWANDB_MODE\\nIf you set this to \"offline\" wandb will save your run metadata locally and not sync to the server. If you set this to \"disabled\" wandb will turn off completely.\\nWANDB_NAME\\nThe human-readable name of your run. If not set it will be randomly generated for you\\nWANDB_NOTEBOOK_NAME\\nIf you\\'re running in jupyter you can set the name of the notebook with this variable. We attempt to auto detect this.\\nWANDB_NOTES\\nLonger notes about your run. Markdown is allowed and you can edit this later in the UI.\\nWANDB_PROJECT\\nThe project associated with your run. This can also be set with `wandb init`, but the environmental variable will override the value.\\nWANDB_RESUME\\nBy default this is set to never. If set to auto wandb will automatically resume failed runs. If set to must forces the run to exist on startup. If you want to always generate your own unique ids, set this to allow and always set WANDB_RUN_ID.\\nWANDB_RUN_GROUP\\nSpecify the experiment name to automatically group runs together. See grouping for more info.\\nWANDB_RUN_ID\\nSet this to a globally unique string (per project) corresponding to a single run of your script. It must be no longer than 64 characters. All non-word characters will be converted to dashes. This can be used to resume an existing run in cases of failure.\\nWANDB_SILENT\\nSet this to true to silence wandb log statements. If this is set all logs will be written to WANDB_DIR/debug.log\\nWANDB_SHOW_RUN\\nSet this to true to automatically open a browser with the run url if your operating system supports it.\\nWANDB_TAGS\\nA comma separated list of tags to be applied to the run.\\nWANDB_USERNAME\\nThe username of a member of your team associated with the run. This can be used along with a service account API key to enable attribution of automated runs to members of your team.', 'source': 'guides/track/environment-variables.md', 'score': 0.0030396497, 'relevance': 0}, {'content': \"Runs Table\\nOn the project page, we show runs in a sidebar. Expand the sidebar to view a table of hyperparameters and summary metrics across runs.\\nSearch run names\\nWe support full regex search on run names in the table. When you type a query in the search box, that will filter down the visible runs in the graphs on the workspace as well as filtering the rows of the table.\\nFilter and sort runs by minimum and maximum values\\nSort the runs table by the minimum or maximum value of a logged metric. This is particularly useful if you want to view the best (or worst) recorded value.\\nThe following steps describe how to sort the run table by a specific metric based on the minimum or maximum recorded value:\\nHover your mouse over the column with the metric you want to sort with.\\nSelect the kebob menu (three vertical lines).\\nFrom the dropdown, select either Show min or Show max.\\nFrom the same dropdown, select Sort by asc or Sort by desc to sort in ascending or descending order, respectively. \\nWhat to do in case regex fails?\\nIf regex doesn't provide you the desired results, you can make use of tags to filter out the runs in Runs Table. Tags can be added either on run creation or after they're finished. Once the tags are added to a run, you can add a tag filter as shown in the gif below.\\nSearch End Time for runs\\nWe provide a column named `End Time` that logs that last heartbeat from the client process. The field is hidden by default.\\nResize the sidebar\\nWould you like to make more space for the graphs on the project page? Click and drag the edge of the column header to resize the sidebar. You'll still be able to click on the eye icon to turn on and off runs on the graphs.\\nAdd sidebar columns\\nOn the project page, we show runs in a sidebar. To show more columns:\\nClick the button in the upper right corner of the sidebar to expand the table.\\nOn a column header, click the dropdown menu to pin a column.\\nPinned columns will be available in the sidebar when you collapse the table.\\nHere's a screen capture. I expand the table, pin two columns, collapse the table, then resize the sidebar.\\nBulk select runs\\nDelete multiple runs at once, or tag a group of runs— bulk selection makes it easier to keep the runs table organized.\", 'source': 'guides/app/features/runs-table.md', 'score': 0.001133569, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'why did wandb stop logging model parameters with a huggingface model.  I have used in the past and it worked.  Maybe I changed an environement or config, how do I reset?', 'answer': 'It sounds like you\\'re experiencing issues with Weights & Biases not logging model parameters when using a Hugging Face model. This could be due to several reasons, such as changes in environment variables or configuration settings. Here are some steps to troubleshoot and reset your configuration:\\n\\n### 1. Check `WANDB_WATCH` Environment Variable\\nEnsure that the `WANDB_WATCH` environment variable is set correctly. This variable controls whether model gradients and parameters are logged. You should set it to `all` to log both gradients and parameters.\\n\\n```python\\nimport os\\nos.environ[\\'WANDB_WATCH\\'] = \\'all\\'  # Log histograms of gradients and parameters\\n```\\n\\nOr, you can set this in your terminal before running your script:\\n```bash\\nexport WANDB_WATCH=all\\n```\\n\\n### 2. Verify Integration in Your Script\\nMake sure that the `report_to` argument in your `TrainingArguments` or script is set to `wandb`. This ensures that the Hugging Face integration with Weights & Biases is active.\\n\\n```python\\nfrom transformers import TrainingArguments\\n\\ntraining_args = TrainingArguments(\\n    report_to=\"wandb\",\\n    ...\\n)\\n```\\n\\n### 3. Check for Any Overrides in Your Code\\nSometimes, specific settings in your code might override the environment variables. Look for any lines in your script that might be setting `WANDB_WATCH` to `false` or modifying other related settings.\\n\\n### 4. Reset W&B Environment Variables\\nIf you suspect that your environment variables are not set correctly, you can reset them. Here\\'s how you can set them to typical values for logging with Hugging Face:\\n\\n```python\\n# Set environment variables\\nos.environ[\\'WANDB_WATCH\\'] = \\'all\\'  # Ensure all parameters and gradients are logged\\nos.environ[\\'WANDB_LOG_MODEL\\'] = \\'true\\'  # Log model as an artifact\\nos.environ[\\'WANDB_PROJECT\\'] = \\'your_project_name\\'  # Specify your project name\\n```\\n\\n### 5. Re-login to W&B\\nSometimes, simply re-authenticating can resolve issues. Make sure you are logged in to W&B:\\n\\n```python\\nimport wandb\\nwandb.login()\\n```\\n\\n### 6. Update W&B and Hugging Face Libraries\\nEnsure that you are using the latest versions of both `wandb` and `transformers` libraries, as updates often fix bugs and improve integration features.\\n\\n```bash\\npip install --upgrade wandb transformers\\n```\\n\\n### 7. Review W&B Dashboard\\nCheck your W&B dashboard to see if there are any error messages or warnings that might give you more context about what\\'s going wrong.\\n\\nBy following these steps, you should be able to resolve the issue with logging model parameters in Weights & Biases when using a Hugging Face model. If the problem persists, consider reaching out to W&B support or checking the [community forums](https://wandb.me/community) for more help.', 'contexts': [{'content': 'Additional W&B settings\\nFurther configuration of what is logged with `Trainer` is possible by setting environment variables. A full list of W&B environment variables can be found here.\\nEnvironment Variable\\nUsage\\n`WANDB_PROJECT`\\nGive your project a name (`huggingface` by default)\\n`WANDB_LOG_MODEL`\\nLog the model checkpoint as a W&B Artifact (`false` by default) \\n`false` (default): No model checkpointing `checkpoint`: A checkpoint will be uploaded every args.save_steps (set in the Trainer\\'s TrainingArguments). `end`: The final model checkpoint will be uploaded at the end of training.\\n`WANDB_WATCH`\\nSet whether you\\'d like to log your models gradients, parameters or neither\\n`false` (default): No gradient or parameter logging `gradients`: Log histograms of the gradients `all`: Log histograms of gradients and parameters\\n`WANDB_DISABLED`\\nSet to `true` to disable logging entirely (`false` by default)\\n`WANDB_SILENT`\\nSet to `true` to silence the output printed by wandb (`false` by default)\\nWANDB_WATCH=all\\nWANDB_SILENT=true\\n%env WANDB_WATCH=all\\n%env WANDB_SILENT=true\\nCustomize wandb.init\\nThe `WandbCallback` that `Trainer` uses will call `wandb.init` under the hood when `Trainer` is initialized. You can alternatively set up your runs manually by calling `wandb.init` before the`Trainer` is initialized. This gives you full control over your W&B run configuration.\\nAn example of what you might want to pass to `init` is below. For more details on how to use `wandb.init`, check out the reference documentation.\\nwandb.init(\\n    project=\"amazon_sentiment_analysis\",\\n    name=\"bert-base-high-lr\",\\n    tags=[\"baseline\", \"high-lr\"],\\n    group=\"bert\",\\n)', 'source': 'guides/integrations/huggingface.md', 'score': 0.96260285, 'relevance': 2}, {'content': '4) Turn on model checkpointing\\nUsing Weights & Biases\\' Artifacts, you can store up to 100GB of models and datasets for free and then use the Weights & Biases Model Registry to register models to prepare them for staging or deployment in your production environment.\\nLogging your Hugging Face model checkpoints to Artifacts can be done by setting the `WANDB_LOG_MODEL` environment variable to one of `end` or `checkpoint` or `false`: \\n`checkpoint`: a checkpoint will be uploaded every `args.save_steps` from the TrainingArguments. \\n`end`:  the model will be uploaded at the end of training. \\nUse `WANDB_LOG_MODEL` along with `load_best_model_at_end` to upload the best model at the end of training.\\nimport os\\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\\nWANDB_LOG_MODEL=\"checkpoint\"\\n%env WANDB_LOG_MODEL=\"checkpoint\"\\nAny Transformers `Trainer` you initialize from now on will upload models to your W&B project. The model checkpoints you log will be viewable through the Artifacts UI, and include the full model lineage (see an example model checkpoint in the UI here. \\n:::info\\nBy default, your model will be saved to W&B Artifacts as `model-{run_id}` when `WANDB_LOG_MODEL` is set to `end` or `checkpoint-{run_id}` when `WANDB_LOG_MODEL` is set to `checkpoint`.\\nHowever, If you pass a run_name in your `TrainingArguments`, the model will be saved as `model-{run_name}` or `checkpoint-{run_name}`.\\n:::\\nW&B Model Registry\\nOnce you have logged your checkpoints to Artifacts, you can then register your best model checkpoints and centralize them across your team using the Weights & Biases Model Registry. Here you can organize your best models by task, manage model lifecycle, facilitate easy tracking and auditing throughout the ML lifecyle, and automate downstream actions with webhooks or jobs. \\nSee the Model Registry documentation for how to link a model Artifact to the Model Registry.', 'source': 'guides/integrations/huggingface.md', 'score': 0.6389479, 'relevance': 2}, {'content': 'Loading a saved model\\nIf you saved your model to W&B Artifacts with `WANDB_LOG_MODEL`, you can download your model weights for additional training or to run inference. You just load them back into the same Hugging Face architecture that you used before.\\n# Create a new run\\nwith wandb.init(project=\"amazon_sentiment_analysis\") as run:\\n    # Pass the name and version of Artifact\\n    my_model_name = \"model-bert-base-high-lr:latest\"\\n    my_model_artifact = run.use_artifact(my_model_name)\\n    # Download model weights to a folder and return the path\\n    model_dir = my_model_artifact.download()\\n    # Load your Hugging Face model from that folder\\n    #  using the same model class\\n    model = AutoModelForSequenceClassification.from_pretrained(\\n        model_dir, num_labels=num_labels\\n    )\\n    # Do additional training, or run inference\\nResume training from a checkpoint\\nIf you had set `WANDB_LOG_MODEL=\\'checkpoint\\'` you can also resume training by you can using the `model_dir` as the `model_name_or_path` argument in your `TrainingArguments` and pass `resume_from_checkpoint=True` to `Trainer`.\\nlast_run_id = \"xxxxxxxx\"  # fetch the run_id from your wandb workspace\\n# resume the wandb run from the run_id\\nwith wandb.init(\\n    project=os.environ[\"WANDB_PROJECT\"],\\n    id=last_run_id,\\n    resume=\"must\",\\n) as run:\\n    # Connect an Artifact to the run\\n    my_checkpoint_name = f\"checkpoint-{last_run_id}:latest\"\\n    my_checkpoint_artifact = run.use_artifact(my_model_name)\\n    # Download checkpoint to a folder and return the path\\n    checkpoint_dir = my_checkpoint_artifact.download()\\n    # reinitialize your model and trainer\\n    model = AutoModelForSequenceClassification.from_pretrained(\\n        \"<model_name>\", num_labels=num_labels\\n    )\\n    # your awesome training arguments here.\\n    training_args = TrainingArguments()\\n    trainer = Trainer(model=model, args=training_args)\\n    # make sure use the checkpoint dir to resume training from the checkpoint\\n    trainer.train(resume_from_checkpoint=checkpoint_dir)', 'source': 'guides/integrations/huggingface.md', 'score': 0.684053, 'relevance': 1}, {'content': \"Hugging Face\\nTry in a Colab Notebook here →\\nVisualize your Hugging Face model's performance quickly with a seamless W&B integration.\\nCompare hyperparameters, output metrics, and system stats like GPU utilization across your models. \\n🤔 Why should I use W&B?\\nUnified dashboard: Central repository for all your model metrics and predictions\\nLightweight: No code changes required to integrate with Hugging Face\\nAccessible: Free for individuals and academic teams\\nSecure: All projects are private by default\\nTrusted: Used by machine learning teams at OpenAI, Toyota, Lyft and more\\nThink of W&B like GitHub for machine learning models— save machine learning experiments to your private, hosted dashboard. Experiment quickly with the confidence that all the versions of your models are saved for you, no matter where you're running your scripts.\\nW&B lightweight integrations works with any Python script, and all you need to do is sign up for a free W&B account to start tracking and visualizing your models.\\nIn the Hugging Face Transformers repo, we've instrumented the Trainer to automatically log training and evaluation metrics to W&B at each logging step.\\nHere's an in depth look at how the integration works: Hugging Face + W&B Report.\\n🚀 Install, Import, and Log in\\nInstall the Hugging Face and Weights & Biases libraries, and the GLUE dataset and training script for this tutorial.\\n- Hugging Face Transformers: Natural language models and datasets\\n- Weights & Biases: Experiment tracking and visualization\\n- GLUE dataset: A language understanding benchmark dataset\\n- GLUE script: Model training script for sequence classification\\n!pip install datasets wandb evaluate accelerate -qU\\n!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py\\n# the run_glue.py script requires transformers dev\\n!pip install -q git+https://github.com/huggingface/transformers\\n🖊️ Sign up for a free account →\\n🔑 Put in your API key\\nOnce you've signed up, run the next cell and click on the link to get your API key and authenticate this notebook.\\nimport wandb\\nwandb.login()\\nOptionally, we can set environment variables to customize W&B logging. See documentation.\\n# Optional: log both gradients and parameters\\n%env WANDB_WATCH=all\", 'source': 'tutorials/huggingface.md', 'score': 0.6166473, 'relevance': 1}, {'content': 'Hugging Face Transformers\\nThe Hugging Face Transformers library makes state-of-the-art NLP models like BERT and training techniques like mixed precision and gradient checkpointing easy to use. The W&B integration adds rich, flexible experiment tracking and model versioning to interactive centralized dashboards without compromising that ease of use.\\n🤗 Next-level logging in few lines\\nos.environ[\"WANDB_PROJECT\"] = \"<my-amazing-project>\"  # name your W&B project\\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints\\nfrom transformers import TrainingArguments, Trainer\\nargs = TrainingArguments(..., report_to=\"wandb\")  # turn on W&B logging\\ntrainer = Trainer(..., args=args)\\n:::info\\nIf you\\'d rather dive straight into working code, check out this Google Colab.\\n:::\\nGetting started: track experiments\\n1) Sign Up, install the wandb library and log in\\na) Sign up for a free account\\nb) Pip install the `wandb` library\\nc) To log in in your training script, you\\'ll need to be signed in to you account at www.wandb.ai, then you will find your API key on the Authorize page.\\nIf you are using Weights and Biases for the first time you might want to check out our quickstart\\npip install wandb\\nwandb login\\n!pip install wandb\\nimport wandb\\nwandb.login()\\n2) Name the project\\nA Project is where all of the charts, data, and models logged from related runs are stored. Naming your project helps you organize your work and keep all the information about a single project in one place.\\nTo add a run to a project simply set the `WANDB_PROJECT` environment variable to the name of your project. The `WandbCallback` will pick up this project name environment variable and use it when setting up your run.\\nWANDB_PROJECT=amazon_sentiment_analysis\\n%env WANDB_PROJECT=amazon_sentiment_analysis\\nimport os\\nos.environ[\"WANDB_PROJECT\"]=\"amazon_sentiment_analysis\"\\n:::info\\nMake sure you set the project name before you initialize the `Trainer`.\\n:::\\nIf a project name is not specified the project name defaults to \"huggingface\".', 'source': 'guides/integrations/huggingface.md', 'score': 0.2724115, 'relevance': 1}, {'content': \"Run The Library With wandb As Optional\\nIf you want to make `wandb` optional when your users use your library, you can either:\\nDefine a `wandb` flag such as:\\ntrainer = my_trainer(..., use_wandb=True)\\npython train.py ... --use-wandb\\nOr, set `wandb` to be disabled in `wandb.init`\\nwandb.init(mode=“disabled”)\\nexport WANDB_MODE=disabled\\nor\\nwandb disabled\\nOr, set `wandb` to be offline - note this will still run `wandb`, it just won't try and communicate back to W&B over the internet\\nexport WANDB_MODE=offline\\nor\\nos.environ['WANDB_MODE'] = 'offline'\\nwandb offline\\nDefining A wandb Run Config\\nWith a `wandb` run config you can provide metadata about your model, dataset, and so on when you create a W&B Run. You can use this information to compare different experiments and quickly understand what are the main differences.\\nTypical config parameters you can log include:\\nModel name, version, architecture parameters etc\\nDataset name, version, number of train/val examples etc\\nTraining parameters such as learning rate, batch size, optimizer etc\\nThe following code snippet shows how to log a config:\\nconfig = {“batch_size”:32, …}\\nwandb.init(…, config=config)\\nUpdating The wandb config\\nUse `wandb.config.update` to update the config. Updating your configuration dictionary is useful when parameters are obtained after the dictionary was defined, for example you might want to add a model’s parameters after the model is instantiated.\\nwandb.config.update({“model_parameters” = 3500})\\nFor more information on how to define a config file, see Configure Experiments with wandb.config\\nLogging To W&B\", 'source': 'guides/integrations/add-wandb-to-any-library.md', 'score': 0.16344544, 'relevance': 0}, {'content': 'import os\\nimport wandb\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\nconfig = {\"optimizer\": \"adam\", \"loss\": \"categorical_crossentropy\"}\\n# Initialize a W&B run\\nrun = wandb.init(entity=\"charlie\", project=\"mnist-experiments\", config=config)\\n# Hyperparameters\\nloss = run.config[\"loss\"]\\noptimizer = run.config[\"optimizer\"]\\nmetrics = [\"accuracy\"]\\nnum_classes = 10\\ninput_shape = (28, 28, 1)\\n# Training algorithm\\nmodel = keras.Sequential(\\n    [\\n        layers.Input(shape=input_shape),\\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\\n        layers.MaxPooling2D(pool_size=(2, 2)),\\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\\n        layers.MaxPooling2D(pool_size=(2, 2)),\\n        layers.Flatten(),\\n        layers.Dropout(0.5),\\n        layers.Dense(num_classes, activation=\"softmax\"),\\n    ]\\n)\\n# Configure the model for training\\nmodel.compile(loss=loss, optimizer=optimizer, metrics=metrics)\\n# Save model\\nmodel_filename = \"model.h5\"\\nlocal_filepath = \"./\"\\nfull_path = os.path.join(local_filepath, model_filename)\\nmodel.save(filepath=full_path)\\n# Log the model to the W&B run\\nrun.log_model(path=full_path, name=\"MNIST\")\\nrun.finish()\\nWhen the user called `log_model`, a model artifact named `MNIST` was created and the file `model.h5` was added to the model artifact. Your terminal or notebook will print information of where to find information about the run the model was logged to.\\nView run different-surf-5 at: https://wandb.ai/charlie/mnist-experiments/runs/wlby6fuw\\nSynced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)\\nFind logs at: ./wandb/run-20231206_103511-wlby6fuw/logs', 'source': 'guides/track/log/log-models.md', 'score': 0.07172112, 'relevance': 0}, {'content': '👟 Train the model\\nNext, call the downloaded training script run_glue.py and see training automatically get tracked to the Weights & Biases dashboard. This script fine-tunes BERT on the Microsoft Research Paraphrase Corpus— pairs of sentences with human annotations indicating whether they are semantically equivalent.\\n%env WANDB_PROJECT=huggingface-demo\\n%env TASK_NAME=MRPC\\n!python run_glue.py \\\\\\n  --model_name_or_path bert-base-uncased \\\\\\n  --task_name $TASK_NAME \\\\\\n  --do_train \\\\\\n  --do_eval \\\\\\n  --max_seq_length 256 \\\\\\n  --per_device_train_batch_size 32 \\\\\\n  --learning_rate 2e-4 \\\\\\n  --num_train_epochs 3 \\\\\\n  --output_dir /tmp/$TASK_NAME/ \\\\\\n  --overwrite_output_dir \\\\\\n  --logging_steps 50\\n👀 Visualize results in dashboard\\nClick the link printed out above, or go to wandb.ai to see your results stream in live. The link to see your run in the browser will appear after all the dependencies are loaded — look for the following output: \"wandb: 🚀 View run at [URL to your unique run]\"\\nVisualize Model Performance\\nIt\\'s easy to look across dozens of experiments, zoom in on interesting findings, and visualize highly dimensional data.\\nCompare Architectures\\nHere\\'s an example comparing BERT vs DistilBERT — it\\'s easy to see how different architectures effect the evaluation accuracy throughout training with automatic line plot visualizations.\\n📈 Track key information effortlessly by default\\nWeights & Biases saves a new run for each experiment. Here\\'s the information that gets saved by default:\\n- Hyperparameters: Settings for your model are saved in Config\\n- Model Metrics: Time series data of metrics streaming in are saved in Log\\n- Terminal Logs: Command line outputs are saved and available in a tab\\n- System Metrics: GPU and CPU utilization, memory, temperature etc.\\n🤓 Learn more!\\nDocumentation: docs on the Weights & Biases and Hugging Face integration\\nVideos: tutorials, interviews with practitioners, and more on our YouTube channel\\nContact: Message us at contact@wandb.com with questions', 'source': 'tutorials/huggingface.md', 'score': 0.06359858, 'relevance': 0}, {'content': 'Keras Models\\nTry in a Colab Notebook here →\\nUse Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.\\nThis colab notebook introduces the `WandbModelCheckpoint` callback. Use this callback to log your model checkpoints to Weight and Biases Artifacts.\\n🌴 Setup and Installation\\nFirst, let us install the latest version of Weights and Biases. We will then authenticate this colab instance to use W&B.\\n!pip install -qq -U wandb\\nimport os\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nfrom tensorflow.keras import models\\nimport tensorflow_datasets as tfds\\n# Weights and Biases related imports\\nimport wandb\\nfrom wandb.integration.keras import WandbMetricsLogger\\nfrom wandb.integration.keras import WandbModelCheckpoint\\nIf this is your first time using W&B or you are not logged in, the link that appears after running `wandb.login()` will take you to sign-up/login page. Signing up for a free account is as easy as a few clicks.\\nwandb.login()\\n🌳 Hyperparameters\\nUse of proper config system is a recommended best practice for reproducible machine learning. We can track the hyperparameters for every experiment using W&B. In this colab we will be using simple Python `dict` as our config system.\\nconfigs = dict(\\n    num_classes = 10,\\n    shuffle_buffer = 1024,\\n    batch_size = 64,\\n    image_size = 28,\\n    image_channels = 1,\\n    earlystopping_patience = 3,\\n    learning_rate = 1e-3,\\n    epochs = 10\\n)', 'source': 'tutorials/keras_models.md', 'score': 0.044265877, 'relevance': 0}, {'content': \"MMF\\nThe `WandbLogger` class in Meta AI's MMF library will enable Weights & Biases to log the training/validation metrics, system (GPU and CPU) metrics, model checkpoints and configuration parameters.\\nCurrent features\\nThe following features are currently supported by the `WandbLogger` in MMF:\\nTraining & Validation metrics\\nLearning Rate over time\\nModel Checkpoint saving to W&B Artifacts\\nGPU and CPU system metrics\\nTraining configuration parameters\\nConfig parameters\\nThe following options are available in MMF config to enable and customize the wandb logging:\\ntraining:\\n    wandb:\\n        enabled: true\\n        # An entity is a username or team name where you're sending runs.\\n        # By default it will log the run to your user account.\\n        entity: null\\n        # Project name to be used while logging the experiment with wandb\\n        project: mmf\\n        # Experiment/ run name to be used while logging the experiment\\n        # under the project with wandb. The default experiment name\\n        # is: ${training.experiment_name}\\n        name: ${training.experiment_name}\\n        # Turn on model checkpointing, saving checkpoints to W&B Artifacts\\n        log_model_checkpoint: true\\n        # Additional argument values that you want to pass to wandb.init(). \\n        # Check out the documentation at https://docs.wandb.ai/ref/python/init\\n        # to see what arguments are available, such as:\\n        # job_type: 'train'\\n        # tags: ['tag1', 'tag2']\\nenv:\\n    # To change the path to the directory where wandb metadata would be \\n    # stored (Default: env.log_dir):\\n    wandb_logdir: ${env:MMF_WANDB_LOGDIR,}\", 'source': 'guides/integrations/other/mmf.md', 'score': 0.027117657000000003, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'can we stopped to automatically add new config params when a new run is added to an experiment?', 'answer': 'In Weights & Biases, when you initialize a new run using `wandb.init()`, any configuration parameters you specify are automatically added to the run\\'s configuration. However, if you want to prevent automatic updates or additions to the configuration after the run has started, you can control this behavior using the `allow_val_change` attribute of the `wandb.config` object.\\n\\nTo prevent new configuration parameters from being automatically added after the run has started, you can set `allow_val_change` to `False`. This setting will ensure that once the configuration is set during the initialization of the run, no new keys can be added, and existing keys cannot be modified. Here\\'s how you can implement this:\\n\\n```python\\nimport wandb\\n\\n# Initialize a new run\\nrun = wandb.init(project=\"your_project_name\", config={\\n    \"parameter1\": value1,\\n    \"parameter2\": value2\\n})\\n\\n# Set allow_val_change to False to prevent changes\\nwandb.config.allow_val_change = False\\n\\n# Attempting to add a new parameter or change an existing one will now raise an error\\n# wandb.config[\"new_parameter\"] = new_value  # This will raise an error\\n```\\n\\nThis setup is particularly useful when you want to ensure the integrity of your experiment configurations and prevent accidental changes or additions after the run has started.', 'contexts': [{'content': 'Set the configuration throughout your script\\nYou can add more parameters to your config object throughout your script. The proceeding code snippet demonstrates how to add new key-value pairs to your config object:\\nimport wandb\\n# Define a config dictionary object\\nconfig = {\\n    \"hidden_layer_sizes\": [32, 64],\\n    \"kernel_sizes\": [3],\\n    \"activation\": \"ReLU\",\\n    \"pool_sizes\": [2],\\n    \"dropout\": 0.5,\\n    \"num_classes\": 10,\\n}\\n# Pass the config dictionary when you initialize W&B\\nrun = wandb.init(project=\"config_example\", config=config)\\n# Update config after you initialize W&B\\nwandb.config[\"dropout\"] = 0.2\\nwandb.config.epochs = 4\\nwandb.config[\"batch_size\"] = 32\\nYou can update multiple values at a time:\\nwandb.init(config={\"epochs\": 4, \"batch_size\": 32})\\n# later\\nwandb.config.update({\"lr\": 0.1, \"channels\": 16})\\nSet the configuration after your Run has finished\\nUse the W&B Public API to update your config (or anything else about from a complete Run) after your Run. This is particularly useful if you forgot to log a value during a Run. \\nProvide your `entity`, `project name`, and the `Run ID` to update your configuration after a Run has finished. Find these values directly from the Run object itself `wandb.run` or from the W&B App UI:\\napi = wandb.Api()\\n# Access attributes directly from the run object\\n# or from the W&B App\\nusername = wandb.run.entity\\nproject = wandb.run.project\\nrun_id = wandb.run.id\\nrun = api.run(f\"{username}/{project}/{run_id}\")\\nrun.config[\"bar\"] = 32\\nrun.update()\\nabsl.FLAGS\\nYou can also pass in absl flags.\\nflags.DEFINE_string(\"model\", None, \"model to run\")  # name, default, help\\nwandb.config.update(flags.FLAGS)  # adds absl flags to config', 'source': 'guides/track/config.md', 'score': 0.7862948, 'relevance': 2}, {'content': 'Configure Experiments\\nConfigure a Machine Learning Experiment\\nTry in a Colab Notebook here\\nUse the `wandb.config` object to save your training configuration such as: \\n- hyperparameters\\n- input settings such as the dataset name or model type\\n- any other independent variables for your experiments. \\nThe `wandb.config` attribute makes it easy to analyze your experiments and reproduce your work in the future. You can group by configuration values in the W&B App, compare the settings of different W&B Runs and view how different training configurations affect the output. A Run\\'s `config` attribute is a dictionary-like object, and it can be built from lots of dictionary-like objects.\\n:::info\\nDependent variables (like loss and accuracy) or output metrics should be saved with `wandb.log`instead.\\n:::\\nSet up an experiment configuration\\nConfigurations are typically defined in the beginning of a training script. Machine learning workflows may vary, however, so you are not required to define a configuration at the beginning of your training script.\\n:::caution\\nWe recommend that you avoid using dots in your config variable names. Instead, use a dash or underscore instead. Use the dictionary access syntax `[\"key\"][\"foo\"]` instead of the attribute access syntax `config.key.foo` if your script accesses `wandb.config` keys below the root.\\n:::\\nThe following sections outline different common scenarios of how to define your experiments configuration.', 'source': 'guides/track/config.md', 'score': 0.08464396, 'relevance': 2}, {'content': 'Access run config inputs\\nJobs launched with run config inputs can access the input values through the `Run.config`. The `Run` returned by `wandb.init` in the job code will have the input values automatically set. Use \\nfrom wandb.sdk import launch\\nrun_config_overrides = launch.load_wandb_config()\\nto load the run config input values anywhere in the job code.\\nReconfigure a file\\nThe Launch SDK also provides a way to manage input values stored in config files in the job code. This is a common pattern in many deep learning and large language model use cases, like this torchtune example or this Axolotl config). \\n:::info\\nSweeps on Launch does not support the use of config file inputs as sweep parameters. Sweep parameters must be controlled through the `Run.config` object.\\n:::\\nThe `launch.manage_config_file` function can be used to add a config file as an input to the Launch job, giving you access to edit values within the config file when launching the job.\\nBy default, no run config inputs will be captured if `launch.manage_config_file` is used. Calling `launch.manage_wandb_config` overrides this behavior.\\nConsider the following example:\\nimport yaml\\nimport wandb\\nfrom wandb.sdk import launch\\n# Required for launch sdk use.\\nwandb.require(\"core\")\\nlaunch.manage_config_file(\"config.yaml\")\\nwith open(\"config.yaml\", \"r\") as f:\\n    config = yaml.safe_load(f)\\nwith wandb.init(config=config):\\n    # Etc.\\n    pass\\nImagine the code is run with an adjacent file `config.yaml`:\\nlearning_rate: 0.01\\nbatch_size: 32\\nmodel: resnet\\ndataset: cifar10\\nThe call to `launch.manage_config_file` will add the `config.yaml` file as an input to the job, making it reconfigurable when launching from the W&B CLI or UI. \\nThe `include` and `exclude` keyword arugments may be used to filter the acceptable input keys for the config file in the same way as `launch.manage_wandb_config`.', 'source': 'guides/launch/job-inputs.md', 'score': 0.16572809, 'relevance': 1}, {'content': 'Reconfigure the Run object\\nThe `Run` object returned by `wandb.init` in a job can be reconfigured, by default. The Launch SDK provides a way to customize what parts of the `Run.config` object can be reconfigured when launching the job.\\nimport wandb\\nfrom wandb.sdk import launch\\n# Required for launch sdk use.\\nwandb.require(\"core\")\\nconfig = {\\n    \"trainer\": {\\n        \"learning_rate\": 0.01,\\n        \"batch_size\": 32,\\n        \"model\": \"resnet\",\\n        \"dataset\": \"cifar10\",\\n        \"private\": {\\n            \"key\": \"value\",\\n        },\\n    },\\n    \"seed\": 42,\\n}\\nwith wandb.init(config=config):\\n    launch.manage_wandb_config(\\n        include=[\"trainer\"], \\n        exclude=[\"trainer.private\"],\\n    )\\n    # Etc.\\nThe function `launch.manage_wandb_config` configures the job to accept input values for the `Run.config` object.  The optional `include` and `exclude` options take path prefixes within the nested config object.  This can be useful if, for example, a job uses a library whose options you don\\'t want to expose to end users.  \\nIf `include` prefixes are provided, only paths within the config that match an `include` prefix will accept input values. If `exclude` prefixes are provided, no paths that match the `exclude` list will be filtered out of the input values. If a path matches both an `include` and an `exclude` prefix, the `exclude` prefix will take precedence.\\nIn the preceding example, the path `[\"trainer.private\"]` will filter out the `private` key from the `trainer` object, and the path `[\"trainer\"]` will filter out all keys not under the `trainer` object.\\n:::tip\\nUse a ``-escaped `.` to filter out keys with a `.` in their name. \\nFor example, `r\"trainer\\\\.private\"` filters out the `trainer.private` key rather than the `private` key under the `trainer` object.\\nNote that the `r` prefix above denotes a raw string.\\n:::\\nIf the code above is packaged and run as a job, the input types of the job will be:', 'source': 'guides/launch/job-inputs.md', 'score': 0.0005152657, 'relevance': 1}, {'content': \"Run The Library With wandb As Optional\\nIf you want to make `wandb` optional when your users use your library, you can either:\\nDefine a `wandb` flag such as:\\ntrainer = my_trainer(..., use_wandb=True)\\npython train.py ... --use-wandb\\nOr, set `wandb` to be disabled in `wandb.init`\\nwandb.init(mode=“disabled”)\\nexport WANDB_MODE=disabled\\nor\\nwandb disabled\\nOr, set `wandb` to be offline - note this will still run `wandb`, it just won't try and communicate back to W&B over the internet\\nexport WANDB_MODE=offline\\nor\\nos.environ['WANDB_MODE'] = 'offline'\\nwandb offline\\nDefining A wandb Run Config\\nWith a `wandb` run config you can provide metadata about your model, dataset, and so on when you create a W&B Run. You can use this information to compare different experiments and quickly understand what are the main differences.\\nTypical config parameters you can log include:\\nModel name, version, architecture parameters etc\\nDataset name, version, number of train/val examples etc\\nTraining parameters such as learning rate, batch size, optimizer etc\\nThe following code snippet shows how to log a config:\\nconfig = {“batch_size”:32, …}\\nwandb.init(…, config=config)\\nUpdating The wandb config\\nUse `wandb.config.update` to update the config. Updating your configuration dictionary is useful when parameters are obtained after the dictionary was defined, for example you might want to add a model’s parameters after the model is instantiated.\\nwandb.config.update({“model_parameters” = 3500})\\nFor more information on how to define a config file, see Configure Experiments with wandb.config\\nLogging To W&B\", 'source': 'guides/integrations/add-wandb-to-any-library.md', 'score': 0.49894142, 'relevance': 0}, {'content': 'launch_add\\nView source on GitHub\\nEnqueue a W&B launch experiment. With either a source uri, job or docker_image.\\nlaunch_add(\\n    uri: Optional[str] = None,\\n    job: Optional[str] = None,\\n    config: Optional[Dict[str, Any]] = None,\\n    template_variables: Optional[Dict[str, Union[float, int, str]]] = None,\\n    project: Optional[str] = None,\\n    entity: Optional[str] = None,\\n    queue_name: Optional[str] = None,\\n    resource: Optional[str] = None,\\n    entry_point: Optional[List[str]] = None,\\n    name: Optional[str] = None,\\n    version: Optional[str] = None,\\n    docker_image: Optional[str] = None,\\n    project_queue: Optional[str] = None,\\n    resource_args: Optional[Dict[str, Any]] = None,\\n    run_id: Optional[str] = None,\\n    build: Optional[bool] = (False),\\n    repository: Optional[str] = None,\\n    sweep_id: Optional[str] = None,\\n    author: Optional[str] = None,\\n    priority: Optional[int] = None\\n) -> \"public.QueuedRun\"', 'source': 'ref/python/launch-library/launch_add.md', 'score': 0.005934067, 'relevance': 0}, {'content': 'Next steps: Visualize your experiment\\nUse the W&B Dashboard as a central place to organize and visualize results from your machine learning models. With just a few clicks, construct rich, interactive charts like parallel coordinates plots, parameter importance analyzes, and more.\\nFor more information on how to view experiments and specific runs, see Visualize results from experiments.\\nBest Practices\\nThe following are some suggested guidelines to consider when you create experiments:\\nConfig: Track hyperparameters, architecture, dataset, and anything else you\\'d like to use to reproduce your model. These will show up in columns— use config columns to group, sort, and filter runs dynamically in the app.\\nProject: A project is a set of experiments you can compare together. Each project gets a dedicated dashboard page, and you can easily turn on and off different groups of runs to compare different model versions.\\nNotes: A quick commit message to yourself. The note can be set from your script. You can edit notes at a later time on the Overview section of your project\\'s dashboard on the W&B App.\\nTags: Identify baseline runs and favorite runs. You can filter runs using tags. You can edit tags at a later time on the Overview section of your project\\'s dashboard on the W&B App.\\nThe following code snippet demonstrates how to define a W&B Experiment using the best practices listed above:\\nimport wandb\\nconfig = dict(\\n    learning_rate=0.01, momentum=0.2, architecture=\"CNN\", dataset_id=\"cats-0192\"\\n)\\nwandb.init(\\n    project=\"detect-cats\",\\n    notes=\"tweak baseline\",\\n    tags=[\"baseline\", \"paper1\"],\\n    config=config,\\n)\\nFor more more information about available parameters when defining a W&B Experiment, see the wandb.init API docs in the API Reference Guide.', 'source': 'guides/track/launch.md', 'score': 0.004556114, 'relevance': 0}, {'content': \"parameters_dict.update({\\n    'learning_rate': {\\n        # a flat distribution between 0 and 0.1\\n        'distribution': 'uniform',\\n        'min': 0,\\n        'max': 0.1\\n      },\\n    'batch_size': {\\n        # integers between 32 and 256\\n        # with evenly-distributed logarithms \\n        'distribution': 'q_log_uniform_values',\\n        'q': 8,\\n        'min': 32,\\n        'max': 256,\\n      }\\n    })\\nWhen we're finished, `sweep_config` is a nested dictionary\\nthat specifies exactly which `parameters` we're interested in trying\\nand what `method` we're going to use to try them.\\nimport pprint\\npprint.pprint(sweep_config)\\nBut that's not all of the configuration options!\\nFor example, we also offer the option to `early_terminate` your runs with the HyperBand scheduling algorithm. See more here.\\nYou can find a list of all configuration options here\\nand a big collection of examples in YAML format here.\", 'source': 'tutorials/sweeps.md', 'score': 0.0041019293, 'relevance': 0}, {'content': 'Enable runs to automatically resume\\nThe following code snippet shows how to enable runs to automatically resume with the Python SDK or with environment variables. \\nThe following code snippet shows how to specify a W&B run ID with the Python SDK. \\nReplace values enclosed within `<>` with your own:\\nrun = wandb.init(entity=\"<entity>\", \\\\ \\n        project=\"<project>\", id=\"<run ID>\", resume=\"<resume>\")\\nThe following example shows how to specify the W&B `WANDB_RUN_ID` variable in a bash script: \\nrun_experiment.sh\\nRUN_ID=\"$1\"\\nWANDB_RESUME=allow WANDB_RUN_ID=\"$RUN_ID\" python eval.py\\nWithin your terminal, you could run the shell script along with the W&B run ID. The following code snippet passes the run ID `akj172`: \\nsh run_experiment.sh akj172 \\n:::important\\nAutomatic resuming only works if the process is restarted on top of the same filesystem as the failed process. \\n:::\\nFor example, suppose you execute a python script called `train.py` in a directory called called `Users/AwesomeEmployee/Desktop/ImageClassify/training/`. Within `train.py`, the script creates a run that enables automatic resuming. Suppose next that the training script is stopped.  To resume this run, you would need to restart your `train.py` script within `Users/AwesomeEmployee/Desktop/ImageClassify/training/` .\\n:::tip\\nIf you can not share a filesystem, specify the `WANDB_RUN_ID` environment variable or pass the run ID with the W&B Python SDK. See the Create a run section in the \"What are runs?\" page for more information on run IDs.\\n:::', 'source': 'guides/runs/resuming.md', 'score': 0.003991728, 'relevance': 0}, {'content': 'More Resources\\nAutoTrain Advanced now supports Experiment Tracking by Rishiraj Acharya.\\n🤗 Autotrain Docs', 'source': 'guides/integrations/autotrain.md', 'score': 3.42685e-05, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'I feel wandb cannot connect the server, how can I test it on the terminal', 'answer': \"To test the connection to the `wandb` server from the terminal, you can follow these steps:\\n\\n### Step 1: Check Server Health\\nYou can use a simple `curl` command to check if the server is responding. Replace `your_server_url` with the actual URL of your W&B server.\\n\\n```bash\\ncurl your_server_url\\n```\\n\\nIf the server is up and running, you should receive a response from this command. If there's no response, it indicates that the server might not be reachable.\\n\\n### Step 2: Verify Local Configuration\\nEnsure that your local `wandb` configuration is set up correctly. You can check the current settings by running:\\n\\n```bash\\nwandb settings\\n```\\n\\nLook for the `base_url` setting to confirm that it's pointing to the correct server URL.\\n\\n### Step 3: Use `wandb verify` Command\\nYou can use the `wandb verify` command to test the connectivity and configuration of your local instance. This command performs several checks, including testing the connection to the specified W&B server.\\n\\n```bash\\nwandb verify\\n```\\n\\nThis command will output logs that can help you identify any connectivity or configuration issues.\\n\\n### Step 4: Check Network Issues\\nIf there are still issues, check your network settings. Firewalls or network policies might be blocking the connection to the server. You can use `ping` or `traceroute` to diagnose network connectivity issues.\\n\\n```bash\\nping your_server_url\\ntraceroute your_server_url\\n```\\n\\nThese commands help you determine if there are any network hops that are failing or if the server is unreachable.\\n\\n### Step 5: Review Logs\\nIf the above steps do not resolve the issue, check the logs for any error messages that might give more insight into what is going wrong. You can find the logs in the directory where you are running your `wandb` commands, typically under `wandb/debug.log`.\\n\\nBy following these steps, you should be able to diagnose and potentially resolve connectivity issues with the `wandb` server using terminal commands. If problems persist, consider reaching out to W&B support for further assistance.\", 'contexts': [{'content': 'Verify your installation\\nVery your W&B Server is configured properly. Run the following commands in your terminal:\\npip install wandb\\nwandb login --host=https://YOUR_DNS_DOMAIN\\nwandb verify\\nCheck log files to view any errors the W&B Server hits at startup. Run the following commands based on whether if you use Docker or Kubernetes: \\ndocker logs wandb-local\\nkubectl get pods\\nkubectl logs wandb-XXXXX-XXXXX\\nContact W&B Support if you encounter errors.', 'source': 'guides/hosting/self-managed/bare-metal.md', 'score': 0.99857306, 'relevance': 2}, {'content': 'wandb verify\\nUsage\\n`wandb verify [OPTIONS]`\\nSummary\\nVerify your local instance\\nOptions\\nOption\\nDescription\\n--host\\nTest a specific instance of W&B', 'source': 'ref/cli/wandb-verify.md', 'score': 0.9720456, 'relevance': 2}, {'content': 'Troubleshooting\\nIf wandb crashes, will it possibly crash my training run?\\nIt is extremely important to us that we never interfere with your training runs. We run wandb in a separate process to make sure that if wandb somehow crashes, your training will continue to run. If the internet goes out, wandb will continue to retry sending data to wandb.ai.\\nWhy is a run marked crashed in W&B when it’s training fine locally?\\nThis is likely a connection problem — if your server loses internet access and data stops syncing to W&B, we mark the run as crashed after a short period of retrying.\\nDoes logging block my training?\\n\"Is the logging function lazy? I don\\'t want to be dependent on the network to send the results to your servers and then carry on with my local operations.\"\\nCalling `wandb.log` writes a line to a local file; it does not block any network calls. When you call `wandb.init` we launch a new process on the same machine that listens for filesystem changes and talks to our web service asynchronously from your training process.\\nHow do I stop wandb from writing to my terminal or my jupyter notebook output?\\nSet the environment variable WANDB_SILENT to `true`.\\nos.environ[\"WANDB_SILENT\"] = \"true\"\\n%env WANDB_SILENT=true\\nWANDB_SILENT=true\\nHow do I kill a job with wandb?\\nPress `Ctrl+D` on your keyboard to stop a script that is instrumented with wandb.\\nHow do I deal with network issues?\\nIf you\\'re seeing SSL or network errors:`wandb: Network error (ConnectionError), entering retry loop`. You can try a couple of different approaches to solving this issue:\\nUpgrade your SSL certificate. If you\\'re running the script on an Ubuntu server, run `update-ca-certificates` We can\\'t sync training logs without a valid SSL certificate because it\\'s a security vulnerability.\\nIf your network is flaky, run training in offline mode and sync the files to us from a machine that has Internet access.\\nTry running W&B Private Hosting, which operates on your machine and doesn\\'t sync files to our cloud servers.\\n`SSL CERTIFICATE_VERIFY_FAILED`: this error could be due to your company\\'s firewall. You can set up local CAs and then use:\\n`export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt`', 'source': 'guides/technical-faq/troubleshooting.md', 'score': 0.42572459999999995, 'relevance': 1}, {'content': 'Getting started\\nFollow this \"Hello, world!\" example to learn the general workflow to install W&B Server for Dedicated Cloud and Self Managed hosting options. By the end of this demo, you will know how to host W&B Server on your local machine using a Trial Mode W&B license. \\nFor demonstration purposes, this demo uses a local development server on port `8080` (`localhost:8080`).\\n:::tip\\nTrial Mode vs. Production Setup\\nIn Trial Mode, you run the Docker container on a single machine. This setup is ideal for testing the product, but it is not scalable.\\nFor production work, set up a scalable file system to avoid data loss. W&B strongly recommends that you:\\n* Allocate extra space in advance, \\n* Resize the file system proactively as you log more data\\n* Configure external metadata and object stores for backup.\\n:::\\nPrerequisites\\nBefore you get started, ensure your local machine satisfies the following requirements: \\nInstall Python\\nInstall Docker and ensure it is running\\nInstall or upgrade the latest version of W&B:\\n   \\npip install --upgrade wandb\\n1. Pull the W&B Docker image\\nRun the following in your terminal:\\nwandb server start\\nThis command pulls the latest W&B Docker image wandb/local.\\n2. Create a W&B account\\nNavigate to `http://localhost:8080/signup` and create an initial user account. Provide a name, email address, a username, and a password: \\nClick the Sign Up button to create a W&B account. \\n:::note\\nFor this demo, create a new W&B account even if you already have a W&B account. \\n:::\\nCopy your API key\\nAfter you create an account, navigate to `http://localhost:8080/authorize`.  \\nCopy the W&B API key that appears on the screen. At a later step, you will need this key at a later step to verify your login credentials.', 'source': 'guides/hosting/self-managed/basic-setup.md', 'score': 0.9837849999999999, 'relevance': 1}, {'content': 'Command Line Interface\\nUsage\\n`wandb [OPTIONS] COMMAND [ARGS]...`\\nOptions\\nOption\\nDescription\\n--version\\nShow the version and exit.\\nCommands\\nCommand\\nDescription\\nagent\\nRun the W&B agent\\nartifact\\nCommands for interacting with artifacts\\nbeta\\nBeta versions of wandb CLI commands.\\ncontroller\\nRun the W&B local sweep controller\\ndisabled\\nDisable W&B.\\ndocker\\nRun your code in a docker container.\\ndocker-run\\nWrap `docker run` and adds WANDB_API_KEY and WANDB_DOCKER...\\nenabled\\nEnable W&B.\\ninit\\nConfigure a directory with Weights & Biases\\njob\\nCommands for managing and viewing W&B jobs\\nlaunch\\nLaunch or queue a W&B Job.\\nlaunch-agent\\nRun a W&B launch agent.\\nlaunch-sweep\\nRun a W&B launch sweep (Experimental).\\nlogin\\nLogin to Weights & Biases\\noffline\\nDisable W&B sync\\nonline\\nEnable W&B sync\\npull\\nPull files from Weights & Biases\\nrestore\\nRestore code, config and docker state for a run\\nscheduler\\nRun a W&B launch sweep scheduler (Experimental)\\nserver\\nCommands for operating a local W&B server\\nstatus\\nShow configuration settings\\nsweep\\nInitialize a hyperparameter sweep.\\nsync\\nUpload an offline training directory to W&B\\nverify\\nVerify your local instance', 'source': 'ref/cli/README.md', 'score': 0.88798404, 'relevance': 1}, {'content': 'Launch a job\\nLet\\'s send a job to our agent. You can launch a simple \"hello world\" from a terminal logged into your W&B account with:\\nwandb launch -d wandb/job_hello_world:main -p <target-wandb-project> -q <your-queue-name> -e <your-queue-entity>\\nYou can test with any job or image you like, but make sure your cluster can pull your image.  See Minikube’s documentation for additional guidance. You can also test using one of our public jobs.', 'source': 'tutorials/minikube_gpu.md', 'score': 0.9906961, 'relevance': 0}, {'content': 'User Login\\nThere are a few ways for your users to log in to W&B:\\nLog into W&B with a bash command in a terminal\\nwandb login $MY_WANDB_KEY\\nIf they\\'re in a Jupyter or Colab notebook, log into W&B like so\\nimport wandb\\nwandb.login\\nSet a W&B environment variable for the API key\\nexport WANDB_API_KEY=$YOUR_API_KEY\\nor\\nos.environ[\\'WANDB_API_KEY\\'] = \"abc123...\"\\nIf a user is using wandb for the first time without following any of the steps mentioned above, they will automatically be prompted to login when your script calls `wandb.init`\\nStarting A wandb Run\\nA W&B Run is a unit of computation logged by W&B. Typically you associate a single W&B Run per training experiment.\\nInitialize W&B and start a Run within your code with:\\nwandb.init()\\nOptionally you can provide a name for their project, or let the user set it themselves with parameter such as `wandb_project` in your code along with the username or team name, such as `wandb_entity` , for the entity parameter:\\nwandb.init(project=wandb_project, entity=wandb_entity)\\nWhere To Place wandb.init?\\nYour library should create W&B Run as early as possible because any output in your console, including error messages, are logged as part of the W&B Run. This makes debugging easier.', 'source': 'guides/integrations/add-wandb-to-any-library.md', 'score': 0.6127153, 'relevance': 0}, {'content': 'wandb server\\nUsage\\n`wandb server [OPTIONS] COMMAND [ARGS]...`\\nSummary\\nCommands for operating a local W&B server\\nOptions\\nOption\\nDescription\\nCommands\\nCommand\\nDescription\\nstart\\nStart a local W&B server\\nstop\\nStop a local W&B server', 'source': 'ref/cli/wandb-server/README.md', 'score': 0.5115259999999999, 'relevance': 0}, {'content': \"wandb server start\\nUsage\\n`wandb server start [OPTIONS]`\\nSummary\\nStart a local W&B server\\nOptions\\nOption\\nDescription\\n-p, --port\\nThe host port to bind W&B server on\\n-e, --env\\nEnv vars to pass to wandb/local\\n--daemon / --no-daemon\\nRun or don't run in daemon mode\", 'source': 'ref/cli/wandb-server/wandb-server-start.md', 'score': 0.24310295, 'relevance': 0}, {'content': \"Run The Library With wandb As Optional\\nIf you want to make `wandb` optional when your users use your library, you can either:\\nDefine a `wandb` flag such as:\\ntrainer = my_trainer(..., use_wandb=True)\\npython train.py ... --use-wandb\\nOr, set `wandb` to be disabled in `wandb.init`\\nwandb.init(mode=“disabled”)\\nexport WANDB_MODE=disabled\\nor\\nwandb disabled\\nOr, set `wandb` to be offline - note this will still run `wandb`, it just won't try and communicate back to W&B over the internet\\nexport WANDB_MODE=offline\\nor\\nos.environ['WANDB_MODE'] = 'offline'\\nwandb offline\\nDefining A wandb Run Config\\nWith a `wandb` run config you can provide metadata about your model, dataset, and so on when you create a W&B Run. You can use this information to compare different experiments and quickly understand what are the main differences.\\nTypical config parameters you can log include:\\nModel name, version, architecture parameters etc\\nDataset name, version, number of train/val examples etc\\nTraining parameters such as learning rate, batch size, optimizer etc\\nThe following code snippet shows how to log a config:\\nconfig = {“batch_size”:32, …}\\nwandb.init(…, config=config)\\nUpdating The wandb config\\nUse `wandb.config.update` to update the config. Updating your configuration dictionary is useful when parameters are obtained after the dictionary was defined, for example you might want to add a model’s parameters after the model is instantiated.\\nwandb.config.update({“model_parameters” = 3500})\\nFor more information on how to define a config file, see Configure Experiments with wandb.config\\nLogging To W&B\", 'source': 'guides/integrations/add-wandb-to-any-library.md', 'score': 0.06766981, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'give me a script that goes through every project of yours and then deletes all images and media files from it using the api', 'answer': 'To create a script that goes through every project in your Weights & Biases account and deletes all images and media files, you\\'ll need to use the W&B API. Below is a Python script that demonstrates how to authenticate with the API, list all projects, and delete media files from each project.\\n\\n### Step-by-Step Script\\n\\n1. **Authenticate with the W&B API**: You need to authenticate using your API key, which you can find in your W&B account settings.\\n\\n2. **List all projects**: Use the API to fetch all projects under your entity.\\n\\n3. **Identify and delete media files**: For each project, list all artifacts, identify those that are images or media files, and delete them.\\n\\nHere\\'s the Python script:\\n\\n```python\\nimport wandb\\n\\n# Authenticate with the API\\napi = wandb.Api()\\n\\n# Your entity name\\nentity = \"your_entity_name\"\\n\\n# List all projects in your entity\\nprojects = api.projects(entity=entity)\\n\\n# Loop through each project\\nfor project in projects:\\n    print(f\"Processing project: {project.name}\")\\n    # List all artifacts in the project\\n    artifacts = api.artifacts(f\"{entity}/{project.name}\", per_page=50)\\n    for artifact in artifacts:\\n        # Check if the artifact is an image or media file\\n        if artifact.type in [\\'image\\', \\'media\\']:\\n            print(f\"Deleting artifact: {artifact.name}\")\\n            # Delete the artifact\\n            artifact.delete()\\n\\nprint(\"Completed deleting images and media files from all projects.\")\\n```\\n\\n### Explanation\\n\\n- **Authentication**: The script starts by authenticating with the W&B API using your API key.\\n- **Listing Projects**: It retrieves all projects under your specified entity.\\n- **Deleting Media Files**: For each project, it fetches all artifacts and checks if they are images or media files based on their type. If they are, it deletes them.\\n\\n### Important Notes\\n\\n- **Permissions**: Ensure that your API key has the necessary permissions to delete artifacts.\\n- **Backup**: Consider backing up your data before running this script, as deletions are irreversible.\\n\\nThis script provides a basic framework. You might need to adjust the artifact type checking depending on how you categorize or store images and media files in your projects.', 'contexts': [{'content': 'Delete multiple artifact versions with a specific alias\\nThe proceeding code demonstrates how to delete multiple artifact versions that have a specific alias. Provide the entity, project name, and run ID that created the artifacts. Replace the deletion logic with your own:\\nimport wandb\\nruns = api.run(\"entity/project_name/run_id\")\\n# Delete artifact ith alias \\'v3\\' and \\'v4\\nfor artifact_version in runs.logged_artifacts():\\n    # Replace with your own deletion logic.\\n    if artifact_version.name[-2:] == \"v3\" or artifact_version.name[-2:] == \"v4\":\\n        artifact.delete(delete_aliases=True)\\nDelete all versions of an artifact that do not have an alias\\nThe following code snippet demonstrates how to delete all versions of an artifact that do not have an alias. Provide the name of the project and entity for the `project` and `entity` keys in `wandb.Api`, respectively. Replace the `<>` with the name of your artifact:\\nimport wandb\\n# Provide your entity and a project name when you\\n# use wandb.Api methods.\\napi = wandb.Api(overrides={\"project\": \"project\", \"entity\": \"entity\"})\\nartifact_type, artifact_name = \"<>\"  # provide type and name\\nfor v in api.artifact_versions(artifact_type, artifact_name):\\n    # Clean up versions that don\\'t have an alias such as \\'latest\\'.\\n    # NOTE: You can put whatever deletion logic you want here.\\n    if len(v.aliases) == 0:\\n        v.delete()\\nDelete an artifact collection\\nTo delete an artifact collection:\\nNavigate to the artifact collection you want to delete and hover over it.\\nSelect the kebab dropdown next to the artifact collection name.\\nChoose Delete.\\nYou can also delete artifact collection programmatically with the delete() method. Provide the name of the project and entity for the `project` and `entity` keys in `wandb.Api`, respectively:\\nimport wandb\\n# Provide your entity and a project name when you\\n# use wandb.Api methods.\\napi = wandb.Api(overrides={\"project\": \"project\", \"entity\": \"entity\"})\\ncollection = api.artifact_collection(\\n    \"<artifact_type>\", \"entity/project/artifact_collection_name\"\\n)\\ncollection.delete()', 'source': 'guides/artifacts/delete-artifacts.md', 'score': 0.17398883, 'relevance': 2}, {'content': 'Delete artifacts\\nDelete W&B Artifacts\\nDelete artifacts interactively with the App UI or programmatically with the W&B SDK. When you delete an artifact, W&B marks that artifact as a soft-delete. In other words, the artifact is marked for deletion but files are not immediately deleted from storage. \\nThe contents of the artifact remain as a soft-delete, or pending deletion state, until a regularly run garbage collection process reviews all artifacts marked for deletion. The garbage collection process deletes associated files from storage if the artifact and its associated files are not used by a previous or subsequent artifact versions. \\nThe sections in this page describe how to delete specific artifact versions, how to delete an artifact collection, how to delete artifacts with and without aliases, and more. You can schedule when artifacts are deleted from W&B with TTL policies. For more information, see Manage data retention with Artifact TTL policy.\\n:::note\\nArtifacts that are scheduled for deletion with a TTL policy, deleted with the W&B SDK, or deleted with the W&B App UI are first soft-deleted. Artifacts that are soft deleted undergo garbage collection before they are hard-deleted.\\n:::\\nDelete an artifact version\\nTo delete an artifact version:\\nSelect the name of the artifact. This will expand the artifact view and list all the artifact versions associated with that artifact.\\nFrom the list of artifacts, select the artifact version you want to delete.\\nOn the right hand side of the workspace, select the kebab dropdown.\\nChoose Delete.\\nAn artifact version can also be deleted programatically via the delete() method. See the examples below. \\nDelete multiple artifact versions with aliases\\nThe following code example demonstrates how to delete artifacts that have aliases associated with them. Provide the entity, project name, and run ID that created the artifacts.\\nimport wandb\\nrun = api.run(\"entity/project/run_id\")\\nfor artifact in run.logged_artifacts():\\n    artifact.delete()\\nSet the `delete_aliases` parameter to the boolean value, `True` to delete aliases if the artifact has one or more aliases.\\nimport wandb\\nrun = api.run(\"entity/project/run_id\")\\nfor artifact in run.logged_artifacts():\\n    # Set delete_aliases=True in order to delete\\n    # artifacts with one more aliases\\n    artifact.delete(delete_aliases=True)', 'source': 'guides/artifacts/delete-artifacts.md', 'score': 0.0068239546, 'relevance': 2}, {'content': 'flush\\nView source\\nflush()\\nFlush the local cache.\\nThe api object keeps a local cache of runs, so if the state of the run may\\nchange while executing your script you must clear the local cache with\\n`api.flush()` to get the latest values associated with the run.\\nfrom_path\\nView source\\nfrom_path(\\n    path\\n)\\nReturn a run, sweep, project or report from a path.\\nExamples:\\nproject = api.from_path(\"my_project\")\\nteam_project = api.from_path(\"my_team/my_project\")\\nrun = api.from_path(\"my_team/my_project/runs/id\")\\nsweep = api.from_path(\"my_team/my_project/sweeps/id\")\\nreport = api.from_path(\"my_team/my_project/reports/My-Report-Vm11dsdf\")\\nArguments\\n`path`\\n(str) The path to the project, run, sweep or report\\nReturns\\nA `Project`, `Run`, `Sweep`, or `BetaReport` instance.\\nRaises\\nwandb.Error if path is invalid or the object doesn\\'t exist\\njob\\nView source\\njob(\\n    name: Optional[str],\\n    path: Optional[str] = None\\n) -> \"public.Job\"\\nReturn a `Job` from the given parameters.\\nArguments\\n`name`\\n(str) The job name.\\n`path`\\n(str, optional) If given, the root path in which to download the job artifact.\\nReturns\\nA `Job` object.\\nlist_jobs\\nView source\\nlist_jobs(\\n    entity: str,\\n    project: str\\n) -> List[Dict[str, Any]]\\nReturn a list of jobs, if any, for the given entity and project.\\nArguments\\n`entity`\\n(str) The entity for the listed job(s).\\n`project`\\n(str) The project for the listed job(s).\\nReturns\\nA list of matching jobs.\\nproject\\nView source\\nproject(\\n    name: str,\\n    entity: Optional[str] = None\\n) -> \"public.Project\"\\nReturn the `Project` with the given name (and entity, if given).\\nArguments\\n`name`\\n(str) The project name.\\n`entity`\\n(str) Name of the entity requested. If None, will fall back to the default entity passed to `Api`. If no default entity, will raise a `ValueError`.\\nReturns\\nA `Project` object.', 'source': 'ref/python/public-api/api.md', 'score': 0.015967654, 'relevance': 1}, {'content': \"Storage\\nIf you are approaching or exceeding your storage limit, there are multiple paths forward to manage your data. The path that's best for you will depend on your account type and your current project setup.\\nManage storage consumption\\nW&B offers different methods of optimizing your storage consumption:\\nUse\\xa0reference artifacts\\xa0to track files saved outside the W&B system, instead of uploading them to W&B storage.\\nUse an external cloud storage bucket for storage. (Enterprise only)\\nDelete data\\nYou can also choose to delete data to remain under your storage limit. There are several ways to do this:\\nDelete data interactively with the app UI.\\nSet a TTL policy on Artifacts so they are automatically deleted.\", 'source': 'guides/app/features/storage.md', 'score': 0.0009966077, 'relevance': 1}, {'content': 'Data Privacy and Compliance\\nArtifact Data Privacy and Compliance\\nFiles are uploaded to Google Cloud bucket managed by W&B when you log artifacts. The contents of the bucket are encrypted both at rest and in transit. Artifact files are only visible to users who have access to the corresponding project.\\nWhen you delete a version of an artifact, it is marked for soft deletion in our database and removed from your storage cost. When you delete an entire artifact, it is queued for permanently deletion and all of its contents are removed from the W&B bucket. If you have specific needs around file deletion please reach out to Customer Support.\\nFor sensitive datasets that cannot reside in a multi-tenant environment, you can use either a private W&B server connected to your cloud bucket or reference artifacts. Reference artifacts track references to private buckets without sending file contents to W&B. Reference artifacts maintain links to files on your buckets or servers. In other words, W&B only keeps track of the metadata associated with the files and not the files themselves.\\nCreate a reference artifact similar to how you create a non reference artifact:\\nimport wandb\\nrun = wandb.init()\\nartifact = wandb.Artifact(\"animals\", type=\"dataset\")\\nartifact.add_reference(\"s3://my-bucket/animals\")\\nFor alternatives, contact us at contact@wandb.com to talk about private cloud and on-premises installations.', 'source': 'guides/artifacts/data-privacy-and-compliance.md', 'score': 0.0016166499, 'relevance': 0}, {'content': 'Export metrics from all runs in a project to a CSV file\\nThis script pulls down the runs in a project and produces a dataframe and a CSV of runs including their names, configs, and summary stats. Replace `<entity>` and `<project>` with your W&B entity and the name of your project, respectively.\\nimport pandas as pd\\nimport wandb\\napi = wandb.Api()\\nentity, project = \"<entity>\", \"<project>\"\\nruns = api.runs(entity + \"/\" + project)\\nsummary_list, config_list, name_list = [], [], []\\nfor run in runs:\\n    # .summary contains the output keys/values\\n    #  for metrics such as accuracy.\\n    #  We call ._json_dict to omit large files\\n    summary_list.append(run.summary._json_dict)\\n    # .config contains the hyperparameters.\\n    #  We remove special values that start with _.\\n    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\\n    # .name is the human-readable name of the run.\\n    name_list.append(run.name)\\nruns_df = pd.DataFrame(\\n    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\\n)\\nruns_df.to_csv(\"project.csv\")\\nGet the starting time for a run\\nThis code snippet retrieves the time at which the run was created.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"entity/project/run_id\")\\nstart_time = run.created_at\\nUpload files to a finished run\\nThe code snippet below uploads a selected file to a finished run.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"entity/project/run_id\")\\nrun.upload_file(\"file_name.extension\")\\nDownload a file from a run\\nThis finds the file \"model-best.h5\" associated with with run ID uxte44z7 in the cifar project and saves it locally.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nrun.file(\"model-best.h5\").download()\\nDownload all files from a run\\nThis finds all files associated with a run and saves them locally.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nfor file in run.files():\\n    file.download()', 'source': 'guides/track/public-api-guide.md', 'score': 0.0004339325, 'relevance': 0}, {'content': 'wandb artifact cache cleanup\\nUsage\\n`wandb artifact cache cleanup [OPTIONS] TARGET_SIZE`\\nSummary\\nClean up less frequently used files from the artifacts cache\\nOptions\\nOption\\nDescription\\n--remove-temp / --no-remove-temp\\nRemove temp files', 'source': 'ref/cli/wandb-artifact/wandb-artifact-cache/wandb-artifact-cache-cleanup.md', 'score': 0.0003874762, 'relevance': 0}, {'content': '%%capture\\n!curl -SL $src_url > $src_zip\\n!unzip $src_zip\\nimport wandb\\nimport pandas as pd\\nimport os\\nwith wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"log_datasets\") as run:\\n    img_paths = []\\n    for root, dirs, files in os.walk(\"nature_100\", topdown=False):\\n        for name in files:\\n            img_path = os.path.join(root, name)\\n            label = img_path.split(\"/\")[1]\\n            img_paths.append([img_path, label])\\n    index_df = pd.DataFrame(columns=[\"image_path\", \"label\"], data=img_paths)\\n    index_df.to_csv(\"index.csv\", index=False)\\n    train_art = wandb.Artifact(\\n        name=\"Nature_100\",\\n        type=\"raw_images\",\\n        description=\"nature image dataset with 10 classes, 10 images per class\",\\n    )\\n    train_art.add_dir(\"nature_100\")\\n    # Also adding a csv indicating the labels of each image\\n    train_art.add_file(\"index.csv\")\\n    wandb.log_artifact(train_art)', 'source': 'tutorials/models.md', 'score': 0.0001647466, 'relevance': 0}, {'content': 'Known issues and limitations\\nIf the destination namespace does not exist, W&B creates one automatically.\\nIf a run or artifact has the same ID in the destination namespace, W&B treats it as an incremental import. The destination run/artifact is validated and retried if it failed in a previous import.\\nNo data is ever deleted from the source system.\\nSometimes when bulk importing (especially large artifacts), you can run into S3 rate limits. If you see `botocore.exceptions.ClientError: An error occurred (SlowDown) when calling the PutObject operation`, you can try spacing out imports by moving just a few namespaces at a time.\\nImported run tables appear to be blank in the workspace, but if you nav to the Artifacts tab and click the equivalent run table artifact you should see the table as expected.\\nSystem metrics and custom charts (not explicitly logged with `wandb.log`) are not imported\\nExport Data\\nUse the Public API to export or update data that you have saved to W&B. Before using this API, you\\'ll want to log data from your script — check the Quickstart for more details.\\nUse Cases for the Public API\\nExport Data: Pull down a dataframe for custom analysis in a Jupyter Notebook. Once you have explored the data, you can sync your findings by creating a new analysis run and logging results, for example: `wandb.init(job_type=\"analysis\")`\\nUpdate Existing Runs: You can update the data logged in association with a W&B run. For example, you might want to update the config of a set of runs to include additional information, like the architecture or a hyperparameter that wasn\\'t originally logged.\\nSee the Generated Reference Docs for details on available functions.\\nAuthentication\\nAuthenticate your machine with your API key in one of two ways:\\nRun `wandb login` on the command line and paste in your API key.\\nSet the `WANDB_API_KEY` environment variable to your API key.\\nFind the run path\\nTo use the Public API, you\\'ll often need the run path which is `<entity>/<project>/<run_id>`. In the app UI, open a run page and click the Overview tab to get the run path.', 'source': 'guides/track/public-api-guide.md', 'score': 0.0001263204, 'relevance': 0}, {'content': 'File count\\nKeep the total number of files uploaded for a single run under 1,000. You can use W&B Artifacts when you need to log a large number of files. Exceeding 1,000 files in a single run can slow down your run pages.\\nPython script performance\\nThere are a few ways that your performance of your python script is reduced:\\nThe size of your data is too large. Large data sizes could introduce a >1 ms overhead to the training loop.\\nThe speed of your network and the how the W&B backend is configured\\nCalling `wandb.log` more than a few times per second. This is due to a small latency added to the training loop every time `wandb.log` is called.\\n:::info\\nIs frequent logging slowing your training runs down? Check out this Colab for methods to get better performance by changing your logging strategy.\\n:::\\nW&B does not assert any limits beyond rate limiting. The W&B Python SDK automatically completes an exponential \"backoff\" and \"retry\" requests that exceed limits. W&B Python SDK responds with a “Network failure” on the command line. For unpaid accounts, W&B may reach out in extreme cases where usage exceeds reasonable thresholds.\\nRate limits\\nW&B SaaS Cloud API implements a rate limit to maintain system integrity and ensure availability. This measure prevents any single user from monopolizing available resources in the shared infrastructure, ensuring that the service remains accessible to all users. You may encounter a lower rate limit for a variety of reasons. \\n:::note\\nRate limits are subject to change.\\n:::\\nThe `wandb.log` calls in your script utilize a metrics logging API to log your training data to W&B. This API is engaged through either online or offline syncing. In either case, it imposes a rate limit quota limit in a rolling time window. This includes limits on total request size and request rate, where latter refers to the number of requests in a time duration. \\nRate limits are applied to each W&B project. So if you have 3 projects in a team, each project has its own rate limit quota. Users on Teams and Enterprise plans have higher rate limits than those on the Free plan.', 'source': 'guides/track/limits.md', 'score': 3.5913e-05, 'relevance': 0}]}),\n",
       " WeaveDict({'question': \"I'm trying to get data from a run.history() and I get only 500 points (the real run is 3.2k points). It happens only with some runs but not all of them. Which can be the reason?\", 'answer': \"When you use `run.history()` in Weights & Biases, by default, it samples the data to 500 points. This is a common reason why you might see only 500 points even if the actual run has more data points like 3.2k in your case.\\n\\nTo retrieve more than the default 500 data points, you can adjust the `samples` parameter in the `run.history()` method. Here's how you can modify your code to fetch more or all data points:\\n\\n```python\\n# Assuming 'run' is your run object\\n# To fetch more than 500 points, specify the 'samples' parameter\\nhistory = run.history(samples=1000)  # Adjust the number as needed\\n\\n# To fetch all data points, you might consider using run.scan_history()\\n# This method does not sample the data\\nfull_history = [row for row in run.scan_history()]\\n```\\n\\nThe `run.scan_history()` method is particularly useful if you need to access all data points without sampling, as it iterates over every data point logged in the run.\\n\\nKeep in mind that fetching a large number of data points can be slow, especially if the data size is large. If you experience performance issues or timeouts, consider fetching data in smaller chunks or increasing the timeout settings if possible.\\n\\n**Note**: The sampling behavior of `run.history()` is designed to provide a quick overview of the run data without overwhelming the system or the network with large amounts of data. If you consistently need more detailed data, using `run.scan_history()` as shown above is recommended.\", 'contexts': [{'content': 'run.history()\\n   _step  val   loss  _runtime  _timestamp\\n0      0  500  0.244         4  1644345412\\n1      1   45  0.521         4  1644345412\\n2      2  240  0.785         4  1644345412\\n3      3   31  0.305         4  1644345412\\n4      4  525  0.041         4  1644345412\\nrun.summary\\n{\\n    \"_runtime\": 4,\\n    \"_step\": 4,\\n    \"_timestamp\": 1644345412,\\n    \"_wandb\": {\"runtime\": 3},\\n    \"loss\": 0.041,\\n    \"val\": 525,\\n}\\nSampling\\nThe default history method samples the metrics to a fixed number of samples (the default is 500, you can change this with the `samples` __ argument). If you want to export all of the data on a large run, you can use the `run.scan_history()` method. For more details see the API Reference.', 'source': 'guides/track/public-api-guide.md', 'score': 0.9977128, 'relevance': 2}, {'content': 'Rename a metric in a run, after the run has finished\\nThis example renames a summary column in your tables.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nrun.summary[\"new_name\"] = run.summary[\"old_name\"]\\ndel run.summary[\"old_name\"]\\nrun.summary.update()\\n:::caution\\nRenaming a column only applies to tables. Charts will still refer to metrics by their original names.\\n:::\\nUpdate config for an existing run\\nThis examples updates one of your configuration settings.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nrun.config[\"key\"] = updated_value\\nrun.update()\\nExport system resource consumptions to a CSV file\\nThe snippet below would find the system resource consumptions and then, save them to a CSV.\\nimport wandb\\nrun = wandb.Api().run(\"<entity>/<project>/<run_id>\")\\nsystem_metrics = run.history(stream=\"events\")\\nsystem_metrics.to_csv(\"sys_metrics.csv\")\\nGet unsampled metric data\\nWhen you pull data from history, by default it\\'s sampled to 500 points. Get all the logged data points using `run.scan_history()`. Here\\'s an example downloading all the `loss` data points logged in history.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nhistory = run.scan_history()\\nlosses = [row[\"loss\"] for row in history]\\nGet paginated data from history\\nIf metrics are being fetched slowly on our backend or API requests are timing out, you can try lowering the page size in `scan_history` so that individual requests don\\'t time out. The default page size is 500, so you can experiment with different sizes to see what works best:\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nrun.scan_history(keys=sorted(cols), page_size=100)', 'source': 'guides/track/public-api-guide.md', 'score': 0.9965029999999999, 'relevance': 2}, {'content': 'Why is nothing showing up in my graphs?\\nIf you\\'re seeing \"No visualization data logged yet\" that means that we haven\\'t gotten the first `wandb.log` call from your script yet. This could be because your run takes a long time to finish a step. If you\\'re logging at the end of each epoch, you could log a few times per epoch to see data stream in more quickly.\\nWhy is the same metric appearing more than once?\\nIf you\\'re logging different types of data under the same key, we have to split them out in our database. This means you\\'ll see multiple entries of the same metric name in a dropdown in the UI. The types we group by are `number`, `string`, `bool`, `other` (mostly arrays), and any `wandb` data type (`Histogram`, `Image`, etc). Send only one type to each key to avoid this behavior.\\nWe store metrics in a case-insensitive fashion, so make sure you don\\'t have two metrics with the same name like `\"My-Metric\"` and `\"my-metric\"`.\\nHow can I access the data logged to my runs directly and programmatically?\\nThe history object is used to track metrics logged by `wandb.log`. Using our API, you can access the history object via `run.history()`.\\napi = wandb.Api()\\nrun = api.run(\"username/project/run_id\")\\nprint(run.history())\\nWhat happens when I log millions of steps to W&B? How is that rendered in the browser?\\nThe more points you send us, the longer it will take to load your graphs in the UI. If you have more than 1000 points on a line, we sample down to 1000 points on the backend before we send your browser the data. This sampling is nondeterministic, so if you refresh the page you\\'ll see a different set of sampled points.\\nGuidelines\\nWe recommend that you try to log less than 10,000 points per metric. If you log more than 1 million points in a line, it will take us while to load the page. For more on strategies for reducing logging footprint without sacrificing accuracy, check out this Colab. If you have more than 500 columns of config and summary metrics, we\\'ll only show 500 in the table.', 'source': 'guides/track/log/logging-faqs.md', 'score': 0.8824278999999999, 'relevance': 1}, {'content': 'Date\\nruns = api.runs(\\n    \"<entity>/<project>\",\\n    {\"$and\": [{\"created_at\": {\"$lt\": \"YYYY-MM-DDT##\", \"$gt\": \"YYYY-MM-DDT##\"}}]},\\n)\\nRead specific metrics from a run\\nTo pull specific metrics from a run, use the `keys` argument. The default number of samples when using `run.history()` is 500. Logged steps that do not include a specific metric will appear in the output dataframe as `NaN`. The `keys` argument will cause the API to sample steps that include the listed metric keys more frequently.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nif run.state == \"finished\":\\n    for i, row in run.history(keys=[\"accuracy\"]).iterrows():\\n        print(row[\"_timestamp\"], row[\"accuracy\"])\\nCompare two runs\\nThis will output the config parameters that are different between `run1` and `run2`.\\nimport pandas as pd\\nimport wandb\\napi = wandb.Api()\\n# replace with your <entity>, <project>, and <run_id>\\nrun1 = api.run(\"<entity>/<project>/<run_id>\")\\nrun2 = api.run(\"<entity>/<project>/<run_id>\")\\ndf = pd.DataFrame([run1.config, run2.config]).transpose()\\ndf.columns = [run1.name, run2.name]\\nprint(df[df[run1.name] != df[run2.name]])\\nOutputs:\\n              c_10_sgd_0.025_0.01_long_switch base_adam_4_conv_2fc\\nbatch_size                                 32                   16\\nn_conv_layers                               5                    4\\noptimizer                             rmsprop                 adam\\nUpdate metrics for a run, after the run has finished\\nThis example sets the accuracy of a previous run to `0.9`. It also modifies the accuracy histogram of a previous run to be the histogram of `numpy_array`.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nrun.summary[\"accuracy\"] = 0.9\\nrun.summary[\"accuracy_histogram\"] = wandb.Histogram(numpy_array)\\nrun.summary.update()', 'source': 'guides/track/public-api-guide.md', 'score': 0.8224745, 'relevance': 1}, {'content': 'W&B Line Plots Point aggregation\\nUse point aggregation methods within W&B Line Plots to improve data visualization accuracy and performance. There are two types of point aggregation modes: Random sampling and Full fidelity.\\n:::note\\nWorkspaces use Random sampling mode by default. Switching to Full fidelity applies the chart setting per user.\\n:::\\nRandom sampling\\nFor performance reasons, when over 1500 points were chosen for a line plot metric, the point aggregation method returns 1500 randomly sampled points. Each metric is sampled separately. Only steps where the metric are actually logged are considered. Because random sampling samples non-deterministically, this method sometimes excluded important outliers or spikes.\\nExample: Accessing run history\\nTo access the complete history of metrics logged during a run, you can use the W&B Run API. The following example demonstrates how to retrieve and process the loss values from a specific run:\\n# Initialize the W&B API\\nrun = api.run(\"l2k2/examples-numpy-boston/i0wt6xua\")\\n# Retrieve the history of the \\'Loss\\' metric\\nhistory = run.scan_history(keys=[\"Loss\"])\\n# Extract the loss values from the history\\nlosses = [row[\"Loss\"] for row in history]\\nFull fidelity\\nThe full fidelity point aggregation method replaces random sampling with an averaging approach that maintains the integrity of critical visual insights, such as outliers and spikes. Full fidelity mode guarantees the inclusion of minimum and maximum values within each bucket on your chart, allowing for high-detail zoom capabilities.\\nSome key benfits of full fidelity mode include:\\n* Accurate Data Representation: Ensures all critical outlier spikes are displayed.\\n* High-Density Visualization: Maintains full data resolution beyond the 1,500 point limit.\\n* Enhanced Zoom: Users can zoom into data points without losing detail due to downsampling.', 'source': 'guides/app/features/panels/line-plot/sampling.md', 'score': 0.7108291, 'relevance': 1}, {'content': 'Export Run Data\\nDownload data from a finished or active run. Common usage includes downloading a dataframe for custom analysis in a Jupyter notebook, or using custom logic in an automated environment.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nThe most commonly used attributes of a run object are:\\nAttribute\\nMeaning\\n`run.config`\\nA dictionary of the run\\'s configuration information, such as the hyperparameters for a training run or the preprocessing methods for a run that creates a dataset Artifact. Think of these as the run\\'s \"inputs\".\\n`run.history()`\\nA list of dictionaries meant to store values that change while the model is training such as loss. The command `wandb.log()` appends to this object.\\n`run.summary`\\nA dictionary of information that summarizes the run\\'s results. This can be scalars like accuracy and loss, or large files. By default, `wandb.log()` sets the summary to the final value of a logged time series. The contents of the summary can also be set directly. Think of the summary as the run\\'s \"outputs\".\\nYou can also modify or update the data of past runs. By default a single instance of an api object will cache all network requests. If your use case requires real time information in a running script, call `api.flush()` to get updated values.\\nUnderstanding the Different Attributes\\nFor the below run\\nn_epochs = 5\\nconfig = {\"n_epochs\": n_epochs}\\nrun = wandb.init(project=project, config=config)\\nfor n in range(run.config.get(\"n_epochs\")):\\n    run.log(\\n        {\"val\": random.randint(0, 1000), \"loss\": (random.randint(0, 1000) / 1000.00)}\\n    )\\nrun.finish()\\nthese are the different outputs for the above run object attributes\\nrun.config\\n{\"n_epochs\": 5}', 'source': 'guides/track/public-api-guide.md', 'score': 0.601418, 'relevance': 0}, {'content': 'Runs\\nView source on GitHub\\nAn iterable collection of runs associated with a project and optional filter.\\nRuns(\\n    client: \"RetryingClient\",\\n    entity: str,\\n    project: str,\\n    filters: Optional[Dict[str, Any]] = None,\\n    order: Optional[str] = None,\\n    per_page: int = 50,\\n    include_sweeps: bool = (True)\\n)\\nThis is generally used indirectly via the `Api`.runs method.\\nAttributes\\nMethods\\nconvert_objects\\nView source\\nconvert_objects()\\nhistories\\nView source\\nhistories(\\n    samples: int = 500,\\n    keys: Optional[List[str]] = None,\\n    x_axis: str = \"_step\",\\n    format: Literal[\\'default\\', \\'pandas\\', \\'polars\\'] = \"default\",\\n    stream: Literal[\\'default\\', \\'system\\'] = \"default\"\\n)\\nReturn sampled history metrics for all runs that fit the filters conditions.\\nArguments\\n`samples`\\n(int, optional) The number of samples to return per run\\n`keys`\\n(list[str], optional) Only return metrics for specific keys\\n`x_axis`\\n(str, optional) Use this metric as the xAxis defaults to _step\\n`format`\\n(Literal, optional) Format to return data in, options are \"default\", \"pandas\", \"polars\"\\n`stream`\\n(Literal, optional) \"default\" for metrics, \"system\" for machine metrics\\nReturns\\n`pandas.DataFrame`\\nIf format=\"pandas\", returns a `pandas.DataFrame` of history metrics.\\n`polars.DataFrame`\\nIf format=\"polars\", returns a `polars.DataFrame` of history metrics. list of dicts: If format=\"default\", returns a list of dicts containing history metrics with a run_id key.\\nnext\\nView source\\nnext()\\nupdate_variables\\nView source\\nupdate_variables()\\n__getitem__\\nView source\\n__getitem__(\\n    index\\n)\\n__iter__\\nView source\\n__iter__()\\n__len__\\nView source\\n__len__()\\nClass Variables\\n`QUERY`', 'source': 'ref/python/public-api/runs.md', 'score': 0.58148134, 'relevance': 0}, {'content': \"log\\nView source on GitHub\\nLog a dictionary of data to the current run's history.\\nlog(\\n    data: Dict[str, Any],\\n    step: Optional[int] = None,\\n    commit: Optional[bool] = None,\\n    sync: Optional[bool] = None\\n) -> None\", 'source': 'ref/python/log.md', 'score': 0.56643826, 'relevance': 0}, {'content': 'Get runs from a specific sweep\\nThis snippet downloads all the runs associated with a particular sweep.\\nimport wandb\\napi = wandb.Api()\\nsweep = api.sweep(\"<entity>/<project>/<sweep_id>\")\\nsweep_runs = sweep.runs\\nGet the best run from a sweep\\nThe following snippet gets the best run from a given sweep.\\nimport wandb\\napi = wandb.Api()\\nsweep = api.sweep(\"<entity>/<project>/<sweep_id>\")\\nbest_run = sweep.best_run()\\nThe `best_run` is the run with the best metric as defined by the `metric` parameter in the sweep config.\\nDownload the best model file from a sweep\\nThis snippet downloads the model file with the highest validation accuracy from a sweep with runs that saved model files to `model.h5`.\\nimport wandb\\napi = wandb.Api()\\nsweep = api.sweep(\"<entity>/<project>/<sweep_id>\")\\nruns = sorted(sweep.runs, key=lambda run: run.summary.get(\"val_acc\", 0), reverse=True)\\nval_acc = runs[0].summary.get(\"val_acc\", 0)\\nprint(f\"Best run {runs[0].name} with {val_acc}% val accuracy\")\\nruns[0].file(\"model.h5\").download(replace=True)\\nprint(\"Best model saved to model-best.h5\")\\nDelete all files with a given extension from a run\\nThis snippet deletes files with a given extension from a run.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nextension = \".png\"\\nfiles = run.files()\\nfor file in files:\\n    if file.name.endswith(extension):\\n        file.delete()\\nDownload system metrics data\\nThis snippet produces a dataframe with all the system resource consumption metrics for a run and then saves it to a CSV.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nsystem_metrics = run.history(stream=\"events\")\\nsystem_metrics.to_csv(\"sys_metrics.csv\")\\nUpdate summary metrics\\nYou can pass a dictionary to update summary metrics.\\nsummary.update({\"key\": val})', 'source': 'guides/track/public-api-guide.md', 'score': 0.027066175, 'relevance': 0}, {'content': 'Get the latest git commit through the API\\nIn the UI, click on a run and then click the Overview tab on the run page to see the latest git commit. It\\'s also in the file `wandb-metadata.json` . Using the public API, you can get the git hash with `run.commit`.\\nFrequently Asked Questions\\nHow do I export data to visualize in matplotlib or seaborn?\\nCheck out our API examples for some common export patterns. You can also click the download button on a custom plot or on the expanded runs table to download a CSV from your browser.\\nHow do I get a run\\'s name and ID during a run?\\nAfter calling `wandb.init()` you can access the random run ID or the human readable run name from your script like this:\\nUnique run ID (8 character hash): `wandb.run.id`\\nRandom run name (human readable): `wandb.run.name`\\nIf you\\'re thinking about ways to set useful identifiers for your runs, here\\'s what we recommend:\\nRun ID: leave it as the generated hash. This needs to be unique across runs in your project.\\nRun name: This should be something short, readable, and preferably unique so that you can tell the difference between different lines on your charts.\\nRun notes: This is a great place to put a quick description of what you\\'re doing in your run. You can set this with `wandb.init(notes=\"your notes here\")`\\nRun tags: Track things dynamically in run tags, and use filters in the UI to filter your table down to just the runs you care about. You can set tags from your script and then edit them in the UI, both in the runs table and the overview tab of the run page. See the detailed instructions here.\\nPublic API Examples\\nRead metrics from a run\\nThis example outputs timestamp and accuracy saved with `wandb.log({\"accuracy\": acc})` for a run saved to `\"<entity>/<project>/<run_id>\"`.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nif run.state == \"finished\":\\n    for i, row in run.history().iterrows():\\n        print(row[\"_timestamp\"], row[\"accuracy\"])\\nFilter runs\\nYou can filters by using the MongoDB Query Language.', 'source': 'guides/track/public-api-guide.md', 'score': 0.013171949, 'relevance': 0}]}),\n",
       " WeaveDict({'question': \"if I execute a run in offline mode, is there a method of interacting with the run data using the API before it's upload to wandb?\", 'answer': \"When you execute a run in offline mode using Weights & Biases, the data is stored locally on your machine and not sent to the W&B servers until you decide to sync it. While the run is in offline mode, you can interact with the run data using the local API, but with some limitations compared to the full capabilities when connected online.\\n\\nHere’s how you can interact with run data in offline mode:\\n\\n1. **Accessing Run Data Locally**: You can access the run data stored in the local files. W&B stores the data in a directory (usually `wandb/` in your project directory). This includes configuration files, model checkpoints (if saved), and logs.\\n\\n2. **Using Python API**: You can use the W&B Python API to read the run data from these files. For example, you can load the configuration or the metrics logged during the run by reading the JSON files in the `wandb/` directory.\\n\\n3. **Syncing Data**: Once you are ready to upload the data to the W&B servers for more comprehensive analysis and sharing, you can use the `wandb sync` command. This command will upload the local run data to the W&B servers, and then you can use the W&B web interface or the public API to interact with your data as usual.\\n\\nHere is an example of how you might sync your data after running in offline mode:\\n\\n```bash\\nwandb sync /path/to/run/directory\\n```\\n\\nThis command will find all the runs in the specified directory that haven't been synced and will upload them to the W&B servers.\\n\\nRemember, while the run is in offline mode, some features like real-time charts and collaboration may not be available until the data is synced with the W&B servers. For more detailed information on working with offline runs and syncing them, you can refer to the [Weights & Biases documentation on offline runs](https://docs.wandb.ai/guides/track/tracking-faq).\", 'contexts': [{'content': 'Is it possible to save metrics offline and sync them to W&B later?\\nBy default, `wandb.init` starts a process that syncs metrics in real time to our cloud hosted app. If your machine is offline, you don\\'t have internet access, or you just want to hold off on the upload, here\\'s how to run `wandb` in offline mode and sync later.\\nYou will need to set two environment variables.\\n`WANDB_API_KEY=$KEY`, where `$KEY` is the API Key from your settings page\\n`WANDB_MODE=\"offline\"`\\nAnd here\\'s a sample of what this would look like in your script:\\nimport wandb\\nimport os\\nos.environ[\"WANDB_API_KEY\"] = YOUR_KEY_HERE\\nos.environ[\"WANDB_MODE\"] = \"offline\"\\nconfig = {\\n    \"dataset\": \"CIFAR10\",\\n    \"machine\": \"offline cluster\",\\n    \"model\": \"CNN\",\\n    \"learning_rate\": 0.01,\\n    \"batch_size\": 128,\\n}\\nwandb.init(project=\"offline-demo\")\\nfor i in range(100):\\n    wandb.log({\"accuracy\": i})\\nHere\\'s a sample terminal output:\\nAnd once you\\'re ready, just run a sync command to send that folder to the cloud.\\nwandb sync wandb/dryrun-folder-name\\nWhat is the difference between wandb.init modes?\\nModes can be \"online\", \"offline\" or \"disabled\", and default to online.\\n`online`(default): In this mode, the client sends data to the wandb server.\\n`offline`: In this mode, instead of sending data to the wandb server, the client will store data on your local machine which can be later synced with the wandb sync command.\\n`disabled`: In this mode, the client returns mocked objects and prevents all network communication. The client will essentially act like a no-op. In other words, all logging is entirely disabled. However, stubs out of all the API methods are still callable. This is usually used in tests.\\nMy run\\'s state is \"crashed\" on the UI but is still running on my machine. What do I do to get my data back?\\nYou most likely lost connection to your machine while training. You can recover your data by running wandb sync [PATH_TO_RUN]. The path to your run will be a folder in your `wandb` directory corresponding to the Run ID of the run in progress.', 'source': 'guides/track/tracking-faq.md', 'score': 0.9896718, 'relevance': 2}, {'content': 'Setup\\nHow can I configure the name of the run in my training code?\\nAt the top of your training script when you call `wandb.init`, pass in an experiment name, like this: `wandb.init(name=\"my_awesome_run\")`.\\nCan I run wandb offline?\\nIf you\\'re training on an offline machine and want to upload your results to our servers afterwards, we have a feature for you!\\nSet the environment variable `WANDB_MODE=offline` to save the metrics locally, no internet required.\\nWhen you\\'re ready, run `wandb init` in your directory to set the project name.\\nRun `wandb sync YOUR_RUN_DIRECTORY` to push the metrics to our cloud service and see your results in our hosted web app.\\nYou can check via API whether your run is offline by using `run.settings._offline` or `run.settings.mode` after your wandb.init().\\nSome use-cases where you can use wandb sync\\nIf you don’t have internet.\\nIf you need to fully disable things.\\nTo sync your run later due to any reason. For instance: if you want to avoid using resources on a training machine.\\nDoes this only work for Python?\\nCurrently, the library only works with Python 2.7+ & 3.6+ projects. The architecture mentioned above should enable us to integrate with other languages easily. If you have a need for monitoring other languages, send us a note at contact@wandb.com.\\nIs there an anaconda package?\\nYes! You can either install with `pip` or with `conda`. For the latter, you\\'ll need to get the package from the conda-forge channel.\\n# Create a conda env\\nconda create -n wandb-env python=3.8 anaconda\\n# Activate created env\\nconda activate wandb-env\\n# install wandb with pip in this conda env\\npip install wandb\\nconda activate myenv\\nconda install wandb --channel conda-forge\\nIf you run into issues with this install, please let us know. This Anaconda doc on managing packages has some helpful guidance.', 'source': 'guides/technical-faq/setup.md', 'score': 0.9644556, 'relevance': 2}, {'content': 'wandb sync\\nUsage\\n`wandb sync [OPTIONS] [PATH]...`\\nSummary\\nUpload an offline training directory to W&B\\nOptions\\nOption\\nDescription\\n--id\\nThe run you want to upload to.\\n-p, --project\\nThe project you want to upload to.\\n-e, --entity\\nThe entity to scope to.\\n--job_type\\nSpecifies the type of run for grouping   related runs together.\\n--sync-tensorboard / --no-sync-tensorboard\\nStream tfevent files to wandb.\\n--include-globs\\nComma separated list of globs to include.\\n--exclude-globs\\nComma separated list of globs to exclude.\\n--include-online / --no-include-online\\nInclude online runs\\n--include-offline / --no-include-offline\\nInclude offline runs\\n--include-synced / --no-include-synced\\nInclude synced runs\\n--mark-synced / --no-mark-synced\\nMark runs as synced\\n--sync-all\\nSync all runs\\n--clean\\nDelete synced runs\\n--clean-old-hours\\nDelete runs created before this many hours.   To be used alongside --clean flag.\\n--clean-force\\nClean without confirmation prompt.\\n--show\\nNumber of runs to show\\n--append\\nAppend run\\n--skip-console\\nSkip console logs', 'source': 'ref/cli/wandb-sync.md', 'score': 0.8743993600000001, 'relevance': 2}, {'content': 'Export Run Data\\nDownload data from a finished or active run. Common usage includes downloading a dataframe for custom analysis in a Jupyter notebook, or using custom logic in an automated environment.\\nimport wandb\\napi = wandb.Api()\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nThe most commonly used attributes of a run object are:\\nAttribute\\nMeaning\\n`run.config`\\nA dictionary of the run\\'s configuration information, such as the hyperparameters for a training run or the preprocessing methods for a run that creates a dataset Artifact. Think of these as the run\\'s \"inputs\".\\n`run.history()`\\nA list of dictionaries meant to store values that change while the model is training such as loss. The command `wandb.log()` appends to this object.\\n`run.summary`\\nA dictionary of information that summarizes the run\\'s results. This can be scalars like accuracy and loss, or large files. By default, `wandb.log()` sets the summary to the final value of a logged time series. The contents of the summary can also be set directly. Think of the summary as the run\\'s \"outputs\".\\nYou can also modify or update the data of past runs. By default a single instance of an api object will cache all network requests. If your use case requires real time information in a running script, call `api.flush()` to get updated values.\\nUnderstanding the Different Attributes\\nFor the below run\\nn_epochs = 5\\nconfig = {\"n_epochs\": n_epochs}\\nrun = wandb.init(project=project, config=config)\\nfor n in range(run.config.get(\"n_epochs\")):\\n    run.log(\\n        {\"val\": random.randint(0, 1000), \"loss\": (random.randint(0, 1000) / 1000.00)}\\n    )\\nrun.finish()\\nthese are the different outputs for the above run object attributes\\nrun.config\\n{\"n_epochs\": 5}', 'source': 'guides/track/public-api-guide.md', 'score': 0.91102153, 'relevance': 1}, {'content': 'Known issues and limitations\\nIf the destination namespace does not exist, W&B creates one automatically.\\nIf a run or artifact has the same ID in the destination namespace, W&B treats it as an incremental import. The destination run/artifact is validated and retried if it failed in a previous import.\\nNo data is ever deleted from the source system.\\nSometimes when bulk importing (especially large artifacts), you can run into S3 rate limits. If you see `botocore.exceptions.ClientError: An error occurred (SlowDown) when calling the PutObject operation`, you can try spacing out imports by moving just a few namespaces at a time.\\nImported run tables appear to be blank in the workspace, but if you nav to the Artifacts tab and click the equivalent run table artifact you should see the table as expected.\\nSystem metrics and custom charts (not explicitly logged with `wandb.log`) are not imported\\nExport Data\\nUse the Public API to export or update data that you have saved to W&B. Before using this API, you\\'ll want to log data from your script — check the Quickstart for more details.\\nUse Cases for the Public API\\nExport Data: Pull down a dataframe for custom analysis in a Jupyter Notebook. Once you have explored the data, you can sync your findings by creating a new analysis run and logging results, for example: `wandb.init(job_type=\"analysis\")`\\nUpdate Existing Runs: You can update the data logged in association with a W&B run. For example, you might want to update the config of a set of runs to include additional information, like the architecture or a hyperparameter that wasn\\'t originally logged.\\nSee the Generated Reference Docs for details on available functions.\\nAuthentication\\nAuthenticate your machine with your API key in one of two ways:\\nRun `wandb login` on the command line and paste in your API key.\\nSet the `WANDB_API_KEY` environment variable to your API key.\\nFind the run path\\nTo use the Public API, you\\'ll often need the run path which is `<entity>/<project>/<run_id>`. In the app UI, open a run page and click the Overview tab to get the run path.', 'source': 'guides/track/public-api-guide.md', 'score': 0.75635755, 'relevance': 1}, {'content': \"Common Questions\\nWhere do I find my API key?\\nOnce you've signed in to www.wandb.ai, the API key will be on the Authorize page.\\nHow do I use W&B in an automated environment?\\nIf you are training models in an automated environment where it's inconvenient to run shell commands, such as Google's CloudML, you should look at our guide to configuration with Environment Variables.\\nDo you offer local, on-prem installs?\\nYes, you can privately host W&B locally on your own machines or in a private cloud, try this quick tutorial notebook to see how.\\nHow do I turn off wandb logging temporarily?\\nIf are testing code and want to disable wandb syncing, set the environment variable WANDB_MODE=offline.\", 'source': 'quickstart.md', 'score': 0.49597558, 'relevance': 1}, {'content': '📏 Best Practices\\nProjects: Log multiple runs to a project to compare them. `wandb.init(project=\"project-name\")`\\nGroups: For multiple processes or cross validation folds, log each process as a runs and group them together. `wandb.init(group=\\'experiment-1\\')`\\nTags: Add tags to track your current baseline or production model.\\nNotes: Type notes in the table to track the changes between runs.\\nReports: Take quick notes on progress to share with colleagues and make dashboards and snapshots of your ML projects.\\n🤓 Advanced Setup\\nEnvironment variables: Set API keys in environment variables so you can run training on a managed cluster.\\nOffline mode: Use `dryrun` mode to train offline and sync results later.\\nOn-prem: Install W&B in a private cloud or air-gapped servers in your own infrastructure. We have local installations for everyone from academics to enterprise teams.\\nArtifacts: Track and version models and datasets in a streamlined way that automatically picks up your pipeline steps as you train models.', 'source': 'tutorials/tensorflow.md', 'score': 0.21883628, 'relevance': 1}, {'content': '5. Download and use the artifact\\nThe following code example demonstrates the steps you can take to use an artifact you have logged and saved to the W&B servers.\\nFirst, initialize a new run object with `wandb.init()`.\\nSecond, use the run objects use_artifact() method to tell W&B what artifact to use. This returns an artifact object.\\nThird, use the artifacts download() method to download the contents of the artifact.\\n# Create a W&B Run. Here we specify \\'training\\' for \\'type\\'\\n# because we will use this run to track training.\\nrun = wandb.init(project=\"artifacts-example\", job_type=\"training\")\\n# Query W&B for an artifact and mark it as input to this run\\nartifact = run.use_artifact(\"bicycle-dataset:latest\")\\n# Download the artifact\\'s contents\\nartifact_dir = artifact.download()\\nAlternatively, you can use the Public API (`wandb.Api`) to export (or update data) data already saved in a W&B outside of a Run. See Track external files for more information.', 'source': 'guides/artifacts/artifacts-walkthrough.md', 'score': 0.82375413, 'relevance': 0}, {'content': \"How is W&B different from TensorBoard?\\nWe love the TensorBoard folks, and we have a TensorBoard integration! We were inspired to improve experiment tracking tools for everyone. When the co-founders started working on W&B, they were inspired to build a tool for the frustrated TensorBoard users at OpenAI. Here are a few things we focused on improving:\\nReproduce models: W&B is good for experimentation, exploration, and reproducing models later. We capture not just the metrics, but also the hyperparameters and version of the code, and we can save your model checkpoints for you so your project is reproducible.\\nAutomatic organization: If you hand off a project to a collaborator or take a vacation, W&B makes it easy to see all the models you've tried so you're not wasting hours re-running old experiments.\\nFast, flexible integration: Add W&B to your project in 5 minutes. Install our free open-source Python package and add a couple of lines to your code, and every time you run your model you'll have nice logged metrics and records.\\nPersistent, centralized dashboard: Anywhere you train your models, whether on your local machine, your lab cluster, or spot instances in the cloud, we give you the same centralized dashboard. You don't need to spend your time copying and organizing TensorBoard files from different machines.\\nPowerful table: Search, filter, sort, and group results from different models. It's easy to look over thousands of model versions and find the best-performing models for different tasks. TensorBoard isn't built to work well on large projects.\\nTools for collaboration: Use W&B to organize complex machine learning projects. It's easy to share a link to W&B, and you can use private teams to have everyone send results to a shared project. We also support collaboration via reports— add interactive visualizations and describe your work in markdown. This is a great way to keep a work log, share findings with your supervisor, or present findings to your lab.\\nGet started with a free account\\nHow does wandb stream logs and writes to disk?\\nW&B queues in memory but also write the events to disk asynchronously to handle failures and for the `WANDB_MODE=offline` case where you can sync the data after it's been logged.\\nIn your terminal, you can see a path to the local run directory. This directory will contain a `.wandb` file that is the datastore above. If you're also logging images, we write them to `media/images` in that directory before uploading them to cloud storage.\", 'source': 'guides/technical-faq/general.md', 'score': 0.7994422999999999, 'relevance': 0}, {'content': 'Check out interactive examples!\\nYou can follow along in our video tutorial with our tutorial colab here\\nFrequently Asked Questions\\nHow does W&B integrate with Lightning?\\nThe core integration is based on the Lightning loggers API, which lets you write much of your logging code in a framework-agnostic way. `Logger`s are passed to the Lightning Trainer and are triggered based on that API\\'s rich hook-and-callback system. This keeps your research code well-separated from engineering and logging code.\\nWhat does the integration log without any additional code?\\nWe\\'ll save your model checkpoints to W&B, where you can view them or download them for use in future runs. We\\'ll also capture system metrics, like GPU usage and network I/O, environment information, like hardware and OS information, code state (including git commit and diff patch, notebook contents and session history), and anything printed to the standard out.\\nWhat if I really need to use wandb.run in my training setup?\\nYou will have to essentially expand the scope of the variable you need to access yourself. In other words, making sure that the initial conditions are the same on all processes.\\nif os.environ.get(\"LOCAL_RANK\", None) is None:\\n    os.environ[\"WANDB_DIR\"] = wandb.run.dir\\nThen, you can use `os.environ[\"WANDB_DIR\"]` to set up the model checkpoints directory. This way, `wandb.run.dir` can be used by any non-zero rank processes as well.', 'source': 'guides/integrations/lightning.md', 'score': 0.49688914, 'relevance': 0}]}),\n",
       " WeaveDict({'question': 'i am not getting loss/average data from training only loss. What are reasons for this?', 'answer': 'If you\\'re only seeing loss data and not the average loss during your training sessions with Weights & Biases, there could be several reasons for this issue. Here are some steps and checks you can perform to troubleshoot and resolve this:\\n\\n1. **Check Your Logging Code**: Ensure that you are logging the average loss explicitly. Weights & Biases does not automatically calculate averages unless specified. You need to manually calculate the average and log it using `wandb.log()`. For example:\\n\\n   ```python\\n   average_loss = total_loss / number_of_batches\\n   wandb.log({\"average_loss\": average_loss})\\n   ```\\n\\n2. **Ensure Consistent Logging**: Make sure that you are logging the average loss at the same frequency as the loss. Inconsistencies in logging can lead to missing data in the dashboard.\\n\\n3. **Check for Errors or Warnings**: Look at the console or the logs for any errors or warnings that might indicate what the issue is. Sometimes, misconfigurations or exceptions during logging can cause some metrics not to be recorded.\\n\\n4. **Version Compatibility**: Verify that the version of Weights & Biases you are using is compatible with your training framework. Incompatibilities can sometimes lead to unexpected behavior.\\n\\n5. **Review W&B Initialization**: Ensure that your `wandb.init()` call is correctly configured and that your project is set up correctly in the Weights & Biases dashboard.\\n\\n6. **Manual Calculation and Logging**: If you\\'re not already, ensure that you are calculating the average loss manually and logging it explicitly. Weights & Biases logs exactly what you tell it to log, so you need to provide the average calculation yourself.\\n\\nHere is an example snippet that demonstrates how to log both loss and average loss:\\n\\n```python\\nimport wandb\\n\\n# Initialize a new run\\nwandb.init(project=\"my_project\")\\n\\nfor epoch in range(epochs):\\n    total_loss = 0\\n    for batch_idx, (data, target) in enumerate(train_loader):\\n        # Training code here\\n        loss = train(data, target)\\n        total_loss += loss.item()\\n        # Log loss\\n        wandb.log({\"loss\": loss.item()})\\n\\n    # Calculate and log average loss\\n    average_loss = total_loss / len(train_loader)\\n    wandb.log({\"average_loss\": average_loss})\\n\\nwandb.finish()\\n```\\n\\nThis code ensures that both the loss for each batch and the average loss per epoch are logged to your Weights & Biases dashboard. Make sure that your actual training loop and loss calculations are correctly set up to reflect this structure.', 'contexts': [{'content': 'Log metrics inside your training loop\\nLog metrics during each `for` loop (epoch), the accuracy and loss values are computed and logged to W&B with wandb.log(). By default, when you call wandb.log it appends a new step to the history object and updates the summary object.\\nThe following code example shows how to log metrics with `wandb.log`.\\n:::note\\nDetails of how to set up your mode and retrieve data are omitted. \\n:::\\n# Set up model and data\\nmodel, dataloader = get_model(), get_data()\\nfor epoch in range(wandb.config.epochs):\\n    for batch in dataloader:\\n        loss, accuracy = model.training_step()\\n        # \\u20033. Log metrics inside your training loop to visualize\\n        # model performance\\n        wandb.log({\"accuracy\": accuracy, \"loss\": loss})\\nFor more information on different data types you can log with W&B, see Log Data During Experiments.\\nLog an artifact to W&B\\nOptionally log a W&B Artifact. Artifacts make it easy to version datasets and models. \\nwandb.log_artifact(model)\\nFor more information about Artifacts, see the Artifacts Chapter. For more information about versioning models, see Model Management.\\nPutting it all together\\nThe full script with the preceding code snippets is found below:\\n# Import the W&B Python Library\\nimport wandb\\n# 1. Start a W&B Run\\nrun = wandb.init(project=\"cat-classification\", notes=\"\", tags=[\"baseline\", \"paper1\"])\\n# \\u20032. Capture a dictionary of hyperparameters\\nwandb.config = {\"epochs\": 100, \"learning_rate\": 0.001, \"batch_size\": 128}\\n# Set up model and data\\nmodel, dataloader = get_model(), get_data()\\nfor epoch in range(wandb.config.epochs):\\n    for batch in dataloader:\\n        loss, accuracy = model.training_step()\\n        # \\u20033. Log metrics inside your training loop to visualize\\n        # model performance\\n        wandb.log({\"accuracy\": accuracy, \"loss\": loss})\\n# 4. Log an artifact to W&B\\nwandb.log_artifact(model)\\n# Optional: save model at the end\\nmodel.to_onnx()\\nwandb.save(\"model.onnx\")', 'source': 'guides/track/launch.md', 'score': 0.003976228, 'relevance': 2}, {'content': 'Log a dictionary of data to the current run\\'s history.\\nUse `wandb.log` to log data from runs, such as scalars, images, video,\\nhistograms, plots, and tables.\\nSee our guides to logging for\\nlive examples, code snippets, best practices, and more.\\nThe most basic usage is `wandb.log({\"train-loss\": 0.5, \"accuracy\": 0.9})`.\\nThis will save the loss and accuracy to the run\\'s history and update\\nthe summary values for these metrics.\\nVisualize logged data in the workspace at wandb.ai,\\nor locally on a self-hosted instance\\nof the W&B app, or export data to visualize and explore locally, e.g. in\\nJupyter notebooks, with our API.\\nIn the UI, summary values show up in the run table to compare single values across runs.\\nSummary values can also be set directly with `wandb.run.summary[\"key\"] = value`.\\nLogged values don\\'t have to be scalars. Logging any wandb object is supported.\\nFor example `wandb.log({\"example\": wandb.Image(\"myimage.jpg\")})` will log an\\nexample image which will be displayed nicely in the W&B UI.\\nSee the reference documentation\\nfor all of the different supported types or check out our\\nguides to logging for examples,\\nfrom 3D molecular structures and segmentation masks to PR curves and histograms.\\n`wandb.Table`s can be used to logged structured data. See our\\nguide to logging tables\\nfor details.\\nLogging nested metrics is encouraged and is supported in the W&B UI.\\nIf you log with a nested dictionary like `wandb.log({\"train\": {\"acc\": 0.9}, \"val\": {\"acc\": 0.8}})`, the metrics will be organized into\\n`train` and `val` sections in the W&B UI.\\nwandb keeps track of a global step, which by default increments with each\\ncall to `wandb.log`, so logging related metrics together is encouraged.\\nIf it\\'s inconvenient to log related metrics together\\ncalling `wandb.log({\"train-loss\": 0.5}, commit=False)` and then\\n`wandb.log({\"accuracy\": 0.9})` is equivalent to calling\\n`wandb.log({\"train-loss\": 0.5, \"accuracy\": 0.9})`.', 'source': 'ref/python/run.md', 'score': 0.0020667946, 'relevance': 2}, {'content': 'Use `wandb.log` to log data from runs, such as scalars, images, video,\\nhistograms, plots, and tables.\\nSee our guides to logging for\\nlive examples, code snippets, best practices, and more.\\nThe most basic usage is `wandb.log({\"train-loss\": 0.5, \"accuracy\": 0.9})`.\\nThis will save the loss and accuracy to the run\\'s history and update\\nthe summary values for these metrics.\\nVisualize logged data in the workspace at wandb.ai,\\nor locally on a self-hosted instance\\nof the W&B app, or export data to visualize and explore locally, e.g. in\\nJupyter notebooks, with our API.\\nIn the UI, summary values show up in the run table to compare single values across runs.\\nSummary values can also be set directly with `wandb.run.summary[\"key\"] = value`.\\nLogged values don\\'t have to be scalars. Logging any wandb object is supported.\\nFor example `wandb.log({\"example\": wandb.Image(\"myimage.jpg\")})` will log an\\nexample image which will be displayed nicely in the W&B UI.\\nSee the reference documentation\\nfor all of the different supported types or check out our\\nguides to logging for examples,\\nfrom 3D molecular structures and segmentation masks to PR curves and histograms.\\n`wandb.Table`s can be used to logged structured data. See our\\nguide to logging tables\\nfor details.\\nLogging nested metrics is encouraged and is supported in the W&B UI.\\nIf you log with a nested dictionary like `wandb.log({\"train\": {\"acc\": 0.9}, \"val\": {\"acc\": 0.8}})`, the metrics will be organized into\\n`train` and `val` sections in the W&B UI.\\nwandb keeps track of a global step, which by default increments with each\\ncall to `wandb.log`, so logging related metrics together is encouraged.\\nIf it\\'s inconvenient to log related metrics together\\ncalling `wandb.log({\"train-loss\": 0.5}, commit=False)` and then\\n`wandb.log({\"accuracy\": 0.9})` is equivalent to calling\\n`wandb.log({\"train-loss\": 0.5, \"accuracy\": 0.9})`.', 'source': 'ref/python/log.md', 'score': 0.0017546144, 'relevance': 2}, {'content': '@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\\n    def log_training_loss(engine):\\n        pbar.desc = desc.format(engine.state.output)\\n        pbar.update(log_interval)\\n    @trainer.on(Events.EPOCH_COMPLETED)\\n    def log_training_results(engine):\\n        pbar.refresh()\\n        evaluator.run(train_loader)\\n        metrics = evaluator.state.metrics\\n        avg_accuracy = metrics[\\'accuracy\\']\\n        avg_nll = metrics[\\'nll\\']\\n        tqdm.write(\\n            \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\\n            .format(engine.state.epoch, avg_accuracy, avg_nll)\\n        )\\n    @trainer.on(Events.EPOCH_COMPLETED)\\n    def log_validation_results(engine):\\n        evaluator.run(val_loader)\\n        metrics = evaluator.state.metrics\\n        avg_accuracy = metrics[\\'accuracy\\']\\n        avg_nll = metrics[\\'nll\\']\\n        tqdm.write(\\n            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\\n            .format(engine.state.epoch, avg_accuracy, avg_nll))\\n        pbar.n = pbar.last_print_n = 0\\n    trainer.run(train_loader, max_epochs=epochs)\\n    pbar.close()\\nif __name__ == \"__main__\":\\n    parser = ArgumentParser()\\n    parser.add_argument(\\'--batch_size\\', type=int, default=64,\\n                        help=\\'input batch size for training (default: 64)\\')\\n    parser.add_argument(\\'--val_batch_size\\', type=int, default=1000,\\n                        help=\\'input batch size for validation (default: 1000)\\')\\n    parser.add_argument(\\'--epochs\\', type=int, default=10,\\n                        help=\\'number of epochs to train (default: 10)\\')\\n    parser.add_argument(\\'--lr\\', type=float, default=0.01,\\n                        help=\\'learning rate (default: 0.01)\\')\\n    parser.add_argument(\\'--momentum\\', type=float, default=0.5,\\n                        help=\\'SGD momentum (default: 0.5)\\')\\n    parser.add_argument(\\'--log_interval\\', type=int, default=10,\\n                        help=\\'how many batches to wait before logging training status\\')\\n    args = parser.parse_args()\\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval)\\nWe get these visualizations on running the above code:\\nRefer Ignite Docs for more detailed documentation', 'source': 'guides/integrations/other/ignite.md', 'score': 0.021125192, 'relevance': 1}, {'content': '# ✨ W&B: Log loss over training steps, visualized in the UI live\\n        wandb.log({\"loss\" : loss})\\n        if (i+1) % 100 == 0:\\n            print (\\'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\\'\\n                .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))', 'source': 'tutorials/tables.md', 'score': 0.00685048, 'relevance': 1}, {'content': 'Logging FAQs\\nFrequently Asked Questions About Logging Data from Experiments\\nHow can I organize my logged charts and media in the W&B UI?\\nWe treat `/` as a separator for organizing logged panels in the W&B UI. By default, the component of the logged item\\'s name before a `/` is used to define a group of panel called a \"Panel Section\".\\nwandb.log({\"val/loss\": 1.1, \"val/acc\": 0.3})\\nwandb.log({\"train/loss\": 0.1, \"train/acc\": 0.94})\\nIn the Workspace settings, you can change whether panels are grouped by just the first component or by all components separated by `/`.\\nHow can I compare images or media across epochs or steps?\\nEach time you log images from a step, we save them to show in the UI. Expand the image panel, and use the step slider to look at images from different steps. This makes it easy to compare how a model\\'s output changes during training.\\nWhat if I want to log some metrics on batches and some metrics only on epochs?\\nIf you\\'d like to log certain metrics in every batch and standardize plots, you can log x axis values that you want to plot with your metrics. Then in the custom plots, click edit and select a custom x-axis.\\nwandb.log({\"batch\": batch_idx, \"loss\": 0.3})\\nwandb.log({\"epoch\": epoch, \"val_acc\": 0.94})\\nHow do I log a list of values?\\nwandb.log({f\"losses/loss-{ii}\": loss for ii, loss in enumerate(losses)})\\nwandb.log({\"losses\": wandb.Histogram(losses)})  # converts losses to a histogram', 'source': 'guides/track/log/logging-faqs.md', 'score': 0.0028228330000000003, 'relevance': 1}, {'content': 'Preventing x-axis Misalignments\\nSometimes you might need to perform multiple calls to `wandb.log` for the same training step. The wandb SDK has its own internal step counter that is incremented every time a `wandb.log` call is made. This means that there is a possibility that the wandb log counter is not aligned with the training step in your training loop.\\nIn first pass of the example below, the internal `wandb` step for `train/loss` will be 0, while the internal `wandb` step for  `eval/loss`  will be 1. On the next pass, the `train/loss` will be 2, while the  `eval/loss` wandb step will be 3, etc\\nfor input, ground_truth in data:\\n    ...\\n    wandb.log(“train/loss”: 0.1)  \\n    wandb.log(“eval/loss”: 0.2)\\nTo avoid this, we recommend that you specifically define your x-axis step. You can define the x-axis with `wandb.define_metric` and you only need to do this once, after `wandb.init` is called:\\nwandb.init(...)\\nwandb.define_metric(\"*\", step_metric=\"global_step\")\\nThe glob pattern, \"*\", means that every metric will use “global_step” as the x-axis in your charts. If you only want certain metrics to be logged against \"global_step\", you can specify them instead:\\nwandb.define_metric(\"train/loss\", step_metric=\"global_step\")\\nNow that you\\'ve called `wandb.define_metric` , you just need to log your metrics as well as your `step_metric`, \"global_step\", every time you call `wandb.log`:\\nfor step, (input, ground_truth) in enumerate(data):\\n    ...\\n    wandb.log({“global_step”: step, “train/loss”: 0.1})\\n    wandb.log({“global_step”: step, “eval/loss”: 0.2})\\nIf you do not have access to the independent step variable, for example “global_step” is not available during your validation loop, the previously logged value for \"global_step\" is automatically used by wandb. In this case, ensure you log an initial value for the metric so it has been defined when it’s needed.', 'source': 'guides/integrations/add-wandb-to-any-library.md', 'score': 0.0027255826, 'relevance': 1}, {'content': 'print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\\n    # If you had a test set, this is how you could log it as a Summary metric\\n    wandb.summary[\\'test_accuracy\\'] = 0.8\\n    # 🐝 Close your wandb run \\n    wandb.finish()', 'source': 'tutorials/experiments.md', 'score': 0.0043483814, 'relevance': 0}, {'content': \"What happens if internet connection is lost while I'm training a model?\\nIf our library is unable to connect to the internet it will enter a retry loop and keep attempting to stream metrics until the network is restored. During this time your program is able to continue running.\\nIf you need to run on a machine without internet, you can set `WANDB_MODE=offline` to only have metrics stored locally on your hard drive. Later you can call `wandb sync DIRECTORY` to have the data streamed to our server.\", 'source': 'guides/technical-faq/troubleshooting.md', 'score': 0.0013406205, 'relevance': 0}, {'content': 'Logged Metrics\\nEach recipe has their own training loop, so check each individual recipe to see what metrics are logged. The default metrics logged are:\\nMetric\\nDescription\\n`loss`\\nThe loss of the model\\n`lr`\\nThe learning rate\\n`tokens_per_second`\\nThe tokens per second of the model\\n`grad_norm`\\nThe gradient norm of the model\\n`global_step`\\nCorresponds to the current step in the training loop. Takes into account gradient accumulation, basically every time an optimizer step is taken, the model is updated, the gradients are accumulated and the model is updated once every `gradient_accumulation_steps`\\n:::info\\n`global_step` is not the same as the number of training steps. It corresponds to the current step in the training loop. Takes into account gradient accumulation, basically every time an optimizer step is taken the `global_step` is incremented by 1. For example, if the dataloader has 10 batches, gradient accumulation steps is 2 and run for 3 epochs, the optimizer will step 15 times, in this case `global_step` will range from 1 to 15.\\n:::\\nThe streamlined design of torchtune allows to easily add custom metrics or modify the existing ones. It suffices to modify the corresponding recipe file, for example, computing one could log `current_epoch` as a percentage of the total number of epochs as following:\\n# inside `train.py` function in the recipe file\\nself._metric_logger.log_dict(\\n    {\"current_epoch\": self.epochs * self.global_step / self._steps_per_epoch},\\n    step=self.global_step,\\n)\\n:::info\\nThis is a fast evolving library, the current metrics are subject to change. If you want to add a custom metric, you should modify the recipe and call the corresponding `self._metric_logger.*` function.\\n:::', 'source': 'guides/integrations/torchtune.md', 'score': 0.0006411777000000001, 'relevance': 0}]})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.rows[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_evaluation = weave.Evaluation(\n",
    "    name=\"Retrieval_Evaluation\",\n",
    "    dataset=eval_dataset.rows[:10],\n",
    "    scorers=RETRIEVAL_METRICS,\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"], \"top_k\": 10, \"top_n\": 5},\n",
    ")\n",
    "# dense_retrieval_scores = asyncio.run(retrieval_evaluation.evaluate(dense_retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the query enhancer, response generator, and RAG pipeline from the previous chapter\n",
    "\n",
    "import cohere\n",
    "from scripts.query_enhancer import QueryEnhancer\n",
    "from scripts.response_generator import QueryEnhanedResponseGenerator\n",
    "from scripts.rag_pipeline import QueryEnhancedRAGPipeline\n",
    "\n",
    "query_enhancer = QueryEnhancer()\n",
    "# lets add the new prompt\n",
    "QUERY_ENHANCED_PROMPT = open(\"prompts/query_enhanced_system.txt\").read()\n",
    "\n",
    "response_generator = QueryEnhanedResponseGenerator(\n",
    "    model=\"command-r-plus\", prompt=QUERY_ENHANCED_PROMPT, client=cohere.AsyncClient()\n",
    ")\n",
    "\n",
    "rag_pipeline = QueryEnhancedRAGPipeline(\n",
    "    query_enhancer=query_enhancer,\n",
    "    retriever=dense_retriever,\n",
    "    response_generator=response_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.response_metrics import ALL_METRICS as RESPONSE_METRICS\n",
    "\n",
    "response_evaluations = weave.Evaluation(\n",
    "    name=\"Response_Evaluation\",\n",
    "    dataset=eval_dataset.rows[:10],\n",
    "    scorers=RESPONSE_METRICS,\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"]},\n",
    ")\n",
    "query_enhanced_response_scores = asyncio.run(\n",
    "    response_evaluations.evaluate(rag_pipeline)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.retriever import HybridRetrieverReranker\n",
    "\n",
    "hybrid_retriever = HybridRetrieverReranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a086b8a3474843c79d956b650e113f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hybrid_retriever.index_data(chunked_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069bab8bd52b4387b6090e51d4108a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bcf1b961dc473f89ba864b395619ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbda228f6cc645029ac01e4a32ea29e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93b69f239ed4e6b84504339b56f09be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc33199cb294027986f9124cebe46e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413793644c584c759841e6db85823cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6dbd97feb745e4bd54c47a5fa21132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4b1690adc04c34a4202afb826c4b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a550623511f481c94509015e9eaa8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a82d9f0589848ab97304a4d5530e0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_hit_rate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5399999999999999</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_mrr'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2823333333333333</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_ndcg'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4504062569632664</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_map'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7809126984126984</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_precision'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45833333333333337</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_recall'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5019047619047619</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compute_f1_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4494444444444444</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_retrieval_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'relevance'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'relevance_rank_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24166666666666664</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.96199152469635</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'compute_hit_rate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.5399999999999999\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compute_mrr'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.2823333333333333\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compute_ndcg'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.4504062569632664\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compute_map'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.7809126984126984\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compute_precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.45833333333333337\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compute_recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.5019047619047619\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compute_f1_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.4494444444444444\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'llm_retrieval_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'relevance'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.7\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'relevance_rank_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.24166666666666664\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.96199152469635\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hybrid_retrieval_scores = asyncio.run(retrieval_evaluation.evaluate(hybrid_retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
