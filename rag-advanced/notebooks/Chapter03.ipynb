{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 \n",
    "## Data Ingestion and Preprocessing\n",
    "\n",
    "One way to improve our RAG system is to improve our data ingestion and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import wandb\n",
    "import cohere\n",
    "import requests\n",
    "import markdown\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mparambharat\u001b[0m (\u001b[33mrag-course\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/mugan/data/wandb/projects/edu/rag-advanced/notebooks/wandb/run-20240704_171355-bn5dpiph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rag-course/dev/runs/bn5dpiph' target=\"_blank\">elated-resonance-18</a></strong> to <a href='https://wandb.ai/rag-course/dev' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rag-course/dev' target=\"_blank\">https://wandb.ai/rag-course/dev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rag-course/dev/runs/bn5dpiph' target=\"_blank\">https://wandb.ai/rag-course/dev/runs/bn5dpiph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WANDB_ENTITY = \"rag-course\"\n",
    "WANDB_PROJECT = \"dev\"\n",
    "\n",
    "wandb.require(\"core\")\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=WANDB_ENTITY,\n",
    "    project=WANDB_PROJECT,\n",
    "    group=\"Chapter 3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/04 17:13:57 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/rag-course/dev/0z2t11h3/artifact/936065098/wandb_manifest.json?Expires=1720097037&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=bMktGRSkJcXb%2FxWpQNSLbiBv%2FfFsE1Xsw9LoOOjcFOSAbD9CxakPgMDgvgZTsU4cGXHVceERXsqfOzLfeA%2BI5JPB7aWo4V9IZakLrPjFBMs1ueRNCoiLSNE5sikvnVA9Dw%2FNdGzlSRyjtYRVBsknElgIbT7dvJxo1dlrx%2FLIs%2B1P0wsjOaWFHXqThg3yIFJfWrUwB%2FKdaG%2B6OaxPhevCekX6Nc9jGGjAWZL3pn0vgjkzgTYcuJfHN1r9YbnmkHqIuL09%2BJrOJ3P4AQAacecnv5KDa1eR4swnBa84OcVFroVE%2FxgbSGWa19ttzCu4HGkGB62979dTz6v%2F4Z5VLm%2F2Bg%3D%3D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': '---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n',\n",
       "  'metadata': {'source': 'guides/app/features/anon.md', 'raw_tokens': 470}},\n",
       " {'content': '---\\nslug: /guides/app/features/custom-charts\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Custom Charts\\n\\nUse **Custom Charts** to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of [Vega](https://vega.github.io/vega/).\\n\\n* **What\\'s possible**: Read the[ launch announcement →](https://wandb.ai/wandb/posts/reports/Announcing-the-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n* **Code**: Try a live example in a[ hosted notebook →](https://tiny.cc/custom-charts)\\n* **Video**: Watch a quick [walkthrough video →](https://www.youtube.com/watch?v=3-N9OV6bkSM)\\n* **Example**: Quick Keras and Sklearn [demo notebook →](https://colab.research.google.com/drive/1g-gNGokPWM2Qbc8p1Gofud0\\\\_5AoZdoSD?usp=sharing)\\n\\n![Supported charts from vega.github.io/vega](/images/app_ui/supported_charts.png)\\n\\n### How it works\\n\\n1. **Log data**: From your script, log [config](../../../../guides/track/config.md) and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a custom`wandb.Table`\\n2. **Customize the chart**: Pull in any of this logged data with a [GraphQL](https://graphql.org) query. Visualize the results of your query with [Vega](https://vega.github.io/vega/), a powerful visualization grammar.\\n3. **Log the chart**: Call your own preset from your script with `wandb.plot_table()`.\\n\\n![](/images/app_ui/pr_roc.png)\\n\\n## Log charts from a script\\n\\n### Builtin presets\\n\\nThese presets have builtin `wandb.plot` methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n<Tabs\\n  defaultValue=\"line-plot\"\\n  values={[\\n    {label: \\'Line plot\\', value: \\'line-plot\\'},\\n    {label: \\'Scatter plot\\', value: \\'scatter-plot\\'},\\n    {label: \\'Bar chart\\', value: \\'bar-chart\\'},\\n    {label: \\'Histogram\\', value: \\'histogram\\'},\\n    {label: \\'PR curve\\', value: \\'pr-curve\\'},\\n    {label: \\'ROC curve\\', value: \\'roc-curve\\'},\\n  ]}>\\n  <TabItem value=\"line-plot\">\\n\\n`wandb.plot.line()`\\n\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/line_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Line-Plots--VmlldzoyNjk5NTA)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"scatter-plot\">\\n\\n`wandb.plot.scatter()`\\n\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n```\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/demo_scatter_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Scatter-Plots--VmlldzoyNjk5NDQ)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"bar-chart\">\\n\\n`wandb.plot.bar()`\\n\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\n\\n```python\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\n![](@site/static/images/app_ui/line_plot_bar_chart.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Bar-Charts--VmlldzoyNzExNzk)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"histogram\">\\n\\n`wandb.plot.histogram()`\\n\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (`scores`) and want to visualize their distribution:\\n\\n```python\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n```\\n\\nYou can use this to log arbitrary histograms. Note that `data` is a list of lists, intended to support a 2D array of rows and columns.\\n\\n![](/images/app_ui/demo_custom_chart_histogram.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Histograms--VmlldzoyNzE0NzM)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n    <TabItem value=\"pr-curve\">\\n\\n`wandb.plot.pr_curve()`\\n\\nCreate a [Precision-Recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision\\\\_recall\\\\_curve.html#sklearn.metrics.precision\\\\_recall\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n![](/images/app_ui/demo_average_precision_lines.png)\\n\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-Precision-Recall-Curves--VmlldzoyNjk1ODY)\\n\\n[Run the code →](https://colab.research.google.com/drive/1mS8ogA3LcZWOXchfJoMrboW3opY1A8BY?usp=sharing)\\n\\n  </TabItem>\\n  <TabItem value=\"roc-curve\">\\n\\n`wandb.plot.roc_curve()`\\n\\nCreate an [ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc\\\\_curve.html#sklearn.metrics.roc\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/ class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n![](/images/app_ui/demo_custom_chart_roc_curve.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-ROC-Curves--VmlldzoyNjk3MDE)\\n\\n[Run the code →](https://colab.research.google.com/drive/1\\\\_RMppCqsA8XInV\\\\_jhJz32NCZG6Z5t1RO?usp=sharing)\\n\\n  </TabItem>\\n</Tabs>\\n\\n### Custom presets\\n\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n\\n```python\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n```\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n![](/images/app_ui/custom_presets.png)\\n\\n## Log data\\n\\nHere are the data types you can log from your script and use in a custom chart:\\n\\n* **Config**: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to `wandb.config` at the start of your training (e.g. `wandb.config.learning_rate = 0.0001)`\\n* **Summary**: Single values logged during training (your results or dependent variables), e.g. `wandb.log({\"val_acc\" : 0.8})`. If you write to this key multiple times during training via `wandb.log()`, the summary is set to the final value of that key.\\n* **History**: The full time series of the logged scalar is available to the query via the `history` field\\n* **summaryTable**: If you need to log a list of multiple values, use a `wandb.Table()` to save that data, then query it in your custom panel.\\n* **historyTable**: If you need to see the history data, then query `historyTable` in your custom chart panel. Each time you call `wandb.Table()` or log a custom chart, you\\'re creating a new table in history for that step.\\n\\n### How to log a custom table\\n\\nUse `wandb.Table()` to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to `wandb.log()`(\"custom\\\\_data\\\\_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\n\\n[Try it in a Google Colab →](https://tiny.cc/custom-charts)\\n\\n```python\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n```\\n\\n## Customize the chart\\n\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses [GraphQL](https://graphql.org) to fetch data from the config, summary, and history fields in your runs.\\n\\n![Add a new custom chart, then edit the query](/images/app_ui/customize_chart.gif)\\n\\n### Custom visualizations\\n\\nSelect a **Chart** in the upper right corner to start with a default preset. Next, pick **Chart fields** to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\n![Creating a custom bar chart showing accuracy across runs in a project](/images/app_ui/demo_make_a_custom_chart_bar_chart.gif)\\n\\n### How to edit Vega\\n\\nClick **Edit** at the top of the panel to go into [Vega](https://vega.github.io/vega/) edit mode. Here you can define a [Vega specification](https://vega.github.io/vega/docs/specification/) that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The [Vega documentation and tutorials ](https://vega.github.io/vega/)are an excellent source of inspiration.\\n\\n**Field references**\\n\\nTo pull data into your chart from W&B, add template strings of the form `\"${field:<field-name>}\"` anywhere in your Vega spec. This will create a dropdown in the **Chart Fields** area on the right side, which users can use to select a query result column to map into Vega.\\n\\nTo set a default value for a field, use this syntax: `\"${field:<field-name>:<placeholder text>}\"`\\n\\n### Saving chart presets\\n\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click **Save as** at the top of the Vega editor and give your preset a name.\\n\\n## Articles and guides\\n\\n1. [The W&B Machine Learning Visualization IDE](https://wandb.ai/wandb/posts/reports/The-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n2. [Visualizing NLP Attention Based Models](https://wandb.ai/kylegoyette/gradientsandtranslation2/reports/Visualizing-NLP-Attention-Based-Models-Using-Custom-Charts--VmlldzoyNjg2MjM)\\n3. [Visualizing The Effect of Attention on Gradient Flow](https://wandb.ai/kylegoyette/gradientsandtranslation/reports/Visualizing-The-Effect-of-Attention-on-Gradient-Flow-Using-Custom-Charts--VmlldzoyNjg1NDg)\\n4. [Logging arbitrary curves](https://wandb.ai/stacey/presets/reports/Logging-Arbitrary-Curves--VmlldzoyNzQyMzA)\\n\\n## Frequently asked questions\\n\\n### Coming soon\\n\\n* **Polling**: Auto-refresh of data in the chart\\n* **Sampling**: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\n### Gotchas\\n\\n* Not seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the **eye** icon.\\n\\n### How to show a \"step slider\" in a custom chart?\\n\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a `historyTable` instead of the `summaryTable`, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\n\\n<!-- ![Show step slider in a custom chart](/images/app_ui/step_sllider_custon_charts.mov>) -->\\n\\n### How to delete a custom chart preset?\\n\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\n![](/images/app_ui/delete_custome_chart_preset.gif)\\n\\n\\n### Common use cases\\n\\n* Customize bar plots with error bars\\n* Show model validation metrics which require custom x-y coordinates (like precision-recall curves)\\n* Overlay data distributions from two different models/experiments as histograms\\n* Show changes in a metric via snapshots at multiple points during training\\n* Create a unique visualization not yet available in W&B (and hopefully share it with the world)\\n',\n",
       "  'metadata': {'source': 'guides/app/features/custom-charts/intro.md',\n",
       "   'raw_tokens': 1904}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll re-use the raw dataset from the artifact in our previous step\n",
    "\n",
    "\n",
    "raw_artifact = run.use_artifact(\n",
    "    f\"{WANDB_ENTITY}/{WANDB_PROJECT}/raw_data:latest\", type=\"dataset\"\n",
    ")\n",
    "artifact_dir = raw_artifact.download()\n",
    "raw_data_file = pathlib.Path(f\"{artifact_dir}/documents.jsonl\")\n",
    "raw_data = list(map(json.loads, raw_data_file.read_text().splitlines()))\n",
    "raw_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlier we referred to words as tokens. We can be more correct in defining tokens by using a tokenizer.\n",
    "# We'll use the Cohere tokenizer for this example.\n",
    "\n",
    "co = cohere.Client(api_key=os.environ[\"CO_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text: str) -> List[str]:\n",
    "    return co.tokenize(text=text, model=\"command-r\", offline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = {\n",
    "    \"command-r\": \"https://storage.googleapis.com/cohere-public/tokenizers/command-r.json\",\n",
    "    \"command-r-plus\": \"https://storage.googleapis.com/cohere-public/tokenizers/command-r-plus.json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n',\n",
       "  'metadata': {'source': 'guides/app/features/anon.md',\n",
       "   'words': 470,\n",
       "   'tokens': 759}},\n",
       " {'content': '---\\nslug: /guides/app/features/custom-charts\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Custom Charts\\n\\nUse **Custom Charts** to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of [Vega](https://vega.github.io/vega/).\\n\\n* **What\\'s possible**: Read the[ launch announcement →](https://wandb.ai/wandb/posts/reports/Announcing-the-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n* **Code**: Try a live example in a[ hosted notebook →](https://tiny.cc/custom-charts)\\n* **Video**: Watch a quick [walkthrough video →](https://www.youtube.com/watch?v=3-N9OV6bkSM)\\n* **Example**: Quick Keras and Sklearn [demo notebook →](https://colab.research.google.com/drive/1g-gNGokPWM2Qbc8p1Gofud0\\\\_5AoZdoSD?usp=sharing)\\n\\n![Supported charts from vega.github.io/vega](/images/app_ui/supported_charts.png)\\n\\n### How it works\\n\\n1. **Log data**: From your script, log [config](../../../../guides/track/config.md) and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a custom`wandb.Table`\\n2. **Customize the chart**: Pull in any of this logged data with a [GraphQL](https://graphql.org) query. Visualize the results of your query with [Vega](https://vega.github.io/vega/), a powerful visualization grammar.\\n3. **Log the chart**: Call your own preset from your script with `wandb.plot_table()`.\\n\\n![](/images/app_ui/pr_roc.png)\\n\\n## Log charts from a script\\n\\n### Builtin presets\\n\\nThese presets have builtin `wandb.plot` methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n<Tabs\\n  defaultValue=\"line-plot\"\\n  values={[\\n    {label: \\'Line plot\\', value: \\'line-plot\\'},\\n    {label: \\'Scatter plot\\', value: \\'scatter-plot\\'},\\n    {label: \\'Bar chart\\', value: \\'bar-chart\\'},\\n    {label: \\'Histogram\\', value: \\'histogram\\'},\\n    {label: \\'PR curve\\', value: \\'pr-curve\\'},\\n    {label: \\'ROC curve\\', value: \\'roc-curve\\'},\\n  ]}>\\n  <TabItem value=\"line-plot\">\\n\\n`wandb.plot.line()`\\n\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/line_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Line-Plots--VmlldzoyNjk5NTA)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"scatter-plot\">\\n\\n`wandb.plot.scatter()`\\n\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n```\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/demo_scatter_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Scatter-Plots--VmlldzoyNjk5NDQ)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"bar-chart\">\\n\\n`wandb.plot.bar()`\\n\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\n\\n```python\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\n![](@site/static/images/app_ui/line_plot_bar_chart.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Bar-Charts--VmlldzoyNzExNzk)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"histogram\">\\n\\n`wandb.plot.histogram()`\\n\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (`scores`) and want to visualize their distribution:\\n\\n```python\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n```\\n\\nYou can use this to log arbitrary histograms. Note that `data` is a list of lists, intended to support a 2D array of rows and columns.\\n\\n![](/images/app_ui/demo_custom_chart_histogram.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Histograms--VmlldzoyNzE0NzM)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n    <TabItem value=\"pr-curve\">\\n\\n`wandb.plot.pr_curve()`\\n\\nCreate a [Precision-Recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision\\\\_recall\\\\_curve.html#sklearn.metrics.precision\\\\_recall\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n![](/images/app_ui/demo_average_precision_lines.png)\\n\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-Precision-Recall-Curves--VmlldzoyNjk1ODY)\\n\\n[Run the code →](https://colab.research.google.com/drive/1mS8ogA3LcZWOXchfJoMrboW3opY1A8BY?usp=sharing)\\n\\n  </TabItem>\\n  <TabItem value=\"roc-curve\">\\n\\n`wandb.plot.roc_curve()`\\n\\nCreate an [ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc\\\\_curve.html#sklearn.metrics.roc\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/ class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n![](/images/app_ui/demo_custom_chart_roc_curve.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-ROC-Curves--VmlldzoyNjk3MDE)\\n\\n[Run the code →](https://colab.research.google.com/drive/1\\\\_RMppCqsA8XInV\\\\_jhJz32NCZG6Z5t1RO?usp=sharing)\\n\\n  </TabItem>\\n</Tabs>\\n\\n### Custom presets\\n\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n\\n```python\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n```\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n![](/images/app_ui/custom_presets.png)\\n\\n## Log data\\n\\nHere are the data types you can log from your script and use in a custom chart:\\n\\n* **Config**: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to `wandb.config` at the start of your training (e.g. `wandb.config.learning_rate = 0.0001)`\\n* **Summary**: Single values logged during training (your results or dependent variables), e.g. `wandb.log({\"val_acc\" : 0.8})`. If you write to this key multiple times during training via `wandb.log()`, the summary is set to the final value of that key.\\n* **History**: The full time series of the logged scalar is available to the query via the `history` field\\n* **summaryTable**: If you need to log a list of multiple values, use a `wandb.Table()` to save that data, then query it in your custom panel.\\n* **historyTable**: If you need to see the history data, then query `historyTable` in your custom chart panel. Each time you call `wandb.Table()` or log a custom chart, you\\'re creating a new table in history for that step.\\n\\n### How to log a custom table\\n\\nUse `wandb.Table()` to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to `wandb.log()`(\"custom\\\\_data\\\\_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\n\\n[Try it in a Google Colab →](https://tiny.cc/custom-charts)\\n\\n```python\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n```\\n\\n## Customize the chart\\n\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses [GraphQL](https://graphql.org) to fetch data from the config, summary, and history fields in your runs.\\n\\n![Add a new custom chart, then edit the query](/images/app_ui/customize_chart.gif)\\n\\n### Custom visualizations\\n\\nSelect a **Chart** in the upper right corner to start with a default preset. Next, pick **Chart fields** to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\n![Creating a custom bar chart showing accuracy across runs in a project](/images/app_ui/demo_make_a_custom_chart_bar_chart.gif)\\n\\n### How to edit Vega\\n\\nClick **Edit** at the top of the panel to go into [Vega](https://vega.github.io/vega/) edit mode. Here you can define a [Vega specification](https://vega.github.io/vega/docs/specification/) that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The [Vega documentation and tutorials ](https://vega.github.io/vega/)are an excellent source of inspiration.\\n\\n**Field references**\\n\\nTo pull data into your chart from W&B, add template strings of the form `\"${field:<field-name>}\"` anywhere in your Vega spec. This will create a dropdown in the **Chart Fields** area on the right side, which users can use to select a query result column to map into Vega.\\n\\nTo set a default value for a field, use this syntax: `\"${field:<field-name>:<placeholder text>}\"`\\n\\n### Saving chart presets\\n\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click **Save as** at the top of the Vega editor and give your preset a name.\\n\\n## Articles and guides\\n\\n1. [The W&B Machine Learning Visualization IDE](https://wandb.ai/wandb/posts/reports/The-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n2. [Visualizing NLP Attention Based Models](https://wandb.ai/kylegoyette/gradientsandtranslation2/reports/Visualizing-NLP-Attention-Based-Models-Using-Custom-Charts--VmlldzoyNjg2MjM)\\n3. [Visualizing The Effect of Attention on Gradient Flow](https://wandb.ai/kylegoyette/gradientsandtranslation/reports/Visualizing-The-Effect-of-Attention-on-Gradient-Flow-Using-Custom-Charts--VmlldzoyNjg1NDg)\\n4. [Logging arbitrary curves](https://wandb.ai/stacey/presets/reports/Logging-Arbitrary-Curves--VmlldzoyNzQyMzA)\\n\\n## Frequently asked questions\\n\\n### Coming soon\\n\\n* **Polling**: Auto-refresh of data in the chart\\n* **Sampling**: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\n### Gotchas\\n\\n* Not seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the **eye** icon.\\n\\n### How to show a \"step slider\" in a custom chart?\\n\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a `historyTable` instead of the `summaryTable`, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\n\\n<!-- ![Show step slider in a custom chart](/images/app_ui/step_sllider_custon_charts.mov>) -->\\n\\n### How to delete a custom chart preset?\\n\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\n![](/images/app_ui/delete_custome_chart_preset.gif)\\n\\n\\n### Common use cases\\n\\n* Customize bar plots with error bars\\n* Show model validation metrics which require custom x-y coordinates (like precision-recall curves)\\n* Overlay data distributions from two different models/experiments as histograms\\n* Show changes in a metric via snapshots at multiple points during training\\n* Create a unique visualization not yet available in W&B (and hopefully share it with the world)\\n',\n",
       "  'metadata': {'source': 'guides/app/features/custom-charts/intro.md',\n",
       "   'words': 1904,\n",
       "   'tokens': 4283}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for doc in raw_data[:]:\n",
    "    doc['metadata']['words'] = doc['metadata'].pop('raw_tokens')\n",
    "    doc['metadata']['tokens'] = len(tokenize_text(doc['content']).tokens)\n",
    "raw_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "There is a lot of extra formatting information (markdown elements) that is not very useful to an LLM.\n",
    "\n",
    "We can remove this information by converting the contents to text. We can also remove any special characters and extra whitespace. \n",
    "\n",
    "Special characters here are ones that are defined in the tokenizer and will vary depending on the model used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import frontmatter\n",
    "\n",
    "def convert_contents_to_text(contents: str) -> str:\n",
    "    _, content = frontmatter.parse(contents)\n",
    "    # use some extensions to convert the markdown to html\n",
    "    markdown_document = markdown.markdown(\n",
    "        content,\n",
    "        extensions=[\n",
    "            \"toc\",\n",
    "            \"pymdownx.extra\",\n",
    "            \"pymdownx.blocks.admonition\",\n",
    "            \"pymdownx.magiclink\",\n",
    "            \"pymdownx.blocks.tab\",\n",
    "            \"pymdownx.pathconverter\",\n",
    "            \"pymdownx.saneheaders\",\n",
    "            \"pymdownx.striphtml\",\n",
    "            \"pymdownx.highlight\",\n",
    "            \"pymdownx.pathconverter\",\n",
    "            \"pymdownx.escapeall\"\n",
    "        ],\n",
    "    )\n",
    "    soup = BeautifulSoup(markdown_document, \"html.parser\")\n",
    "    def remove_urls_a_tags_hrefs(soup):\n",
    "        # For hyperlinks, keep the text but remove the link\n",
    "        for a_tag in soup.find_all('a'):\n",
    "            a_tag.replace_with(a_tag.text)\n",
    "        \n",
    "        # Remove all images\n",
    "        for img_tag in soup.find_all('img'):\n",
    "            img_tag.decompose()\n",
    "        \n",
    "        # Remove all href attributes (this is now redundant for <a> tags, but keeps other elements clean)\n",
    "        # for tag in soup.find_all(href=True):\n",
    "        #     del tag['href']\n",
    "        \n",
    "        return soup\n",
    "\n",
    "    # Use the function as before\n",
    "    soup = remove_urls_a_tags_hrefs(soup)\n",
    "\n",
    "    def remove_javascript_import_statements(soup):\n",
    "        for p in soup.find_all('p'):\n",
    "            if p.text.strip().startswith('import') and ';' in p.text:\n",
    "                p.decompose()\n",
    "        return soup\n",
    "    soup = remove_javascript_import_statements(soup)\n",
    "\n",
    "    return soup.get_text()\n",
    "\n",
    "def get_special_tokens_set(tokenizer_url):\n",
    "    # https://docs.cohere.com/docs/tokens-and-tokenizers\n",
    "    response = requests.get(tokenizer_url)\n",
    "    return set([tok[\"content\"] for tok in response.json()[\"added_tokens\"]])\n",
    "\n",
    "special_tokens_set = get_special_tokens_set(tokenizers[\"command-r\"])\n",
    "def make_text_tokenization_safe(content: str, special_tokens_set: set=special_tokens_set) -> str:\n",
    "    \n",
    "    # Normalize newlines and replace multiple new lines with a single new line\n",
    "    # content = re.sub(r'\\n+', '\\n', content, flags=re.UNICODE)\n",
    "    \n",
    "\n",
    "    def remove_special_tokens(text: str) -> str:\n",
    "        \"\"\"Removes special tokens from the given text.\n",
    "\n",
    "        Args:\n",
    "            text: A string representing the text.\n",
    "\n",
    "        Returns:\n",
    "            The text with special tokens removed.\n",
    "        \"\"\"\n",
    "        for token in special_tokens_set:\n",
    "            text = text.replace(token, \"\")\n",
    "        return text\n",
    "\n",
    "    cleaned_content = remove_special_tokens(content)\n",
    "    return cleaned_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n',\n",
       "  'metadata': {'source': 'guides/app/features/anon.md',\n",
       "   'words': 470,\n",
       "   'tokens': 759,\n",
       "   'parsed_tokens': 611},\n",
       "  'parsed_content': 'Anonymous Mode\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\nAllow results to be logged in Anonymous Mode with wandb.init(anonymous=\"allow\")\\n:::info\\nPublishing a paper? Please cite W&B, and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\nHow does someone without an account see results?\\nIf someone runs your script and you have to set anonymous=\"allow\":\\n\\nAuto-create temporary account: W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\nLog results quickly: The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\nClaim data when it\\'s useful: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\nAnonymous run links are sensitive. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\nWhat happens to users with existing accounts?\\nIf you set anonymous=\"allow\" in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\nWhat are features that aren\\'t available to anonymous users?\\n\\nNo persistent data: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n\\nNo artifact logging: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n\\n\\nNo profile or settings pages: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\nExample usage\\nTry the example notebook to see how anonymous mode works.\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n'},\n",
       " {'content': '---\\nslug: /guides/app/features/custom-charts\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Custom Charts\\n\\nUse **Custom Charts** to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of [Vega](https://vega.github.io/vega/).\\n\\n* **What\\'s possible**: Read the[ launch announcement →](https://wandb.ai/wandb/posts/reports/Announcing-the-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n* **Code**: Try a live example in a[ hosted notebook →](https://tiny.cc/custom-charts)\\n* **Video**: Watch a quick [walkthrough video →](https://www.youtube.com/watch?v=3-N9OV6bkSM)\\n* **Example**: Quick Keras and Sklearn [demo notebook →](https://colab.research.google.com/drive/1g-gNGokPWM2Qbc8p1Gofud0\\\\_5AoZdoSD?usp=sharing)\\n\\n![Supported charts from vega.github.io/vega](/images/app_ui/supported_charts.png)\\n\\n### How it works\\n\\n1. **Log data**: From your script, log [config](../../../../guides/track/config.md) and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a custom`wandb.Table`\\n2. **Customize the chart**: Pull in any of this logged data with a [GraphQL](https://graphql.org) query. Visualize the results of your query with [Vega](https://vega.github.io/vega/), a powerful visualization grammar.\\n3. **Log the chart**: Call your own preset from your script with `wandb.plot_table()`.\\n\\n![](/images/app_ui/pr_roc.png)\\n\\n## Log charts from a script\\n\\n### Builtin presets\\n\\nThese presets have builtin `wandb.plot` methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n<Tabs\\n  defaultValue=\"line-plot\"\\n  values={[\\n    {label: \\'Line plot\\', value: \\'line-plot\\'},\\n    {label: \\'Scatter plot\\', value: \\'scatter-plot\\'},\\n    {label: \\'Bar chart\\', value: \\'bar-chart\\'},\\n    {label: \\'Histogram\\', value: \\'histogram\\'},\\n    {label: \\'PR curve\\', value: \\'pr-curve\\'},\\n    {label: \\'ROC curve\\', value: \\'roc-curve\\'},\\n  ]}>\\n  <TabItem value=\"line-plot\">\\n\\n`wandb.plot.line()`\\n\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/line_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Line-Plots--VmlldzoyNjk5NTA)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"scatter-plot\">\\n\\n`wandb.plot.scatter()`\\n\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n```\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/demo_scatter_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Scatter-Plots--VmlldzoyNjk5NDQ)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"bar-chart\">\\n\\n`wandb.plot.bar()`\\n\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\n\\n```python\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\n![](@site/static/images/app_ui/line_plot_bar_chart.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Bar-Charts--VmlldzoyNzExNzk)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"histogram\">\\n\\n`wandb.plot.histogram()`\\n\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (`scores`) and want to visualize their distribution:\\n\\n```python\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n```\\n\\nYou can use this to log arbitrary histograms. Note that `data` is a list of lists, intended to support a 2D array of rows and columns.\\n\\n![](/images/app_ui/demo_custom_chart_histogram.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Histograms--VmlldzoyNzE0NzM)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n    <TabItem value=\"pr-curve\">\\n\\n`wandb.plot.pr_curve()`\\n\\nCreate a [Precision-Recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision\\\\_recall\\\\_curve.html#sklearn.metrics.precision\\\\_recall\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n![](/images/app_ui/demo_average_precision_lines.png)\\n\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-Precision-Recall-Curves--VmlldzoyNjk1ODY)\\n\\n[Run the code →](https://colab.research.google.com/drive/1mS8ogA3LcZWOXchfJoMrboW3opY1A8BY?usp=sharing)\\n\\n  </TabItem>\\n  <TabItem value=\"roc-curve\">\\n\\n`wandb.plot.roc_curve()`\\n\\nCreate an [ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc\\\\_curve.html#sklearn.metrics.roc\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/ class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n![](/images/app_ui/demo_custom_chart_roc_curve.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-ROC-Curves--VmlldzoyNjk3MDE)\\n\\n[Run the code →](https://colab.research.google.com/drive/1\\\\_RMppCqsA8XInV\\\\_jhJz32NCZG6Z5t1RO?usp=sharing)\\n\\n  </TabItem>\\n</Tabs>\\n\\n### Custom presets\\n\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n\\n```python\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n```\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n![](/images/app_ui/custom_presets.png)\\n\\n## Log data\\n\\nHere are the data types you can log from your script and use in a custom chart:\\n\\n* **Config**: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to `wandb.config` at the start of your training (e.g. `wandb.config.learning_rate = 0.0001)`\\n* **Summary**: Single values logged during training (your results or dependent variables), e.g. `wandb.log({\"val_acc\" : 0.8})`. If you write to this key multiple times during training via `wandb.log()`, the summary is set to the final value of that key.\\n* **History**: The full time series of the logged scalar is available to the query via the `history` field\\n* **summaryTable**: If you need to log a list of multiple values, use a `wandb.Table()` to save that data, then query it in your custom panel.\\n* **historyTable**: If you need to see the history data, then query `historyTable` in your custom chart panel. Each time you call `wandb.Table()` or log a custom chart, you\\'re creating a new table in history for that step.\\n\\n### How to log a custom table\\n\\nUse `wandb.Table()` to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to `wandb.log()`(\"custom\\\\_data\\\\_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\n\\n[Try it in a Google Colab →](https://tiny.cc/custom-charts)\\n\\n```python\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n```\\n\\n## Customize the chart\\n\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses [GraphQL](https://graphql.org) to fetch data from the config, summary, and history fields in your runs.\\n\\n![Add a new custom chart, then edit the query](/images/app_ui/customize_chart.gif)\\n\\n### Custom visualizations\\n\\nSelect a **Chart** in the upper right corner to start with a default preset. Next, pick **Chart fields** to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\n![Creating a custom bar chart showing accuracy across runs in a project](/images/app_ui/demo_make_a_custom_chart_bar_chart.gif)\\n\\n### How to edit Vega\\n\\nClick **Edit** at the top of the panel to go into [Vega](https://vega.github.io/vega/) edit mode. Here you can define a [Vega specification](https://vega.github.io/vega/docs/specification/) that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The [Vega documentation and tutorials ](https://vega.github.io/vega/)are an excellent source of inspiration.\\n\\n**Field references**\\n\\nTo pull data into your chart from W&B, add template strings of the form `\"${field:<field-name>}\"` anywhere in your Vega spec. This will create a dropdown in the **Chart Fields** area on the right side, which users can use to select a query result column to map into Vega.\\n\\nTo set a default value for a field, use this syntax: `\"${field:<field-name>:<placeholder text>}\"`\\n\\n### Saving chart presets\\n\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click **Save as** at the top of the Vega editor and give your preset a name.\\n\\n## Articles and guides\\n\\n1. [The W&B Machine Learning Visualization IDE](https://wandb.ai/wandb/posts/reports/The-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n2. [Visualizing NLP Attention Based Models](https://wandb.ai/kylegoyette/gradientsandtranslation2/reports/Visualizing-NLP-Attention-Based-Models-Using-Custom-Charts--VmlldzoyNjg2MjM)\\n3. [Visualizing The Effect of Attention on Gradient Flow](https://wandb.ai/kylegoyette/gradientsandtranslation/reports/Visualizing-The-Effect-of-Attention-on-Gradient-Flow-Using-Custom-Charts--VmlldzoyNjg1NDg)\\n4. [Logging arbitrary curves](https://wandb.ai/stacey/presets/reports/Logging-Arbitrary-Curves--VmlldzoyNzQyMzA)\\n\\n## Frequently asked questions\\n\\n### Coming soon\\n\\n* **Polling**: Auto-refresh of data in the chart\\n* **Sampling**: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\n### Gotchas\\n\\n* Not seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the **eye** icon.\\n\\n### How to show a \"step slider\" in a custom chart?\\n\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a `historyTable` instead of the `summaryTable`, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\n\\n<!-- ![Show step slider in a custom chart](/images/app_ui/step_sllider_custon_charts.mov>) -->\\n\\n### How to delete a custom chart preset?\\n\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\n![](/images/app_ui/delete_custome_chart_preset.gif)\\n\\n\\n### Common use cases\\n\\n* Customize bar plots with error bars\\n* Show model validation metrics which require custom x-y coordinates (like precision-recall curves)\\n* Overlay data distributions from two different models/experiments as histograms\\n* Show changes in a metric via snapshots at multiple points during training\\n* Create a unique visualization not yet available in W&B (and hopefully share it with the world)\\n',\n",
       "  'metadata': {'source': 'guides/app/features/custom-charts/intro.md',\n",
       "   'words': 1904,\n",
       "   'tokens': 4283,\n",
       "   'parsed_tokens': 2721},\n",
       "  'parsed_content': '\\nCustom Charts\\nUse Custom Charts to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of Vega.\\n\\nWhat\\'s possible: Read the launch announcement →\\nCode: Try a live example in a hosted notebook →\\nVideo: Watch a quick walkthrough video →\\nExample: Quick Keras and Sklearn demo notebook →\\n\\n\\nHow it works\\n\\nLog data: From your script, log config and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a customwandb.Table\\nCustomize the chart: Pull in any of this logged data with a GraphQL query. Visualize the results of your query with Vega, a powerful visualization grammar.\\nLog the chart: Call your own preset from your script with wandb.plot_table().\\n\\n\\nLog charts from a script\\nBuiltin presets\\nThese presets have builtin wandb.plot methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n\\nwandb.plot.line()\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.scatter()\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.bar()\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.histogram()\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (scores) and want to visualize their distribution:\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n\\nYou can use this to log arbitrary histograms. Note that data is a list of lists, intended to support a 2D array of rows and columns.\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.pr_curve()\\nCreate a Precision-Recall curve in one line:\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n\\nYou can log this whenever your code has access to:\\n\\na model\\'s predicted scores (predictions) on a set of examples\\nthe corresponding ground truth labels (ground_truth) for those examples\\n(optionally) a list of the labels/class names (labels=[\"cat\", \"dog\", \"bird\"...] if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n(optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.roc_curve()\\nCreate an ROC curve in one line:\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n\\nYou can log this whenever your code has access to:\\n\\na model\\'s predicted scores (predictions) on a set of examples\\nthe corresponding ground truth labels (ground_truth) for those examples\\n(optionally) a list of the labels/ class names (labels=[\"cat\", \"dog\", \"bird\"...] if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n(optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n\\nSee in the app →\\nRun the code →\\n\\n\\nCustom presets\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n\\nRun the code →\\n\\nLog data\\nHere are the data types you can log from your script and use in a custom chart:\\n\\nConfig: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to wandb.config at the start of your training (e.g. wandb.config.learning_rate = 0.0001)\\nSummary: Single values logged during training (your results or dependent variables), e.g. wandb.log({\"val_acc\" : 0.8}). If you write to this key multiple times during training via wandb.log(), the summary is set to the final value of that key.\\nHistory: The full time series of the logged scalar is available to the query via the history field\\nsummaryTable: If you need to log a list of multiple values, use a wandb.Table() to save that data, then query it in your custom panel.\\nhistoryTable: If you need to see the history data, then query historyTable in your custom chart panel. Each time you call wandb.Table() or log a custom chart, you\\'re creating a new table in history for that step.\\n\\nHow to log a custom table\\nUse wandb.Table() to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to wandb.log()(\"custom_data_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\nTry it in a Google Colab →\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n\\nCustomize the chart\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses GraphQL to fetch data from the config, summary, and history fields in your runs.\\n\\nCustom visualizations\\nSelect a Chart in the upper right corner to start with a default preset. Next, pick Chart fields to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\nHow to edit Vega\\nClick Edit at the top of the panel to go into Vega edit mode. Here you can define a Vega specification that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The Vega documentation and tutorials are an excellent source of inspiration.\\nField references\\nTo pull data into your chart from W&B, add template strings of the form \"${field:<field-name>}\" anywhere in your Vega spec. This will create a dropdown in the Chart Fields area on the right side, which users can use to select a query result column to map into Vega.\\nTo set a default value for a field, use this syntax: \"${field:<field-name>:<placeholder text>}\"\\nSaving chart presets\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click Save as at the top of the Vega editor and give your preset a name.\\nArticles and guides\\n\\nThe W&B Machine Learning Visualization IDE\\nVisualizing NLP Attention Based Models\\nVisualizing The Effect of Attention on Gradient Flow\\nLogging arbitrary curves\\n\\nFrequently asked questions\\nComing soon\\n\\nPolling: Auto-refresh of data in the chart\\nSampling: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\nGotchas\\n\\nNot seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the eye icon.\\n\\nHow to show a \"step slider\" in a custom chart?\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a historyTable instead of the summaryTable, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\nHow to delete a custom chart preset?\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\nCommon use cases\\n\\nCustomize bar plots with error bars\\nShow model validation metrics which require custom x-y coordinates (like precision-recall curves)\\nOverlay data distributions from two different models/experiments as histograms\\nShow changes in a metric via snapshots at multiple points during training\\nCreate a unique visualization not yet available in W&B (and hopefully share it with the world)\\n'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data = []\n",
    "\n",
    "for doc in raw_data:\n",
    "    parsed_doc = doc.copy()\n",
    "    content = convert_contents_to_text(doc[\"content\"])\n",
    "    parsed_doc[\"parsed_content\"] = make_text_tokenization_safe(content)\n",
    "    parsed_doc[\"metadata\"][\"parsed_tokens\"] = len(tokenize_text(parsed_doc[\"parsed_content\"]).tokens)\n",
    "    parsed_data.append(parsed_doc)\n",
    "parsed_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact preprocessed_data>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = sum(map(lambda x: x[\"metadata\"][\"words\"], parsed_data))\n",
    "total_raw_tokens = sum(map(lambda x: x[\"metadata\"][\"tokens\"], raw_data))\n",
    "total_parsed_tokens = sum(map(lambda x: x[\"metadata\"][\"parsed_tokens\"], parsed_data))\n",
    "\n",
    "preprocessed_artifact = wandb.Artifact(name=\"preprocessed_data\", type=\"dataset\",\n",
    "description=\"Preprocessed wandb documentation\", metadata={\n",
    "    \"total_files\": len(parsed_data),\n",
    "    \"date_preprocessed\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"total_words\": total_words,\n",
    "    \"total_raw_tokens\": total_raw_tokens,\n",
    "    \"total_parsed_tokens\": total_parsed_tokens,\n",
    "    }\n",
    ")\n",
    "with preprocessed_artifact.new_file(\"documents.jsonl\", mode=\"w\") as f:\n",
    "    for item in parsed_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "run.log_artifact(preprocessed_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Chunking\n",
    "\n",
    "1. First we split the text into sentences using [BlingFire](https://github.com/microsoft/BlingFire) library.\n",
    "2. Then we split the sentences into chunks of a maximum number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blingfire import text_to_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/04 17:14:40 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/rag-course/dev/bn5dpiph/artifact/943357119/wandb_manifest.json?Expires=1720097080&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=fkAYjmFYdY%2BVBvA9r0eI6i%2B7kgpMpdYwzrTLUVvgDXFPyVm9jQxEl3xNp%2FkxpSK1dIe%2FXVU6CvS%2FsJzMUdEMGXK90Y6wF5RaBNE2P9wuuiP%2B%2FgKmin6PGYERMY6TZTARpFv%2Bwe8Rc35oU2nuLwlmzQQoLZ7I%2FzMwNE6lMRS3kkHQoN%2BdR09GpLM4AkhFDpMhgkc2TKngAqs75wq1JNsXE88J5LDPx%2F2FMtuUjIdvyWuB%2Blmp6yZMLOWIqbVvFHQMk1XBMgDUEHu%2Fpl5HZ6pxuaMlMMxhHrytIo5vUnMzKJm8JbY%2F5ffTJvueADXgmdGs%2FxQ2y%2BTmGZ8lt9Yc6iF8OQ%3D%3D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': '---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n',\n",
       "  'metadata': {'source': 'guides/app/features/anon.md',\n",
       "   'words': 470,\n",
       "   'tokens': 759,\n",
       "   'parsed_tokens': 611},\n",
       "  'parsed_content': 'Anonymous Mode\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\nAllow results to be logged in Anonymous Mode with wandb.init(anonymous=\"allow\")\\n:::info\\nPublishing a paper? Please cite W&B, and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\nHow does someone without an account see results?\\nIf someone runs your script and you have to set anonymous=\"allow\":\\n\\nAuto-create temporary account: W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\nLog results quickly: The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\nClaim data when it\\'s useful: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\nAnonymous run links are sensitive. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\nWhat happens to users with existing accounts?\\nIf you set anonymous=\"allow\" in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\nWhat are features that aren\\'t available to anonymous users?\\n\\nNo persistent data: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n\\nNo artifact logging: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n\\n\\nNo profile or settings pages: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\nExample usage\\nTry the example notebook to see how anonymous mode works.\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n'},\n",
       " {'content': '---\\nslug: /guides/app/features/custom-charts\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Custom Charts\\n\\nUse **Custom Charts** to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of [Vega](https://vega.github.io/vega/).\\n\\n* **What\\'s possible**: Read the[ launch announcement →](https://wandb.ai/wandb/posts/reports/Announcing-the-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n* **Code**: Try a live example in a[ hosted notebook →](https://tiny.cc/custom-charts)\\n* **Video**: Watch a quick [walkthrough video →](https://www.youtube.com/watch?v=3-N9OV6bkSM)\\n* **Example**: Quick Keras and Sklearn [demo notebook →](https://colab.research.google.com/drive/1g-gNGokPWM2Qbc8p1Gofud0\\\\_5AoZdoSD?usp=sharing)\\n\\n![Supported charts from vega.github.io/vega](/images/app_ui/supported_charts.png)\\n\\n### How it works\\n\\n1. **Log data**: From your script, log [config](../../../../guides/track/config.md) and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a custom`wandb.Table`\\n2. **Customize the chart**: Pull in any of this logged data with a [GraphQL](https://graphql.org) query. Visualize the results of your query with [Vega](https://vega.github.io/vega/), a powerful visualization grammar.\\n3. **Log the chart**: Call your own preset from your script with `wandb.plot_table()`.\\n\\n![](/images/app_ui/pr_roc.png)\\n\\n## Log charts from a script\\n\\n### Builtin presets\\n\\nThese presets have builtin `wandb.plot` methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n<Tabs\\n  defaultValue=\"line-plot\"\\n  values={[\\n    {label: \\'Line plot\\', value: \\'line-plot\\'},\\n    {label: \\'Scatter plot\\', value: \\'scatter-plot\\'},\\n    {label: \\'Bar chart\\', value: \\'bar-chart\\'},\\n    {label: \\'Histogram\\', value: \\'histogram\\'},\\n    {label: \\'PR curve\\', value: \\'pr-curve\\'},\\n    {label: \\'ROC curve\\', value: \\'roc-curve\\'},\\n  ]}>\\n  <TabItem value=\"line-plot\">\\n\\n`wandb.plot.line()`\\n\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/line_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Line-Plots--VmlldzoyNjk5NTA)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"scatter-plot\">\\n\\n`wandb.plot.scatter()`\\n\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n```\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/demo_scatter_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Scatter-Plots--VmlldzoyNjk5NDQ)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"bar-chart\">\\n\\n`wandb.plot.bar()`\\n\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\n\\n```python\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\n![](@site/static/images/app_ui/line_plot_bar_chart.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Bar-Charts--VmlldzoyNzExNzk)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"histogram\">\\n\\n`wandb.plot.histogram()`\\n\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (`scores`) and want to visualize their distribution:\\n\\n```python\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n```\\n\\nYou can use this to log arbitrary histograms. Note that `data` is a list of lists, intended to support a 2D array of rows and columns.\\n\\n![](/images/app_ui/demo_custom_chart_histogram.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Histograms--VmlldzoyNzE0NzM)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n    <TabItem value=\"pr-curve\">\\n\\n`wandb.plot.pr_curve()`\\n\\nCreate a [Precision-Recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision\\\\_recall\\\\_curve.html#sklearn.metrics.precision\\\\_recall\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n![](/images/app_ui/demo_average_precision_lines.png)\\n\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-Precision-Recall-Curves--VmlldzoyNjk1ODY)\\n\\n[Run the code →](https://colab.research.google.com/drive/1mS8ogA3LcZWOXchfJoMrboW3opY1A8BY?usp=sharing)\\n\\n  </TabItem>\\n  <TabItem value=\"roc-curve\">\\n\\n`wandb.plot.roc_curve()`\\n\\nCreate an [ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc\\\\_curve.html#sklearn.metrics.roc\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/ class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n![](/images/app_ui/demo_custom_chart_roc_curve.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-ROC-Curves--VmlldzoyNjk3MDE)\\n\\n[Run the code →](https://colab.research.google.com/drive/1\\\\_RMppCqsA8XInV\\\\_jhJz32NCZG6Z5t1RO?usp=sharing)\\n\\n  </TabItem>\\n</Tabs>\\n\\n### Custom presets\\n\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n\\n```python\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n```\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n![](/images/app_ui/custom_presets.png)\\n\\n## Log data\\n\\nHere are the data types you can log from your script and use in a custom chart:\\n\\n* **Config**: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to `wandb.config` at the start of your training (e.g. `wandb.config.learning_rate = 0.0001)`\\n* **Summary**: Single values logged during training (your results or dependent variables), e.g. `wandb.log({\"val_acc\" : 0.8})`. If you write to this key multiple times during training via `wandb.log()`, the summary is set to the final value of that key.\\n* **History**: The full time series of the logged scalar is available to the query via the `history` field\\n* **summaryTable**: If you need to log a list of multiple values, use a `wandb.Table()` to save that data, then query it in your custom panel.\\n* **historyTable**: If you need to see the history data, then query `historyTable` in your custom chart panel. Each time you call `wandb.Table()` or log a custom chart, you\\'re creating a new table in history for that step.\\n\\n### How to log a custom table\\n\\nUse `wandb.Table()` to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to `wandb.log()`(\"custom\\\\_data\\\\_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\n\\n[Try it in a Google Colab →](https://tiny.cc/custom-charts)\\n\\n```python\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n```\\n\\n## Customize the chart\\n\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses [GraphQL](https://graphql.org) to fetch data from the config, summary, and history fields in your runs.\\n\\n![Add a new custom chart, then edit the query](/images/app_ui/customize_chart.gif)\\n\\n### Custom visualizations\\n\\nSelect a **Chart** in the upper right corner to start with a default preset. Next, pick **Chart fields** to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\n![Creating a custom bar chart showing accuracy across runs in a project](/images/app_ui/demo_make_a_custom_chart_bar_chart.gif)\\n\\n### How to edit Vega\\n\\nClick **Edit** at the top of the panel to go into [Vega](https://vega.github.io/vega/) edit mode. Here you can define a [Vega specification](https://vega.github.io/vega/docs/specification/) that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The [Vega documentation and tutorials ](https://vega.github.io/vega/)are an excellent source of inspiration.\\n\\n**Field references**\\n\\nTo pull data into your chart from W&B, add template strings of the form `\"${field:<field-name>}\"` anywhere in your Vega spec. This will create a dropdown in the **Chart Fields** area on the right side, which users can use to select a query result column to map into Vega.\\n\\nTo set a default value for a field, use this syntax: `\"${field:<field-name>:<placeholder text>}\"`\\n\\n### Saving chart presets\\n\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click **Save as** at the top of the Vega editor and give your preset a name.\\n\\n## Articles and guides\\n\\n1. [The W&B Machine Learning Visualization IDE](https://wandb.ai/wandb/posts/reports/The-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n2. [Visualizing NLP Attention Based Models](https://wandb.ai/kylegoyette/gradientsandtranslation2/reports/Visualizing-NLP-Attention-Based-Models-Using-Custom-Charts--VmlldzoyNjg2MjM)\\n3. [Visualizing The Effect of Attention on Gradient Flow](https://wandb.ai/kylegoyette/gradientsandtranslation/reports/Visualizing-The-Effect-of-Attention-on-Gradient-Flow-Using-Custom-Charts--VmlldzoyNjg1NDg)\\n4. [Logging arbitrary curves](https://wandb.ai/stacey/presets/reports/Logging-Arbitrary-Curves--VmlldzoyNzQyMzA)\\n\\n## Frequently asked questions\\n\\n### Coming soon\\n\\n* **Polling**: Auto-refresh of data in the chart\\n* **Sampling**: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\n### Gotchas\\n\\n* Not seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the **eye** icon.\\n\\n### How to show a \"step slider\" in a custom chart?\\n\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a `historyTable` instead of the `summaryTable`, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\n\\n<!-- ![Show step slider in a custom chart](/images/app_ui/step_sllider_custon_charts.mov>) -->\\n\\n### How to delete a custom chart preset?\\n\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\n![](/images/app_ui/delete_custome_chart_preset.gif)\\n\\n\\n### Common use cases\\n\\n* Customize bar plots with error bars\\n* Show model validation metrics which require custom x-y coordinates (like precision-recall curves)\\n* Overlay data distributions from two different models/experiments as histograms\\n* Show changes in a metric via snapshots at multiple points during training\\n* Create a unique visualization not yet available in W&B (and hopefully share it with the world)\\n',\n",
       "  'metadata': {'source': 'guides/app/features/custom-charts/intro.md',\n",
       "   'words': 1904,\n",
       "   'tokens': 4283,\n",
       "   'parsed_tokens': 2721},\n",
       "  'parsed_content': '\\nCustom Charts\\nUse Custom Charts to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of Vega.\\n\\nWhat\\'s possible: Read the launch announcement →\\nCode: Try a live example in a hosted notebook →\\nVideo: Watch a quick walkthrough video →\\nExample: Quick Keras and Sklearn demo notebook →\\n\\n\\nHow it works\\n\\nLog data: From your script, log config and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a customwandb.Table\\nCustomize the chart: Pull in any of this logged data with a GraphQL query. Visualize the results of your query with Vega, a powerful visualization grammar.\\nLog the chart: Call your own preset from your script with wandb.plot_table().\\n\\n\\nLog charts from a script\\nBuiltin presets\\nThese presets have builtin wandb.plot methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n\\nwandb.plot.line()\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.scatter()\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.bar()\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.histogram()\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (scores) and want to visualize their distribution:\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n\\nYou can use this to log arbitrary histograms. Note that data is a list of lists, intended to support a 2D array of rows and columns.\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.pr_curve()\\nCreate a Precision-Recall curve in one line:\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n\\nYou can log this whenever your code has access to:\\n\\na model\\'s predicted scores (predictions) on a set of examples\\nthe corresponding ground truth labels (ground_truth) for those examples\\n(optionally) a list of the labels/class names (labels=[\"cat\", \"dog\", \"bird\"...] if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n(optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n\\nSee in the app →\\nRun the code →\\n\\n\\nwandb.plot.roc_curve()\\nCreate an ROC curve in one line:\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n\\nYou can log this whenever your code has access to:\\n\\na model\\'s predicted scores (predictions) on a set of examples\\nthe corresponding ground truth labels (ground_truth) for those examples\\n(optionally) a list of the labels/ class names (labels=[\"cat\", \"dog\", \"bird\"...] if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n(optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n\\nSee in the app →\\nRun the code →\\n\\n\\nCustom presets\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n\\nRun the code →\\n\\nLog data\\nHere are the data types you can log from your script and use in a custom chart:\\n\\nConfig: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to wandb.config at the start of your training (e.g. wandb.config.learning_rate = 0.0001)\\nSummary: Single values logged during training (your results or dependent variables), e.g. wandb.log({\"val_acc\" : 0.8}). If you write to this key multiple times during training via wandb.log(), the summary is set to the final value of that key.\\nHistory: The full time series of the logged scalar is available to the query via the history field\\nsummaryTable: If you need to log a list of multiple values, use a wandb.Table() to save that data, then query it in your custom panel.\\nhistoryTable: If you need to see the history data, then query historyTable in your custom chart panel. Each time you call wandb.Table() or log a custom chart, you\\'re creating a new table in history for that step.\\n\\nHow to log a custom table\\nUse wandb.Table() to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to wandb.log()(\"custom_data_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\nTry it in a Google Colab →\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n\\nCustomize the chart\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses GraphQL to fetch data from the config, summary, and history fields in your runs.\\n\\nCustom visualizations\\nSelect a Chart in the upper right corner to start with a default preset. Next, pick Chart fields to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\nHow to edit Vega\\nClick Edit at the top of the panel to go into Vega edit mode. Here you can define a Vega specification that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The Vega documentation and tutorials are an excellent source of inspiration.\\nField references\\nTo pull data into your chart from W&B, add template strings of the form \"${field:<field-name>}\" anywhere in your Vega spec. This will create a dropdown in the Chart Fields area on the right side, which users can use to select a query result column to map into Vega.\\nTo set a default value for a field, use this syntax: \"${field:<field-name>:<placeholder text>}\"\\nSaving chart presets\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click Save as at the top of the Vega editor and give your preset a name.\\nArticles and guides\\n\\nThe W&B Machine Learning Visualization IDE\\nVisualizing NLP Attention Based Models\\nVisualizing The Effect of Attention on Gradient Flow\\nLogging arbitrary curves\\n\\nFrequently asked questions\\nComing soon\\n\\nPolling: Auto-refresh of data in the chart\\nSampling: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\nGotchas\\n\\nNot seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the eye icon.\\n\\nHow to show a \"step slider\" in a custom chart?\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a historyTable instead of the summaryTable, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\nHow to delete a custom chart preset?\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\nCommon use cases\\n\\nCustomize bar plots with error bars\\nShow model validation metrics which require custom x-y coordinates (like precision-recall curves)\\nOverlay data distributions from two different models/experiments as histograms\\nShow changes in a metric via snapshots at multiple points during training\\nCreate a unique visualization not yet available in W&B (and hopefully share it with the world)\\n'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_artifact = run.use_artifact(f'{WANDB_ENTITY}/{WANDB_PROJECT}/preprocessed_data:latest', type='dataset')\n",
    "artifact_dir = preprocessed_artifact.download()\n",
    "preprocessed_data_file = pathlib.Path(f\"{artifact_dir}/documents.jsonl\")\n",
    "preprocessed_data = list(map(json.loads, preprocessed_data_file.read_text().splitlines()))\n",
    "preprocessed_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://platform.openai.com/docs/tutorials/web-qa-embeddings\n",
    "\n",
    "CHUNK_SIZE=500\n",
    "\n",
    "# Function to split the text into chunks of a maximum number of tokens\n",
    "\n",
    "\n",
    "def split_into_chunks(text, max_tokens = CHUNK_SIZE):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text_to_sentences(text).split(\"\\n\")\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenize_text(\"\\n\" + sentence).tokens) for sentence in sentences]\n",
    "\n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater\n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\"\\n\".join(chunk))\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of\n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parsed_content': 'Anonymous Mode Are you publishing code that you want anyone to be able to run easily?\\nUse Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\nAllow results to be logged in Anonymous Mode with wandb.init(anonymous=\"allow\") :::info Publishing a paper?\\nPlease cite W&B, and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n::: How does someone without an account see results?\\nIf someone runs your script and you have to set anonymous=\"allow\":  Auto-create temporary account: W&B checks for an account that\\'s already signed in.\\nIf there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\nLog results quickly: The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI.\\nThese unclaimed anonymous runs will be available for 7 days.\\nClaim data when it\\'s useful: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account.\\nIf they don\\'t claim a run, it will be deleted after 7 days.  :::caution Anonymous run links are sensitive.\\nThese links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust.\\nIf you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n::: What happens to users with existing accounts?\\nIf you set anonymous=\"allow\" in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account.\\nThis means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\nWhat are features that aren\\'t available to anonymous users?\\nNo persistent data: Runs are only saved for 7 days in an anonymous account.\\nUsers can claim anonymous run data by saving it to a real account.',\n",
       "  'metadata': {'source': 'guides/app/features/anon.md', 'parsed_tokens': 481}},\n",
       " {'parsed_content': 'Custom Charts Use Custom Charts to create charts that aren\\'t possible right now in the default UI.\\nLog arbitrary tables of data and visualize them exactly how you want.\\nControl details of fonts, colors, and tooltips with the power of Vega.\\nWhat\\'s possible: Read the launch announcement → Code: Try a live example in a hosted notebook → Video: Watch a quick walkthrough video → Example: Quick Keras and Sklearn demo notebook →   How it works  Log data: From your script, log config and summary data as you normally would when running with W&B.\\nTo visualize a list of multiple values logged at one specific time, use a customwandb.Table Customize the chart: Pull in any of this logged data with a GraphQL query.\\nVisualize the results of your query with Vega, a powerful visualization grammar.\\nLog the chart: Call your own preset from your script with wandb.plot_table().\\nLog charts from a script Builtin presets These presets have builtin wandb.plot methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.   wandb.plot.line() Log a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y. data = [[x, y] for (x, y) in zip(x_values, y_values)] table = wandb.Table(data=data, columns=[\"x\", \"y\"]) wandb.log(     {         \"my_custom_plot_id\": wandb.plot.line(             table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"         )     } )  You can use this to log curves on any two dimensions.\\nNote that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).',\n",
       "  'metadata': {'source': 'guides/app/features/custom-charts/intro.md',\n",
       "   'parsed_tokens': 406}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_data = []\n",
    "for doc in preprocessed_data:\n",
    "    chunks = split_into_chunks(doc[\"parsed_content\"])\n",
    "    for chunk in chunks:\n",
    "        chunked_data.append(\n",
    "            {\n",
    "                \"parsed_content\" : chunk,\n",
    "                \"metadata\": {\n",
    "                    \"source\": doc[\"metadata\"][\"source\"],\n",
    "                    \"parsed_tokens\": len(tokenize_text(chunk).tokens)\n",
    "            }})\n",
    "        \n",
    "chunked_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact chunked_data>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, we'll store the cleaned data in an artifact for future use and reproducibility\n",
    "\n",
    "total_cleaned_tokens = sum(map(lambda x: x[\"metadata\"][\"parsed_tokens\"], chunked_data))\n",
    "\n",
    "chunked_artifact = wandb.Artifact(\n",
    "    name=\"chunked_data\",\n",
    "    type=\"dataset\",\n",
    "    description=\"Chunked wandb documentation\",\n",
    "    metadata={\n",
    "        \"total_files\": len(chunked_data),\n",
    "        \"date_processed\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"total_raw_tokens\": total_raw_tokens,\n",
    "        \"total_cleaned_tokens\": total_cleaned_tokens,\n",
    "        \"chunk_size\": CHUNK_SIZE,\n",
    "    },\n",
    ")\n",
    "with chunked_artifact.new_file(\"documents.jsonl\", mode=\"w\") as f:\n",
    "    for item in chunked_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "run.log_artifact(chunked_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.index = None\n",
    "        self.data = None\n",
    "\n",
    "    def index_data(self, data):\n",
    "        self.data = data\n",
    "        docs = [doc[\"parsed_content\"] for doc in data]\n",
    "        self.index = self.vectorizer.fit_transform(docs)\n",
    "\n",
    "    def search(self, query, k=5):\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        cosine_distances = cdist(\n",
    "            query_vec.todense(), self.index.todense(), metric=\"cosine\"\n",
    "        )[0]\n",
    "        top_k_indices = cosine_distances.argsort()[:k]\n",
    "        output = []\n",
    "        for idx in top_k_indices:\n",
    "            output.append(\n",
    "                {\n",
    "                    \"source\": self.data[idx][\"metadata\"][\"source\"],\n",
    "                    \"text\": self.data[idx][\"parsed_content\"],\n",
    "                    \"score\": 1 - cosine_distances[idx],\n",
    "                }\n",
    "            )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'guides/technical-faq/troubleshooting.md', 'text': 'Troubleshooting If wandb crashes, will it possibly crash my training run?\\nIt is extremely important to us that we never interfere with your training runs.\\nWe run wandb in a separate process to make sure that if wandb somehow crashes, your training will continue to run.\\nIf the internet goes out, wandb will continue to retry sending data to wandb.ai.\\nWhy is a run marked crashed in W&B when it’s training fine locally?\\nThis is likely a connection problem — if your server loses internet access and data stops syncing to W&B, we mark the run as crashed after a short period of retrying.\\nDoes logging block my training?\\n\"Is the logging function lazy?\\nI don\\'t want to be dependent on the network to send the results to your servers and then carry on with my local operations.\"\\nCalling wandb.log writes a line to a local file; it does not block any network calls.\\nWhen you call wandb.init we launch a new process on the same machine that listens for filesystem changes and talks to our web service asynchronously from your training process.\\nHow do I stop wandb from writing to my terminal or my jupyter notebook output?\\nSet the environment variable WANDB_SILENT to true.   os.environ[\"WANDB_SILENT\"] = \"true\"    %env WANDB_SILENT=true    WANDB_SILENT=true    How do I kill a job with wandb?\\nPress Ctrl+D on your keyboard to stop a script that is instrumented with wandb.\\nHow do I deal with network issues?\\nIf you\\'re seeing SSL or network errors:wandb: Network error (ConnectionError), entering retry loop.\\nYou can try a couple of different approaches to solving this issue:  Upgrade your SSL certificate.\\nIf you\\'re running the script on an Ubuntu server, run update-ca-certificates We can\\'t sync training logs without a valid SSL certificate because it\\'s a security vulnerability.\\nIf your network is flaky, run training in offline mode and sync the files to us from a machine that has Internet access.\\nTry running W&B Private Hosting, which operates on your machine and doesn\\'t sync files to our cloud servers.', 'score': 0.26664851047408544}\n",
      "{'source': 'guides/technical-faq/general.md', 'text': 'General What does wandb.init do to my training process?\\nWhen wandb.init() is called from your training script an API call is made to create a run object on our servers.\\nA new process is started to stream and collect metrics, thereby keeping all threads and logic out of your primary process.\\nYour script runs normally and writes to local files, while the separate process streams them to our servers along with system metrics.\\nYou can always turn off streaming by running wandb off from your training directory, or setting the WANDB_MODE environment variable to offline.\\nDoes your tool track or store training data?\\nYou can pass a SHA or other unique identifier to wandb.config.update(...) to associate a dataset with a training run.\\nW&B does not store any data unless wandb.save is called with the local file name.\\nWhat formula do you use for your smoothing algorithm?\\nWe use the same exponential moving average formula as TensorBoard.\\nYou can find an explanation here.\\nHow do I get the random run name in my script?\\nCall wandb.run.save() and then get the name with wandb.run.name .\\nWhat is the difference between .log() and .summary?\\nThe summary is the value that shows in the table while the log will save all the values for plotting later.\\nFor example, you might want to call wandb.log every time the accuracy changes.\\nUsually, you can just use .log. wandb.log() will also update the summary value by default unless you have set the summary manually for that metric The scatterplot and parallel coordinate plots will also use the summary value while the line plot plots all of the values set by .log The reason we have both is that some people like to set the summary manually because they want the summary to reflect for example the optimal accuracy instead of the last accuracy logged.\\nHow is W&B different from TensorBoard?\\nWe love the TensorBoard folks, and we have a TensorBoard integration!\\nWe were inspired to improve experiment tracking tools for everyone.\\nWhen the co-founders started working on W&B, they were inspired to build a tool for the frustrated TensorBoard users at OpenAI.', 'score': 0.2535824064886273}\n",
      "{'source': 'guides/track/log/logging-faqs.md', 'text': 'Logging FAQs  Frequently Asked Questions About Logging Data from Experiments  How can I organize my logged charts and media in the W&B UI?\\nWe treat / as a separator for organizing logged panels in the W&B UI.\\nBy default, the component of the logged item\\'s name before a / is used to define a group of panel called a \"Panel Section\". wandb.log({\"val/loss\": 1.1, \"val/acc\": 0.3}) wandb.log({\"train/loss\": 0.1, \"train/acc\": 0.94})  In the Workspace settings, you can change whether panels are grouped by just the first component or by all components separated by /.\\nHow can I compare images or media across epochs or steps?\\nEach time you log images from a step, we save them to show in the UI.\\nExpand the image panel, and use the step slider to look at images from different steps.\\nThis makes it easy to compare how a model\\'s output changes during training.\\nWhat if I want to log some metrics on batches and some metrics only on epochs?\\nIf you\\'d like to log certain metrics in every batch and standardize plots, you can log x axis values that you want to plot with your metrics.\\nThen in the custom plots, click edit and select a custom x-axis. wandb.log({\"batch\": batch_idx, \"loss\": 0.3}) wandb.log({\"epoch\": epoch, \"val_acc\": 0.94})  How do I log a list of values?   wandb.log({f\"losses/loss-{ii}\": loss for ii, loss in enumerate(losses)})    wandb.log({\"losses\": wandb.Histogram(losses)})  # converts losses to a histogram    How do I plot multiple lines on a plot with a legend?\\nMulti-line custom chart can be created by using wandb.plot.line_series().\\nYou\\'ll need to navigate to the project page to see the line chart.\\nTo add a legend to the plot, pass the keys argument within wandb.plot.line_series().', 'score': 0.24030848530731141}\n",
      "{'source': 'guides/track/launch.md', 'text': 'Capture a dictionary of hyperparameters wandb.config = {\"epochs\": 100, \"learning_rate\": 0.001, \"batch_size\": 128}  For more information on how to configure an experiment, see Configure Experiments.\\nLog metrics inside your training loop Log metrics during each for loop (epoch), the accuracy and loss values are computed and logged to W&B with wandb.log().\\nBy default, when you call wandb.log it appends a new step to the history object and updates the summary object.\\nThe following code example shows how to log metrics with wandb.log. :::note Details of how to set up your mode and retrieve data are omitted.\\n::: # Set up model and data model, dataloader = get_model(), get_data()  for epoch in range(wandb.config.epochs):     for batch in dataloader:         loss, accuracy = model.training_step()         # \\u20033.\\nLog metrics inside your training loop to visualize         # model performance         wandb.log({\"accuracy\": accuracy, \"loss\": loss})  For more information on different data types you can log with W&B, see Log Data During Experiments.\\nLog an artifact to W&B Optionally log a W&B Artifact.\\nArtifacts make it easy to version datasets and models.  wandb.log_artifact(model)  For more information about Artifacts, see the Artifacts Chapter.\\nFor more information about versioning models, see Model Management.\\nPutting it all together The full script with the preceding code snippets is found below: # Import the W&B Python Library import wandb  # 1.\\nStart a W&B Run run = wandb.init(project=\"cat-classification\", notes=\"\", tags=[\"baseline\", \"paper1\"])  # \\u20032.', 'score': 0.23298902413385914}\n",
      "{'source': 'guides/track/log/intro.md', 'text': 'The following lists some commonly logged objects:  Datasets: You have to specifically log images or other dataset samples for them to stream to W&B. Plots: Use wandb.plot with wandb.log to track charts.\\nSee Log Plots for more information.\\nTables: Use wandb.Table to log data to visualize and query with W&B.\\nSee Log Tables for more information.\\nPyTorch gradients: Add wandb.watch(model) to see gradients of the weights as histograms in the UI.\\nConfiguration information: Log hyperparameters, a link to your dataset, or the name of the architecture you\\'re using as config parameters, passed in like this: wandb.init(config=your_config_dictionary).\\nSee the PyTorch Integrations page for more information.\\nMetrics: Use wandb.log to see metrics from your model.\\nIf you log metrics like accuracy and loss from inside your training loop, you\\'ll get live updating graphs in the UI.\\nCommon workflows  Compare the best accuracy: To compare the best value of a metric across runs, set the summary value for that metric.\\nBy default, summary is set to the last value you logged for each key.\\nThis is useful in the table in the UI, where you can sort and filter runs based on their summary metrics — so you could compare runs in a table or bar chart based on their best accuracy, instead of final accuracy.\\nFor example, you could set summary like so: wandb.run.summary[\"best_accuracy\"] = best_accuracy Multiple metrics on one chart: Log multiple metrics in the same call to wandb.log, like this: wandb.log({\"acc\\'\": 0.9, \"loss\": 0.1}) and they will both be available to plot against in the UI Custom x-axis: Add a custom x-axis to the same log call to visualize your metrics against a different axis in the W&B dashboard.\\nFor example: wandb.log({\\'acc\\': 0.9, \\'epoch\\': 3, \\'batch\\': 117}).', 'score': 0.22630141326308773}\n"
     ]
    }
   ],
   "source": [
    "# Let's test with a simple query\n",
    "\n",
    "\n",
    "retriever = Retriever()\n",
    "retriever.index_data(chunked_data)\n",
    "\n",
    "query = \"How do I use W&B to log metrics in my training script?\"\n",
    "search_results = retriever.search(query)\n",
    "for result in search_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to generate a response grounded on the documentation.\n",
    "\n",
    "\n",
    "class ResponseGenerator:\n",
    "    def __init__(self, model: str, prompt: str):\n",
    "        self.client = cohere.Client(api_key=os.environ[\"CO_API_KEY\"])\n",
    "        self.model = model\n",
    "        self.prompt = prompt\n",
    "\n",
    "    # @weave.op()\n",
    "\n",
    "    def generate_response(self, query: str, context: List[Dict[str, any]]) -> str:\n",
    "        \n",
    "        documents = [{\"source\": item['source'], \"text\": item['text']} for item in context]\n",
    "        response = self.client.chat(\n",
    "            preamble=self.prompt,\n",
    "            message=query,\n",
    "            model=self.model,\n",
    "            documents=documents,\n",
    "            temperature=0.1,\n",
    "            max_tokens=2000,\n",
    "        )\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"Answer to the following question about W&B. Provide an helful and complete answer based only on the provided documents.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To log metrics in your training script, you can include the following lines of code:\n",
      "```\n",
      "# Import the W&amp;B Python Library\n",
      "import wandb\n",
      "\n",
      "# Start a W&amp;B Run\n",
      "run = wandb.init(project=\"cat-classification\", notes=\"\", tags=[\"baseline\", \"paper1\"])\n",
      "\n",
      "# Log metrics inside your training loop\n",
      "for epoch in range(wandb.config.epochs):\n",
      " for batch in dataloader:\n",
      " loss, accuracy = model.training_step()\n",
      " wandb.log({\"accuracy\": accuracy, \"loss\": loss})\n",
      "```\n",
      "When you call `wandb.init() from your training script, a separate process is launched to stream and collect metrics, which keeps all threads and logic out of your primary process. Your script runs normally and writes to local files, while the separate process streams them to the W&B servers along with system metrics.\n",
      "\n",
      "You can log metrics such as accuracy and loss during each epoch to visualize model performance. As shown in the example above, use `wandb.log()` to log the metrics inside your training loop. This will append a new step to the history object and update the summary object.\n",
      "\n",
      "To log images, plots, or datasets, you can use different functions such as `wandb.plot`, `wandb.Table`, and `wandb.log_artifact`. For instance, calling `wandb.plot` with `wandb.log` will allow you to track charts.\n"
     ]
    }
   ],
   "source": [
    "response_generator = ResponseGenerator(model=\"command-r\", prompt=PROMPT)\n",
    "answer = response_generator.generate_response(query, search_results)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, retriever: Retriever, response_generator: ResponseGenerator, top_k: int = 5):\n",
    "        self.retriever = retriever\n",
    "        self.response_generator = response_generator\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def __call__(self, query: str):\n",
    "        context = self.retriever.search(query, self.top_k)\n",
    "        return self.response_generator.generate_response(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can collect your API key by navigating to the authorize page or in your user/team settings. User/team settings can be found on the W&B App UI. Alternatively, you can run 'wandb login' on the command line and paste your API key there. Remember to store your API key securely and never share it by checking it into version control.\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = RAGPipeline(retriever, response_generator, top_k=10)\n",
    "response = rag_pipeline(query=\"Where do I find my API Key?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/04 17:27:33 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/rag-course/dev/okxu0mvh/artifact/938190750/wandb_manifest.json?Expires=1720097853&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=kV6NK3lIrKzAia43Uq%2BDA2xEsV7FrKCR5XOdA2tF2KfAdq8RPZwjXS0u1K%2BJbvdwtmC8HoPyE50MxEgHNqt%2FsloCjP6%2FSVOMW5zVYBl78jA46a%2BjcfVbBKTqhcHJ3W79Bv%2FZx8jS%2BguuJT3L63eEbLU0PPdJdefUvAll%2BIi4289DltGz96FnndUfAPpnMm4JZHFeT%2FJw3CL3L%2FZVShBfCvpQA2zHehphBT7LHDjxLeHTqM%2BLKfRKc50P22dCPgM6K3VJUManmX572ndMkamicPd5m7x%2BTsHrv00Y72pWb3B65F5bG%2FxyeJiLbMI7AH7hr3ceBiF9y77i7fwiqS0v5Q%3D%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between `.log()` and `....</td>\n",
       "      <td>The summary is the value that shows in the tab...</td>\n",
       "      <td>guides/technical-faq/general.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I switch between accounts on the same m...</td>\n",
       "      <td>If you have two W&amp;B accounts working from the ...</td>\n",
       "      <td>guides/technical-faq/general.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is W&amp;B different from TensorBoard?</td>\n",
       "      <td>We love the TensorBoard folks, and we have a T...</td>\n",
       "      <td>guides/technical-faq/general.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between team and organi...</td>\n",
       "      <td>A team is a collaborative workspace for a grou...</td>\n",
       "      <td>guides/technical-faq/admin.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the difference between team and entity...</td>\n",
       "      <td>A team is a collaborative workspace for a grou...</td>\n",
       "      <td>guides/technical-faq/admin.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I just log metrics, no code or dataset exa...</td>\n",
       "      <td>**Dataset Examples**\\n\\nBy default, we don't l...</td>\n",
       "      <td>guides/technical-faq/metrics-and-performance.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can I log a metric that doesn't change ove...</td>\n",
       "      <td>Using `wandb.log({'final_accuracy': 0.9}` will...</td>\n",
       "      <td>guides/technical-faq/metrics-and-performance.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many runs to create per project?</td>\n",
       "      <td>We recommend you have roughly 10k runs per pro...</td>\n",
       "      <td>guides/technical-faq/metrics-and-performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can I run wandb offline?</td>\n",
       "      <td>If you're training on an offline machine and w...</td>\n",
       "      <td>guides/technical-faq/setup.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I deal with network issues?</td>\n",
       "      <td>If you're seeing SSL or network errors:`wandb:...</td>\n",
       "      <td>guides/technical-faq/troubleshooting.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What happens if internet connection is lost wh...</td>\n",
       "      <td>If the wandb library is unable to connect to t...</td>\n",
       "      <td>guides/technical-faq/troubleshooting.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where do I find my API key?</td>\n",
       "      <td>Once you've signed in to www.wandb.ai, the API...</td>\n",
       "      <td>quickstart.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I create a W&amp;B Experiment?</td>\n",
       "      <td>Create a W&amp;B Experiment in four steps:\\n\\n1. [...</td>\n",
       "      <td>guides/track/launch.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Log a table to a run</td>\n",
       "      <td>Use `wandb.log()` to save your table to the ru...</td>\n",
       "      <td>track/log/log-tables.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do I log a list of values?</td>\n",
       "      <td>You can log a list of values iteratively, or ...</td>\n",
       "      <td>track/log/logging-faqs.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Is there a way to add extra values to a sweep,...</td>\n",
       "      <td>You cannot change the Sweep configuration once...</td>\n",
       "      <td>guides/sweep/faqs.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Can we flag boolean variables as hyperparameters?</td>\n",
       "      <td>You can use the `${args_no_boolean_flags}` mac...</td>\n",
       "      <td>guides/sweep/faqs.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do I programmatically access the human-rea...</td>\n",
       "      <td>It's available as the `.name` attribute of a `...</td>\n",
       "      <td>guides/track/tracking-faq.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How can I save the git commit associated with ...</td>\n",
       "      <td>When `wandb.init` is called in your script, we...</td>\n",
       "      <td>guides/track/tracking-faq.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can I organize my logged charts and media ...</td>\n",
       "      <td>We treat `/` as a separator for organizing log...</td>\n",
       "      <td>guides/track/log/logging-faqs.md</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is the difference between `.log()` and `....   \n",
       "1   How do I switch between accounts on the same m...   \n",
       "2              How is W&B different from TensorBoard?   \n",
       "3   What is the difference between team and organi...   \n",
       "4   What is the difference between team and entity...   \n",
       "5   Can I just log metrics, no code or dataset exa...   \n",
       "6   How can I log a metric that doesn't change ove...   \n",
       "7                How many runs to create per project?   \n",
       "8                            Can I run wandb offline?   \n",
       "9                  How do I deal with network issues?   \n",
       "10  What happens if internet connection is lost wh...   \n",
       "11                        Where do I find my API key?   \n",
       "12                  How do I create a W&B Experiment?   \n",
       "13                               Log a table to a run   \n",
       "14                     How do I log a list of values?   \n",
       "15  Is there a way to add extra values to a sweep,...   \n",
       "16  Can we flag boolean variables as hyperparameters?   \n",
       "17  How do I programmatically access the human-rea...   \n",
       "18  How can I save the git commit associated with ...   \n",
       "19  How can I organize my logged charts and media ...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   The summary is the value that shows in the tab...   \n",
       "1   If you have two W&B accounts working from the ...   \n",
       "2   We love the TensorBoard folks, and we have a T...   \n",
       "3   A team is a collaborative workspace for a grou...   \n",
       "4   A team is a collaborative workspace for a grou...   \n",
       "5   **Dataset Examples**\\n\\nBy default, we don't l...   \n",
       "6   Using `wandb.log({'final_accuracy': 0.9}` will...   \n",
       "7   We recommend you have roughly 10k runs per pro...   \n",
       "8   If you're training on an offline machine and w...   \n",
       "9   If you're seeing SSL or network errors:`wandb:...   \n",
       "10  If the wandb library is unable to connect to t...   \n",
       "11  Once you've signed in to www.wandb.ai, the API...   \n",
       "12  Create a W&B Experiment in four steps:\\n\\n1. [...   \n",
       "13  Use `wandb.log()` to save your table to the ru...   \n",
       "14   You can log a list of values iteratively, or ...   \n",
       "15  You cannot change the Sweep configuration once...   \n",
       "16  You can use the `${args_no_boolean_flags}` mac...   \n",
       "17  It's available as the `.name` attribute of a `...   \n",
       "18  When `wandb.init` is called in your script, we...   \n",
       "19  We treat `/` as a separator for organizing log...   \n",
       "\n",
       "                                             source  \n",
       "0                   guides/technical-faq/general.md  \n",
       "1                   guides/technical-faq/general.md  \n",
       "2                   guides/technical-faq/general.md  \n",
       "3                     guides/technical-faq/admin.md  \n",
       "4                     guides/technical-faq/admin.md  \n",
       "5   guides/technical-faq/metrics-and-performance.md  \n",
       "6   guides/technical-faq/metrics-and-performance.md  \n",
       "7      guides/technical-faq/metrics-and-performance  \n",
       "8                     guides/technical-faq/setup.md  \n",
       "9           guides/technical-faq/troubleshooting.md  \n",
       "10          guides/technical-faq/troubleshooting.md  \n",
       "11                                    quickstart.md  \n",
       "12                           guides/track/launch.md  \n",
       "13                          track/log/log-tables.md  \n",
       "14                        track/log/logging-faqs.md  \n",
       "15                             guides/sweep/faqs.md  \n",
       "16                             guides/sweep/faqs.md  \n",
       "17                     guides/track/tracking-faq.md  \n",
       "18                     guides/track/tracking-faq.md  \n",
       "19                 guides/track/log/logging-faqs.md  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_artifact = run.use_artifact(\n",
    "    f\"{WANDB_ENTITY}/{WANDB_PROJECT}/eval_dataset:latest\", type=\"dataset\"\n",
    ")\n",
    "eval_dir = eval_artifact.download(\"../data/eval\")\n",
    "eval_dataset = pd.read_json(\n",
    "    f\"{eval_dir}/eval_dataset.jsonl\", lines=True, orient=\"records\"\n",
    ")\n",
    "eval_samples = eval_dataset.to_dict(orient=\"records\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:35<00:00,  1.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>ndcg@10</th>\n",
       "      <th>map@10</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between `.log()` and `....</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I switch between accounts on the same m...</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is W&amp;B different from TensorBoard?</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between team and organi...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the difference between team and entity...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I just log metrics, no code or dataset exa...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can I log a metric that doesn't change ove...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many runs to create per project?</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can I run wandb offline?</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I deal with network issues?</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What happens if internet connection is lost wh...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where do I find my API key?</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I create a W&amp;B Experiment?</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Log a table to a run</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do I log a list of values?</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Is there a way to add extra values to a sweep,...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Can we flag boolean variables as hyperparameters?</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do I programmatically access the human-rea...</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How can I save the git commit associated with ...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can I organize my logged charts and media ...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  ndcg@10    map@10  \\\n",
       "0   What is the difference between `.log()` and `....  1.00000  1.000000   \n",
       "1   How do I switch between accounts on the same m...  0.30103  0.111111   \n",
       "2              How is W&B different from TensorBoard?  0.50000  0.333333   \n",
       "3   What is the difference between team and organi...  1.00000  1.000000   \n",
       "4   What is the difference between team and entity...  1.00000  1.000000   \n",
       "5   Can I just log metrics, no code or dataset exa...  1.00000  1.000000   \n",
       "6   How can I log a metric that doesn't change ove...  1.00000  1.000000   \n",
       "7                How many runs to create per project?  0.00000  0.000000   \n",
       "8                            Can I run wandb offline?  0.50000  0.333333   \n",
       "9                  How do I deal with network issues?  1.00000  1.000000   \n",
       "10  What happens if internet connection is lost wh...  1.00000  1.000000   \n",
       "11                        Where do I find my API key?  0.00000  0.000000   \n",
       "12                  How do I create a W&B Experiment?  1.00000  1.000000   \n",
       "13                               Log a table to a run  0.00000  0.000000   \n",
       "14                     How do I log a list of values?  0.00000  0.000000   \n",
       "15  Is there a way to add extra values to a sweep,...  0.00000  0.000000   \n",
       "16  Can we flag boolean variables as hyperparameters?  0.00000  0.000000   \n",
       "17  How do I programmatically access the human-rea...  0.50000  0.333333   \n",
       "18  How can I save the git commit associated with ...  1.00000  1.000000   \n",
       "19  How can I organize my logged charts and media ...  1.00000  1.000000   \n",
       "\n",
       "         mrr  hit_rate  precision  recall        f1  \n",
       "0   1.000000       1.0   0.111111     1.0  0.200000  \n",
       "1   0.111111       1.0   0.100000     1.0  0.181818  \n",
       "2   0.333333       1.0   0.142857     1.0  0.250000  \n",
       "3   1.000000       1.0   0.166667     1.0  0.285714  \n",
       "4   1.000000       1.0   0.111111     1.0  0.200000  \n",
       "5   1.000000       1.0   0.125000     1.0  0.222222  \n",
       "6   1.000000       1.0   0.100000     1.0  0.181818  \n",
       "7   0.000000       0.0   0.000000     0.0  0.000000  \n",
       "8   0.333333       1.0   0.125000     1.0  0.222222  \n",
       "9   1.000000       1.0   0.100000     1.0  0.181818  \n",
       "10  1.000000       1.0   0.100000     1.0  0.181818  \n",
       "11  0.000000       0.0   0.000000     0.0  0.000000  \n",
       "12  1.000000       1.0   0.100000     1.0  0.181818  \n",
       "13  0.000000       0.0   0.000000     0.0  0.000000  \n",
       "14  0.000000       0.0   0.000000     0.0  0.000000  \n",
       "15  0.000000       0.0   0.000000     0.0  0.000000  \n",
       "16  0.000000       0.0   0.000000     0.0  0.000000  \n",
       "17  0.333333       1.0   0.125000     1.0  0.222222  \n",
       "18  1.000000       1.0   0.125000     1.0  0.222222  \n",
       "19  1.000000       1.0   0.100000     1.0  0.181818  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Overall Retrieval Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg@10</th>\n",
       "      <th>map@10</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.590051</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.145776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ndcg@10    map@10       mrr  hit_rate  precision  recall        f1\n",
       "0  0.590051  0.555556  0.555556       0.7   0.081587     0.7  0.145776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Retrieval Score Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ndcg@10</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.590051</td>\n",
       "      <td>0.451745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map@10</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.468640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.468640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit_rate</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.470162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.470162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.145776</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min  25%       50%       75%       max\n",
       "ndcg@10     20.0  0.590051  0.451745  0.0  0.0  0.750000  1.000000  1.000000\n",
       "map@10      20.0  0.555556  0.468640  0.0  0.0  0.666667  1.000000  1.000000\n",
       "mrr         20.0  0.555556  0.468640  0.0  0.0  0.666667  1.000000  1.000000\n",
       "hit_rate    20.0  0.700000  0.470162  0.0  0.0  1.000000  1.000000  1.000000\n",
       "precision   20.0  0.081587  0.057238  0.0  0.0  0.100000  0.125000  0.166667\n",
       "recall      20.0  0.700000  0.470162  0.0  0.0  1.000000  1.000000  1.000000\n",
       "f1          20.0  0.145776  0.101307  0.0  0.0  0.181818  0.222222  0.285714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ranx import Qrels, Run, evaluate\n",
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "RETRIEVAL_METRICS = [\"ndcg@10\", \"map@10\", \"mrr\", \"hit_rate\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "\n",
    "def evaluate_retriever(retrieved_docs: List[Dict[str, Any]], actual_doc: str) -> Dict[str, Any]:\n",
    "    qrels = Qrels({\"query\": {actual_doc: 1}})\n",
    "    run = Run({\"query\": {doc[\"source\"]: doc[\"score\"] for doc in retrieved_docs}})\n",
    "    return evaluate(qrels, run, metrics=RETRIEVAL_METRICS)\n",
    "\n",
    "\n",
    "retrieval_scores = []\n",
    "for sample in tqdm(eval_samples):\n",
    "    query = sample[\"question\"]\n",
    "    expected_source = sample[\"source\"]\n",
    "    search_results = retriever.search(query, k=10)\n",
    "    eval_scores = evaluate_retriever(search_results, expected_source)\n",
    "    retrieval_scores.append({\"query\": query, **eval_scores})\n",
    "\n",
    "retrieval_scores_df = pd.DataFrame(retrieval_scores)\n",
    "display(retrieval_scores_df)\n",
    "\n",
    "print(\"\\nMean Overall Retrieval Scores:\")\n",
    "display(pd.DataFrame(retrieval_scores_df[RETRIEVAL_METRICS].mean()).T)\n",
    "\n",
    "print(\"\\nOverall Retrieval Score Statistics:\")\n",
    "display(pd.DataFrame(retrieval_scores_df[RETRIEVAL_METRICS].describe()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RETRIEVAL_EVAL_PROMPT =\"\"\"\n",
    "Given a query and a document excerpt, you must provide a score on an integer scale of 0 to 3 with the following meanings:\n",
    "    0 = represent that the excerpt has nothing to do with the query,\n",
    "    1 = represents that the excerpt seems related to the query but does not help answer it,\n",
    "    2 = represents that the excerpt has some answer for the query, but the answer may be a bit unclear, or hidden amongst extraneous information and\n",
    "    3 = represents that the excerpt is dedicated to the query and contains the exact answer.\n",
    "\n",
    "Important Instruction: Assign category 1 if the excerpt is somewhat related to the topic but not completely, category 2 if excerpt presents something very important related to the entire topic but also has some extra information and category 3 if the excerpt only and entirely refers to the topic. If none of the above satisfies give it category 0.\n",
    "\n",
    "Query: {query}\n",
    "Document: {document}\n",
    "\n",
    "Split this problem into steps:\n",
    "Consider the underlying intent of the query. Measure how well the content matches a likely intent of the query(M).\n",
    "Measure how trustworthy the excerpt is (T).\n",
    "Consider the aspects above and the relative importance of each, and decide on a final score (O). \n",
    "Final score must be an integer value only.\n",
    "Do not provide any code in result. Provide each score in the following JSON format: \n",
    "\n",
    "\n",
    "{{\"final_score\": <integer score without providing any reasoning.>}}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cohere.AsyncClient(api_key=os.environ[\"CO_API_KEY\"])\n",
    "\n",
    "async def evaluate_retriever_using_llm_judge(query: str, passage: str) -> int:\n",
    "    response = await client.chat(\n",
    "        message=RETRIEVAL_EVAL_PROMPT.format(query=query, document=passage),\n",
    "        model=\"command-r-plus\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"final_score\": 3}',\n",
       " '{\"final_score\": 3}',\n",
       " '{\"final_score\": 0}',\n",
       " '{\"final_score\": 3}',\n",
       " '{\"final_score\": 2}']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "sample = eval_samples[0]\n",
    "query = sample[\"question\"]\n",
    "search_results = retriever.search(query, k=5)\n",
    "tasks = []\n",
    "for result in search_results:\n",
    "    tasks.append(evaluate_retriever_using_llm_judge(query, result[\"text\"]))\n",
    "sample_scores = asyncio.run(asyncio.gather(*tasks))\n",
    "sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_retriever_evaluation_using_llm(eval_samples):\n",
    "    scores = []\n",
    "    for sample in eval_samples:\n",
    "        query = sample[\"question\"]\n",
    "        search_results = retriever.search(query, k=5)\n",
    "        tasks = []\n",
    "        for result in search_results:\n",
    "            tasks.append(evaluate_retriever_using_llm_judge(query, result[\"text\"]))\n",
    "        sample_scores = await asyncio.gather(*tasks)\n",
    "        sample_scores = map(json.loads, sample_scores)\n",
    "        sample_scores = list(map(lambda x: x[\"final_score\"], sample_scores))\n",
    "        scores.append({\"query\": query, \"scores\": sample_scores})\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_judge_retrieval_results = asyncio.run(run_retriever_evaluation_using_llm(eval_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>scores</th>\n",
       "      <th>rank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between `.log()` and `....</td>\n",
       "      <td>[3, 3, 0, 3, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I switch between accounts on the same m...</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is W&amp;B different from TensorBoard?</td>\n",
       "      <td>[2, 2, 3, 3, 2]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between team and organi...</td>\n",
       "      <td>[3, 1, 1, 1, 1]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the difference between team and entity...</td>\n",
       "      <td>[3, 1, 3, 0, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I just log metrics, no code or dataset exa...</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can I log a metric that doesn't change ove...</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many runs to create per project?</td>\n",
       "      <td>[2, 3, 2, 2, 2]</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can I run wandb offline?</td>\n",
       "      <td>[3, 3, 3, 3, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I deal with network issues?</td>\n",
       "      <td>[3, 2, 2, 0, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What happens if internet connection is lost wh...</td>\n",
       "      <td>[3, 3, 0, 0, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where do I find my API key?</td>\n",
       "      <td>[3, 0, 0, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I create a W&amp;B Experiment?</td>\n",
       "      <td>[3, 3, 2, 2, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Log a table to a run</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do I log a list of values?</td>\n",
       "      <td>[3, 3, 2, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Is there a way to add extra values to a sweep,...</td>\n",
       "      <td>[3, 2, 2, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Can we flag boolean variables as hyperparameters?</td>\n",
       "      <td>[3, 0, 1, 0, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do I programmatically access the human-rea...</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How can I save the git commit associated with ...</td>\n",
       "      <td>[3, 3, 3, 0, 0]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can I organize my logged charts and media ...</td>\n",
       "      <td>[3, 2, 2, 2, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query           scores  \\\n",
       "0   What is the difference between `.log()` and `....  [3, 3, 0, 3, 2]   \n",
       "1   How do I switch between accounts on the same m...  [0, 0, 1, 0, 0]   \n",
       "2              How is W&B different from TensorBoard?  [2, 2, 3, 3, 2]   \n",
       "3   What is the difference between team and organi...  [3, 1, 1, 1, 1]   \n",
       "4   What is the difference between team and entity...  [3, 1, 3, 0, 2]   \n",
       "5   Can I just log metrics, no code or dataset exa...  [3, 3, 3, 3, 3]   \n",
       "6   How can I log a metric that doesn't change ove...  [3, 3, 3, 3, 3]   \n",
       "7                How many runs to create per project?  [2, 3, 2, 2, 2]   \n",
       "8                            Can I run wandb offline?  [3, 3, 3, 3, 0]   \n",
       "9                  How do I deal with network issues?  [3, 2, 2, 0, 0]   \n",
       "10  What happens if internet connection is lost wh...  [3, 3, 0, 0, 0]   \n",
       "11                        Where do I find my API key?  [3, 0, 0, 3, 3]   \n",
       "12                  How do I create a W&B Experiment?  [3, 3, 2, 2, 3]   \n",
       "13                               Log a table to a run  [3, 3, 3, 3, 3]   \n",
       "14                     How do I log a list of values?  [3, 3, 2, 3, 3]   \n",
       "15  Is there a way to add extra values to a sweep,...  [3, 2, 2, 3, 3]   \n",
       "16  Can we flag boolean variables as hyperparameters?  [3, 0, 1, 0, 0]   \n",
       "17  How do I programmatically access the human-rea...  [3, 3, 3, 3, 3]   \n",
       "18  How can I save the git commit associated with ...  [3, 3, 3, 0, 0]   \n",
       "19  How can I organize my logged charts and media ...  [3, 2, 2, 2, 2]   \n",
       "\n",
       "    rank_score  \n",
       "0     1.000000  \n",
       "1     0.000000  \n",
       "2     0.333333  \n",
       "3     1.000000  \n",
       "4     1.000000  \n",
       "5     1.000000  \n",
       "6     1.000000  \n",
       "7     0.500000  \n",
       "8     1.000000  \n",
       "9     1.000000  \n",
       "10    1.000000  \n",
       "11    1.000000  \n",
       "12    1.000000  \n",
       "13    1.000000  \n",
       "14    1.000000  \n",
       "15    1.000000  \n",
       "16    1.000000  \n",
       "17    1.000000  \n",
       "18    1.000000  \n",
       "19    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank Score: 0.8917\n",
      "Std-dev Rank Score: 0.2772\n"
     ]
    }
   ],
   "source": [
    "# we have the scores for each document\n",
    "llm_judge_retrieval_results_df = pd.DataFrame(llm_judge_retrieval_results)\n",
    "\n",
    "# we can compute the reciprocal rank of the first document that is relevant to the query i.e. rated as 3 by our llm judge.\n",
    "def compute_rank_score(scores: List[int]) -> float:\n",
    "    rank_score = 0\n",
    "    for rank, result in enumerate(scores, 1):\n",
    "        if result == 3:\n",
    "            rank_score = 1 / rank\n",
    "            return rank_score\n",
    "    return rank_score\n",
    "\n",
    "llm_judge_retrieval_results_df[\"rank_score\"] = llm_judge_retrieval_results_df[\"scores\"].map(compute_rank_score)\n",
    "\n",
    "\n",
    "display(llm_judge_retrieval_results_df)\n",
    "\n",
    "\n",
    "print(f\"Mean Rank Score: {llm_judge_retrieval_results_df['rank_score'].mean():.4f}\")\n",
    "print(f\"Std-dev Rank Score: {llm_judge_retrieval_results_df['rank_score'].std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import Levenshtein\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import meteor\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# We can measure the similarity of the response to the expected answer using difflib and Levenshtein distance\n",
    "# These are simple metrics.\n",
    "\n",
    "def calculate_diff_score(candidate, reference):\n",
    "    return difflib.SequenceMatcher(None, candidate, reference).ratio()\n",
    "\n",
    "\n",
    "def calculate_levenshtein_score(candidate, reference):\n",
    "    return Levenshtein.ratio(candidate, reference)\n",
    "\n",
    "\n",
    "\n",
    "# semantic answer similarity. (SAS) - https://arxiv.org/abs/2108.06130\n",
    "# Originally, one should use a transformer based cross-encoder to measure and classify this. \n",
    "# For example, use something from https://sbert.net/docs/cross_encoder/usage/usage.html\n",
    "# we can also calculate the cosine similarity between the candidate and the reference using our retriever's vectorizer\n",
    "def calculate_similarity(candidate, reference):\n",
    "    vectors = retriever.vectorizer.transform([candidate, reference])\n",
    "    similarity = cosine_similarity(vectors)[0][1]\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# or we can use traditional metrics used to measure generation systems.\n",
    "# ref: https://blog.paperspace.com/automated-metrics-for-evaluating-generated-text/\n",
    "\n",
    "def calculate_rouge(candidate, reference):\n",
    "    rouge = Rouge(metrics=[\"rouge-l\"], stats=\"f\")\n",
    "    scores = rouge.get_scores(candidate, reference)\n",
    "    return scores[0][\"rouge-l\"][\"f\"]\n",
    "\n",
    "\n",
    "def calculate_bleu(candidate, reference):\n",
    "    chencherry = SmoothingFunction()\n",
    "    smoothing_function = chencherry.method2\n",
    "\n",
    "    reference = word_tokenize(reference)\n",
    "    candidate = word_tokenize(candidate)\n",
    "    score = sentence_bleu([reference], candidate, smoothing_function=smoothing_function)\n",
    "    return score\n",
    "\n",
    "\n",
    "def calculate_meteor(candidate, reference):\n",
    "    reference = word_tokenize(reference)\n",
    "    candidate = word_tokenize(candidate)\n",
    "    meteor_score = meteor([candidate], reference)\n",
    "    return meteor_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:23<00:00,  4.16s/it]\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = RAGPipeline(retriever, response_generator)\n",
    "\n",
    "response_scores = []\n",
    "for sample in tqdm(eval_samples):\n",
    "    query = sample['question']\n",
    "    actual_answer = rag_pipeline(query)\n",
    "    expected_answer = sample['answer']\n",
    "    diff_score = calculate_diff_score(actual_answer, expected_answer)\n",
    "    levenshtein_score = calculate_levenshtein_score(actual_answer, expected_answer)\n",
    "    rouge_score = calculate_rouge(actual_answer, expected_answer)\n",
    "    bleu_score = calculate_bleu(actual_answer, expected_answer)\n",
    "    meteor_score = calculate_meteor(actual_answer, expected_answer)\n",
    "    similarity_score = calculate_similarity(actual_answer, expected_answer)\n",
    "\n",
    "    response_scores.append({\n",
    "        \"query\": query,\n",
    "        \"expected_answer\": expected_answer,\n",
    "        \"actual_answer\": actual_answer,\n",
    "        \"diff_score\": diff_score,\n",
    "        \"levenshtein_score\": levenshtein_score,\n",
    "        \"rouge_score\": rouge_score,\n",
    "        \"bleu_score\": bleu_score,\n",
    "        \"meteor_score\": meteor_score,\n",
    "        \"similarity_score\": similarity_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>actual_answer</th>\n",
       "      <th>diff_score</th>\n",
       "      <th>levenshtein_score</th>\n",
       "      <th>rouge_score</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between `.log()` and `....</td>\n",
       "      <td>The summary is the value that shows in the tab...</td>\n",
       "      <td>The summary is the value that shows in the tab...</td>\n",
       "      <td>0.142349</td>\n",
       "      <td>0.519573</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.273118</td>\n",
       "      <td>0.461614</td>\n",
       "      <td>0.690083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I switch between accounts on the same m...</td>\n",
       "      <td>If you have two W&amp;B accounts working from the ...</td>\n",
       "      <td>To switch between accounts on the same machine...</td>\n",
       "      <td>0.021068</td>\n",
       "      <td>0.365688</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>0.100473</td>\n",
       "      <td>0.174637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is W&amp;B different from TensorBoard?</td>\n",
       "      <td>We love the TensorBoard folks, and we have a T...</td>\n",
       "      <td>Here are some ways in which W&amp;B (Weights &amp; Bia...</td>\n",
       "      <td>0.087273</td>\n",
       "      <td>0.374876</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.511543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between team and organi...</td>\n",
       "      <td>A team is a collaborative workspace for a grou...</td>\n",
       "      <td>An organization is a high-level entity that ma...</td>\n",
       "      <td>0.377193</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>0.389861</td>\n",
       "      <td>0.676034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the difference between team and entity...</td>\n",
       "      <td>A team is a collaborative workspace for a grou...</td>\n",
       "      <td>An entity refers to either a username or a tea...</td>\n",
       "      <td>0.137652</td>\n",
       "      <td>0.518219</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.278176</td>\n",
       "      <td>0.383771</td>\n",
       "      <td>0.587536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I just log metrics, no code or dataset exa...</td>\n",
       "      <td>**Dataset Examples**\\n\\nBy default, we don't l...</td>\n",
       "      <td>Yes, you can just log metrics without providin...</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.448198</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.078870</td>\n",
       "      <td>0.300286</td>\n",
       "      <td>0.213999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can I log a metric that doesn't change ove...</td>\n",
       "      <td>Using `wandb.log({'final_accuracy': 0.9}` will...</td>\n",
       "      <td>To log a metric that doesn't change over time,...</td>\n",
       "      <td>0.197115</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.201340</td>\n",
       "      <td>0.338727</td>\n",
       "      <td>0.436238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many runs to create per project?</td>\n",
       "      <td>We recommend you have roughly 10k runs per pro...</td>\n",
       "      <td>There is no specific number of runs to create ...</td>\n",
       "      <td>0.152985</td>\n",
       "      <td>0.220149</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.017058</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.154099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can I run wandb offline?</td>\n",
       "      <td>If you're training on an offline machine and w...</td>\n",
       "      <td>Yes, you can run W&amp;B offline. If your machine ...</td>\n",
       "      <td>0.159848</td>\n",
       "      <td>0.561370</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.213403</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>0.699943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I deal with network issues?</td>\n",
       "      <td>If you're seeing SSL or network errors:`wandb:...</td>\n",
       "      <td>If you're experiencing network issues, such as...</td>\n",
       "      <td>0.458577</td>\n",
       "      <td>0.579079</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.227293</td>\n",
       "      <td>0.698551</td>\n",
       "      <td>0.752566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What happens if internet connection is lost wh...</td>\n",
       "      <td>If the wandb library is unable to connect to t...</td>\n",
       "      <td>If the internet connection is lost while train...</td>\n",
       "      <td>0.042517</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.200566</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where do I find my API key?</td>\n",
       "      <td>Once you've signed in to www.wandb.ai, the API...</td>\n",
       "      <td>You can collect your API key by navigating to ...</td>\n",
       "      <td>0.247086</td>\n",
       "      <td>0.312354</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>0.150578</td>\n",
       "      <td>0.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I create a W&amp;B Experiment?</td>\n",
       "      <td>Create a W&amp;B Experiment in four steps:\\n\\n1. [...</td>\n",
       "      <td>You can create a W&amp;B Experiment in four steps:...</td>\n",
       "      <td>0.192479</td>\n",
       "      <td>0.397790</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.097003</td>\n",
       "      <td>0.491812</td>\n",
       "      <td>0.617133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Log a table to a run</td>\n",
       "      <td>Use `wandb.log()` to save your table to the ru...</td>\n",
       "      <td>You can log a table to a run using the followi...</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.704065</td>\n",
       "      <td>0.582781</td>\n",
       "      <td>0.387109</td>\n",
       "      <td>0.731381</td>\n",
       "      <td>0.800844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do I log a list of values?</td>\n",
       "      <td>You can log a list of values iteratively, or ...</td>\n",
       "      <td>You can log a list of values by using the wand...</td>\n",
       "      <td>0.373377</td>\n",
       "      <td>0.509740</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.321033</td>\n",
       "      <td>0.612899</td>\n",
       "      <td>0.720118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Is there a way to add extra values to a sweep,...</td>\n",
       "      <td>You cannot change the Sweep configuration once...</td>\n",
       "      <td>Unfortunately, you cannot change the sweep con...</td>\n",
       "      <td>0.465587</td>\n",
       "      <td>0.623482</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.386743</td>\n",
       "      <td>0.779003</td>\n",
       "      <td>0.867619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Can we flag boolean variables as hyperparameters?</td>\n",
       "      <td>You can use the `${args_no_boolean_flags}` mac...</td>\n",
       "      <td>Yes, you can flag boolean variables as hyperpa...</td>\n",
       "      <td>0.568588</td>\n",
       "      <td>0.588469</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.261722</td>\n",
       "      <td>0.733173</td>\n",
       "      <td>0.629063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do I programmatically access the human-rea...</td>\n",
       "      <td>It's available as the `.name` attribute of a `...</td>\n",
       "      <td>After calling wandb.init(), you can access the...</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.398340</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.086747</td>\n",
       "      <td>0.235535</td>\n",
       "      <td>0.310222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How can I save the git commit associated with ...</td>\n",
       "      <td>When `wandb.init` is called in your script, we...</td>\n",
       "      <td>When wandb.init is called in your script, Weig...</td>\n",
       "      <td>0.348928</td>\n",
       "      <td>0.680312</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.649195</td>\n",
       "      <td>0.830568</td>\n",
       "      <td>0.894306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can I organize my logged charts and media ...</td>\n",
       "      <td>We treat `/` as a separator for organizing log...</td>\n",
       "      <td>You can use \"/\" as a separator for organizing ...</td>\n",
       "      <td>0.269521</td>\n",
       "      <td>0.670025</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.390531</td>\n",
       "      <td>0.749572</td>\n",
       "      <td>0.857729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   What is the difference between `.log()` and `....   \n",
       "1   How do I switch between accounts on the same m...   \n",
       "2              How is W&B different from TensorBoard?   \n",
       "3   What is the difference between team and organi...   \n",
       "4   What is the difference between team and entity...   \n",
       "5   Can I just log metrics, no code or dataset exa...   \n",
       "6   How can I log a metric that doesn't change ove...   \n",
       "7                How many runs to create per project?   \n",
       "8                            Can I run wandb offline?   \n",
       "9                  How do I deal with network issues?   \n",
       "10  What happens if internet connection is lost wh...   \n",
       "11                        Where do I find my API key?   \n",
       "12                  How do I create a W&B Experiment?   \n",
       "13                               Log a table to a run   \n",
       "14                     How do I log a list of values?   \n",
       "15  Is there a way to add extra values to a sweep,...   \n",
       "16  Can we flag boolean variables as hyperparameters?   \n",
       "17  How do I programmatically access the human-rea...   \n",
       "18  How can I save the git commit associated with ...   \n",
       "19  How can I organize my logged charts and media ...   \n",
       "\n",
       "                                      expected_answer  \\\n",
       "0   The summary is the value that shows in the tab...   \n",
       "1   If you have two W&B accounts working from the ...   \n",
       "2   We love the TensorBoard folks, and we have a T...   \n",
       "3   A team is a collaborative workspace for a grou...   \n",
       "4   A team is a collaborative workspace for a grou...   \n",
       "5   **Dataset Examples**\\n\\nBy default, we don't l...   \n",
       "6   Using `wandb.log({'final_accuracy': 0.9}` will...   \n",
       "7   We recommend you have roughly 10k runs per pro...   \n",
       "8   If you're training on an offline machine and w...   \n",
       "9   If you're seeing SSL or network errors:`wandb:...   \n",
       "10  If the wandb library is unable to connect to t...   \n",
       "11  Once you've signed in to www.wandb.ai, the API...   \n",
       "12  Create a W&B Experiment in four steps:\\n\\n1. [...   \n",
       "13  Use `wandb.log()` to save your table to the ru...   \n",
       "14   You can log a list of values iteratively, or ...   \n",
       "15  You cannot change the Sweep configuration once...   \n",
       "16  You can use the `${args_no_boolean_flags}` mac...   \n",
       "17  It's available as the `.name` attribute of a `...   \n",
       "18  When `wandb.init` is called in your script, we...   \n",
       "19  We treat `/` as a separator for organizing log...   \n",
       "\n",
       "                                        actual_answer  diff_score  \\\n",
       "0   The summary is the value that shows in the tab...    0.142349   \n",
       "1   To switch between accounts on the same machine...    0.021068   \n",
       "2   Here are some ways in which W&B (Weights & Bia...    0.087273   \n",
       "3   An organization is a high-level entity that ma...    0.377193   \n",
       "4   An entity refers to either a username or a tea...    0.137652   \n",
       "5   Yes, you can just log metrics without providin...    0.011261   \n",
       "6   To log a metric that doesn't change over time,...    0.197115   \n",
       "7   There is no specific number of runs to create ...    0.152985   \n",
       "8   Yes, you can run W&B offline. If your machine ...    0.159848   \n",
       "9   If you're experiencing network issues, such as...    0.458577   \n",
       "10  If the internet connection is lost while train...    0.042517   \n",
       "11  You can collect your API key by navigating to ...    0.247086   \n",
       "12  You can create a W&B Experiment in four steps:...    0.192479   \n",
       "13  You can log a table to a run using the followi...    0.560976   \n",
       "14  You can log a list of values by using the wand...    0.373377   \n",
       "15  Unfortunately, you cannot change the sweep con...    0.465587   \n",
       "16  Yes, you can flag boolean variables as hyperpa...    0.568588   \n",
       "17  After calling wandb.init(), you can access the...    0.340249   \n",
       "18  When wandb.init is called in your script, Weig...    0.348928   \n",
       "19  You can use \"/\" as a separator for organizing ...    0.269521   \n",
       "\n",
       "    levenshtein_score  rouge_score  bleu_score  meteor_score  similarity_score  \n",
       "0            0.519573     0.484375    0.273118      0.461614          0.690083  \n",
       "1            0.365688     0.196078    0.041005      0.100473          0.174637  \n",
       "2            0.374876     0.300000    0.035381      0.477273          0.511543  \n",
       "3            0.412281     0.606742    0.319642      0.389861          0.676034  \n",
       "4            0.518219     0.495050    0.278176      0.383771          0.587536  \n",
       "5            0.448198     0.325203    0.078870      0.300286          0.213999  \n",
       "6            0.451923     0.178571    0.201340      0.338727          0.436238  \n",
       "7            0.220149     0.114286    0.017058      0.026069          0.154099  \n",
       "8            0.561370     0.421875    0.213403      0.457613          0.699943  \n",
       "9            0.579079     0.551724    0.227293      0.698551          0.752566  \n",
       "10           0.416667     0.266667    0.033346      0.200566          0.379000  \n",
       "11           0.312354     0.206897    0.039934      0.150578          0.321100  \n",
       "12           0.397790     0.434568    0.097003      0.491812          0.617133  \n",
       "13           0.704065     0.582781    0.387109      0.731381          0.800844  \n",
       "14           0.509740     0.531250    0.321033      0.612899          0.720118  \n",
       "15           0.623482     0.558824    0.386743      0.779003          0.867619  \n",
       "16           0.588469     0.586207    0.261722      0.733173          0.629063  \n",
       "17           0.398340     0.222222    0.086747      0.235535          0.310222  \n",
       "18           0.680312     0.768116    0.649195      0.830568          0.894306  \n",
       "19           0.670025     0.678899    0.390531      0.749572          0.857729  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Overall Generation Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_score</th>\n",
       "      <th>levenshtein_score</th>\n",
       "      <th>rouge_score</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.48763</td>\n",
       "      <td>0.425517</td>\n",
       "      <td>0.216933</td>\n",
       "      <td>0.457466</td>\n",
       "      <td>0.564691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diff_score  levenshtein_score  rouge_score  bleu_score  meteor_score  \\\n",
       "0    0.257731            0.48763     0.425517    0.216933      0.457466   \n",
       "\n",
       "   similarity_score  \n",
       "0          0.564691  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Generation Score Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diff_score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>0.172215</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.141175</td>\n",
       "      <td>0.222101</td>\n",
       "      <td>0.374331</td>\n",
       "      <td>0.568588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levenshtein_score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.487630</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.220149</td>\n",
       "      <td>0.398203</td>\n",
       "      <td>0.480832</td>\n",
       "      <td>0.581427</td>\n",
       "      <td>0.704065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.425517</td>\n",
       "      <td>0.187632</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.459471</td>\n",
       "      <td>0.564813</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleu_score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.216933</td>\n",
       "      <td>0.166185</td>\n",
       "      <td>0.017058</td>\n",
       "      <td>0.069404</td>\n",
       "      <td>0.220348</td>\n",
       "      <td>0.319989</td>\n",
       "      <td>0.649195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meteor_score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.457466</td>\n",
       "      <td>0.244370</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.284098</td>\n",
       "      <td>0.459613</td>\n",
       "      <td>0.706758</td>\n",
       "      <td>0.830568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.564691</td>\n",
       "      <td>0.238078</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>0.364525</td>\n",
       "      <td>0.623098</td>\n",
       "      <td>0.728230</td>\n",
       "      <td>0.894306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean       std       min       25%       50%  \\\n",
       "diff_score          20.0  0.257731  0.172215  0.011261  0.141175  0.222101   \n",
       "levenshtein_score   20.0  0.487630  0.130090  0.220149  0.398203  0.480832   \n",
       "rouge_score         20.0  0.425517  0.187632  0.114286  0.255556  0.459471   \n",
       "bleu_score          20.0  0.216933  0.166185  0.017058  0.069404  0.220348   \n",
       "meteor_score        20.0  0.457466  0.244370  0.026069  0.284098  0.459613   \n",
       "similarity_score    20.0  0.564691  0.238078  0.154099  0.364525  0.623098   \n",
       "\n",
       "                        75%       max  \n",
       "diff_score         0.374331  0.568588  \n",
       "levenshtein_score  0.581427  0.704065  \n",
       "rouge_score        0.564813  0.768116  \n",
       "bleu_score         0.319989  0.649195  \n",
       "meteor_score       0.706758  0.830568  \n",
       "similarity_score   0.728230  0.894306  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response_scores_df = pd.DataFrame(response_scores)\n",
    "display(response_scores_df)\n",
    "\n",
    "GENERATION_METRICS = [col for col in response_scores_df.columns if \"score\" in col]\n",
    "\n",
    "\n",
    "print(\"\\nMean Overall Generation Scores:\")\n",
    "display(pd.DataFrame(response_scores_df[GENERATION_METRICS].mean()).T)\n",
    "\n",
    "print(\"\\nOverall Generation Score Statistics:\")\n",
    "display(pd.DataFrame(response_scores_df[GENERATION_METRICS].describe()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CORRECTNESS_EVAL_PROMPT =\"\"\"\n",
    "You are a Weight & Biases support expert tasked with evaluating the correctness of answers to questions asked by users to a technical support chatbot. \n",
    "You are tasked with judging the correctness of a generated answer based on the user's query, and a reference answer.\n",
    "\n",
    "You will be given the following information:\n",
    "\n",
    "<query>\n",
    "{query}\n",
    "</query>\n",
    "\n",
    "<reference_answer>\n",
    "{reference_answer}\n",
    "</reference_answer>\n",
    "\n",
    "<generated_answer>\n",
    "{generated_answer}\n",
    "</generated_answer>\n",
    "\n",
    "Important Instruction: To evaluate the generated answer, follow these steps:\n",
    "\n",
    "1. Intent Analysis: Consider the underlying intent of the query.\n",
    "2. Relevance: Check if the generated answer addresses all aspects of the question.\n",
    "3. Accuracy: Compare the generated answer to the reference answer for completeness and correctness.\n",
    "4. Trustworthiness: Measure how trustworthy the generated answer is when compared to the reference.\n",
    "\n",
    "Assign a score on an integer scale of 0 to 3 with the following meanings:\n",
    "- 0 = The generated answer is incorrect and does not satisfy any of the criteria.\n",
    "- 1 = The generated answer is partially correct, contains mistakes or is not factually correct.\n",
    "- 2 = The generated answer is correct but includes some extra information, is incomplete or misses some evaluation criteria.\n",
    "- 3 = The generated answer is correct, completely answers the query, does not contain any mistakes, and is factually consistent with the reference answer.\n",
    "\n",
    "After your analysis, provide your verdict in the following JSON format:\n",
    "\n",
    "{{\n",
    "    \"reason\": \"<<Provide a brief explanation for your decision here>>\",\n",
    "    \"final_score\": <<Provide a score as per the above guidelines>>,\n",
    "    \"decision\": \"<<Provide your final decision here, either 'correct' or 'incorrect'>>\"\n",
    "}}\n",
    "\n",
    "Here are some examples of correct output:\n",
    "\n",
    "Example 1:\n",
    "{{\n",
    "    \"reason\": \"The generated answer has the exact details as the reference answer and completely answers the user's query.\",\n",
    "    \"final_score\": 3,\n",
    "    \"decision\": \"correct\"\n",
    "}}\n",
    "\n",
    "Example 2:\n",
    "{{\n",
    "    \"reason\": \"The generated answer doesn't match the reference answer and deviates from the user's query.\",\n",
    "    \"final_score\": 0,\n",
    "    \"decision\": \"incorrect\"\n",
    "}}\n",
    "\n",
    "Example 3:\n",
    "{{\n",
    "    \"reason\": \"The generated answer follows the same steps as the reference answer. However, it includes assumptions about functions that are not requested in the user's query\",\n",
    "    \"final_score\": 2,\n",
    "    \"decision\": \"correct\"\n",
    "}}\n",
    "\n",
    "Example 4:\n",
    "{{\n",
    "    \"reason\": \"The generated answer is incorrect, irrelevant, and not factually correct and completely misses the user's intent.\",\n",
    "    \"final_score\": 0,\n",
    "    \"decision\": \"incorrect\"\n",
    "}}\n",
    "\n",
    "Please provide your evaluation based on the given information and format your response according to the specified JSON structure.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cohere.AsyncClient(api_key=os.environ[\"CO_API_KEY\"])\n",
    "\n",
    "async def evaluate_correctness_using_llm_judge(query: str, reference_answer: str, generated_answer: str) -> int:\n",
    "    response = await client.chat(\n",
    "        message=CORRECTNESS_EVAL_PROMPT.format(query=query, reference_answer=reference_answer, generated_answer=generated_answer),\n",
    "        model=\"command-r-plus\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_correctness_evaluation_using_llm(response_scores):\n",
    "    tasks = []\n",
    "    for row in response_scores:\n",
    "        query = row[\"query\"]\n",
    "        expected_answer = row[\"expected_answer\"]\n",
    "        generated_answer = row[\"actual_answer\"]\n",
    "        tasks.append(evaluate_correctness_using_llm_judge(query, expected_answer, generated_answer))\n",
    "    scores = await asyncio.gather(*tasks)\n",
    "    scores = list(map(json.loads, scores))\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_judge_correctness_results = asyncio.run(run_correctness_evaluation_using_llm(response_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>actual_answer</th>\n",
       "      <th>diff_score</th>\n",
       "      <th>levenshtein_score</th>\n",
       "      <th>rouge_score</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>reason</th>\n",
       "      <th>final_score</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between `.log()` and `....</td>\n",
       "      <td>The summary is the value that shows in the tab...</td>\n",
       "      <td>The summary is the value that shows in the tab...</td>\n",
       "      <td>0.142349</td>\n",
       "      <td>0.519573</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.273118</td>\n",
       "      <td>0.461614</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>The generated answer addresses the user's quer...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I switch between accounts on the same m...</td>\n",
       "      <td>If you have two W&amp;B accounts working from the ...</td>\n",
       "      <td>To switch between accounts on the same machine...</td>\n",
       "      <td>0.021068</td>\n",
       "      <td>0.365688</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>0.100473</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>The generated answer does not address the user...</td>\n",
       "      <td>0</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How is W&amp;B different from TensorBoard?</td>\n",
       "      <td>We love the TensorBoard folks, and we have a T...</td>\n",
       "      <td>Here are some ways in which W&amp;B (Weights &amp; Bia...</td>\n",
       "      <td>0.087273</td>\n",
       "      <td>0.374876</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.511543</td>\n",
       "      <td>The generated answer addresses the user's quer...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between team and organi...</td>\n",
       "      <td>A team is a collaborative workspace for a grou...</td>\n",
       "      <td>An organization is a high-level entity that ma...</td>\n",
       "      <td>0.377193</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.319642</td>\n",
       "      <td>0.389861</td>\n",
       "      <td>0.676034</td>\n",
       "      <td>The generated answer correctly explains the di...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the difference between team and entity...</td>\n",
       "      <td>A team is a collaborative workspace for a grou...</td>\n",
       "      <td>An entity refers to either a username or a tea...</td>\n",
       "      <td>0.137652</td>\n",
       "      <td>0.518219</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.278176</td>\n",
       "      <td>0.383771</td>\n",
       "      <td>0.587536</td>\n",
       "      <td>The generated answer correctly explains the di...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can I just log metrics, no code or dataset exa...</td>\n",
       "      <td>**Dataset Examples**\\n\\nBy default, we don't l...</td>\n",
       "      <td>Yes, you can just log metrics without providin...</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.448198</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.078870</td>\n",
       "      <td>0.300286</td>\n",
       "      <td>0.213999</td>\n",
       "      <td>The generated answer correctly addresses the u...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can I log a metric that doesn't change ove...</td>\n",
       "      <td>Using `wandb.log({'final_accuracy': 0.9}` will...</td>\n",
       "      <td>To log a metric that doesn't change over time,...</td>\n",
       "      <td>0.197115</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.201340</td>\n",
       "      <td>0.338727</td>\n",
       "      <td>0.436238</td>\n",
       "      <td>The generated answer provides the correct code...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How many runs to create per project?</td>\n",
       "      <td>We recommend you have roughly 10k runs per pro...</td>\n",
       "      <td>There is no specific number of runs to create ...</td>\n",
       "      <td>0.152985</td>\n",
       "      <td>0.220149</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.017058</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>The generated answer addresses the user's quer...</td>\n",
       "      <td>2</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can I run wandb offline?</td>\n",
       "      <td>If you're training on an offline machine and w...</td>\n",
       "      <td>Yes, you can run W&amp;B offline. If your machine ...</td>\n",
       "      <td>0.159848</td>\n",
       "      <td>0.561370</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.213403</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>0.699943</td>\n",
       "      <td>The generated answer correctly states that W&amp;B...</td>\n",
       "      <td>2</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do I deal with network issues?</td>\n",
       "      <td>If you're seeing SSL or network errors:`wandb:...</td>\n",
       "      <td>If you're experiencing network issues, such as...</td>\n",
       "      <td>0.458577</td>\n",
       "      <td>0.579079</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.227293</td>\n",
       "      <td>0.698551</td>\n",
       "      <td>0.752566</td>\n",
       "      <td>The generated answer addresses the user's quer...</td>\n",
       "      <td>2</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What happens if internet connection is lost wh...</td>\n",
       "      <td>If the wandb library is unable to connect to t...</td>\n",
       "      <td>If the internet connection is lost while train...</td>\n",
       "      <td>0.042517</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.200566</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>The generated answer correctly addresses the u...</td>\n",
       "      <td>2</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where do I find my API key?</td>\n",
       "      <td>Once you've signed in to www.wandb.ai, the API...</td>\n",
       "      <td>You can collect your API key by navigating to ...</td>\n",
       "      <td>0.247086</td>\n",
       "      <td>0.312354</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>0.150578</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>The generated answer correctly directs the use...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I create a W&amp;B Experiment?</td>\n",
       "      <td>Create a W&amp;B Experiment in four steps:\\n\\n1. [...</td>\n",
       "      <td>You can create a W&amp;B Experiment in four steps:...</td>\n",
       "      <td>0.192479</td>\n",
       "      <td>0.397790</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.097003</td>\n",
       "      <td>0.491812</td>\n",
       "      <td>0.617133</td>\n",
       "      <td>The generated answer provides a similar struct...</td>\n",
       "      <td>1</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Log a table to a run</td>\n",
       "      <td>Use `wandb.log()` to save your table to the ru...</td>\n",
       "      <td>You can log a table to a run using the followi...</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.704065</td>\n",
       "      <td>0.582781</td>\n",
       "      <td>0.387109</td>\n",
       "      <td>0.731381</td>\n",
       "      <td>0.800844</td>\n",
       "      <td>The generated answer provides the correct code...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do I log a list of values?</td>\n",
       "      <td>You can log a list of values iteratively, or ...</td>\n",
       "      <td>You can log a list of values by using the wand...</td>\n",
       "      <td>0.373377</td>\n",
       "      <td>0.509740</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.321033</td>\n",
       "      <td>0.612899</td>\n",
       "      <td>0.720118</td>\n",
       "      <td>The generated answer directly addresses the us...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Is there a way to add extra values to a sweep,...</td>\n",
       "      <td>You cannot change the Sweep configuration once...</td>\n",
       "      <td>Unfortunately, you cannot change the sweep con...</td>\n",
       "      <td>0.465587</td>\n",
       "      <td>0.623482</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.386743</td>\n",
       "      <td>0.779003</td>\n",
       "      <td>0.867619</td>\n",
       "      <td>The generated answer correctly captures the us...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Can we flag boolean variables as hyperparameters?</td>\n",
       "      <td>You can use the `${args_no_boolean_flags}` mac...</td>\n",
       "      <td>Yes, you can flag boolean variables as hyperpa...</td>\n",
       "      <td>0.568588</td>\n",
       "      <td>0.588469</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.261722</td>\n",
       "      <td>0.733173</td>\n",
       "      <td>0.629063</td>\n",
       "      <td>The generated answer correctly addresses the u...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do I programmatically access the human-rea...</td>\n",
       "      <td>It's available as the `.name` attribute of a `...</td>\n",
       "      <td>After calling wandb.init(), you can access the...</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.398340</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.086747</td>\n",
       "      <td>0.235535</td>\n",
       "      <td>0.310222</td>\n",
       "      <td>The generated answer correctly addresses the u...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How can I save the git commit associated with ...</td>\n",
       "      <td>When `wandb.init` is called in your script, we...</td>\n",
       "      <td>When wandb.init is called in your script, Weig...</td>\n",
       "      <td>0.348928</td>\n",
       "      <td>0.680312</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.649195</td>\n",
       "      <td>0.830568</td>\n",
       "      <td>0.894306</td>\n",
       "      <td>The generated answer correctly addresses the u...</td>\n",
       "      <td>3</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How can I organize my logged charts and media ...</td>\n",
       "      <td>We treat `/` as a separator for organizing log...</td>\n",
       "      <td>You can use \"/\" as a separator for organizing ...</td>\n",
       "      <td>0.269521</td>\n",
       "      <td>0.670025</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.390531</td>\n",
       "      <td>0.749572</td>\n",
       "      <td>0.857729</td>\n",
       "      <td>The generated answer correctly explains how to...</td>\n",
       "      <td>2</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   What is the difference between `.log()` and `....   \n",
       "1   How do I switch between accounts on the same m...   \n",
       "2              How is W&B different from TensorBoard?   \n",
       "3   What is the difference between team and organi...   \n",
       "4   What is the difference between team and entity...   \n",
       "5   Can I just log metrics, no code or dataset exa...   \n",
       "6   How can I log a metric that doesn't change ove...   \n",
       "7                How many runs to create per project?   \n",
       "8                            Can I run wandb offline?   \n",
       "9                  How do I deal with network issues?   \n",
       "10  What happens if internet connection is lost wh...   \n",
       "11                        Where do I find my API key?   \n",
       "12                  How do I create a W&B Experiment?   \n",
       "13                               Log a table to a run   \n",
       "14                     How do I log a list of values?   \n",
       "15  Is there a way to add extra values to a sweep,...   \n",
       "16  Can we flag boolean variables as hyperparameters?   \n",
       "17  How do I programmatically access the human-rea...   \n",
       "18  How can I save the git commit associated with ...   \n",
       "19  How can I organize my logged charts and media ...   \n",
       "\n",
       "                                      expected_answer  \\\n",
       "0   The summary is the value that shows in the tab...   \n",
       "1   If you have two W&B accounts working from the ...   \n",
       "2   We love the TensorBoard folks, and we have a T...   \n",
       "3   A team is a collaborative workspace for a grou...   \n",
       "4   A team is a collaborative workspace for a grou...   \n",
       "5   **Dataset Examples**\\n\\nBy default, we don't l...   \n",
       "6   Using `wandb.log({'final_accuracy': 0.9}` will...   \n",
       "7   We recommend you have roughly 10k runs per pro...   \n",
       "8   If you're training on an offline machine and w...   \n",
       "9   If you're seeing SSL or network errors:`wandb:...   \n",
       "10  If the wandb library is unable to connect to t...   \n",
       "11  Once you've signed in to www.wandb.ai, the API...   \n",
       "12  Create a W&B Experiment in four steps:\\n\\n1. [...   \n",
       "13  Use `wandb.log()` to save your table to the ru...   \n",
       "14   You can log a list of values iteratively, or ...   \n",
       "15  You cannot change the Sweep configuration once...   \n",
       "16  You can use the `${args_no_boolean_flags}` mac...   \n",
       "17  It's available as the `.name` attribute of a `...   \n",
       "18  When `wandb.init` is called in your script, we...   \n",
       "19  We treat `/` as a separator for organizing log...   \n",
       "\n",
       "                                        actual_answer  diff_score  \\\n",
       "0   The summary is the value that shows in the tab...    0.142349   \n",
       "1   To switch between accounts on the same machine...    0.021068   \n",
       "2   Here are some ways in which W&B (Weights & Bia...    0.087273   \n",
       "3   An organization is a high-level entity that ma...    0.377193   \n",
       "4   An entity refers to either a username or a tea...    0.137652   \n",
       "5   Yes, you can just log metrics without providin...    0.011261   \n",
       "6   To log a metric that doesn't change over time,...    0.197115   \n",
       "7   There is no specific number of runs to create ...    0.152985   \n",
       "8   Yes, you can run W&B offline. If your machine ...    0.159848   \n",
       "9   If you're experiencing network issues, such as...    0.458577   \n",
       "10  If the internet connection is lost while train...    0.042517   \n",
       "11  You can collect your API key by navigating to ...    0.247086   \n",
       "12  You can create a W&B Experiment in four steps:...    0.192479   \n",
       "13  You can log a table to a run using the followi...    0.560976   \n",
       "14  You can log a list of values by using the wand...    0.373377   \n",
       "15  Unfortunately, you cannot change the sweep con...    0.465587   \n",
       "16  Yes, you can flag boolean variables as hyperpa...    0.568588   \n",
       "17  After calling wandb.init(), you can access the...    0.340249   \n",
       "18  When wandb.init is called in your script, Weig...    0.348928   \n",
       "19  You can use \"/\" as a separator for organizing ...    0.269521   \n",
       "\n",
       "    levenshtein_score  rouge_score  bleu_score  meteor_score  \\\n",
       "0            0.519573     0.484375    0.273118      0.461614   \n",
       "1            0.365688     0.196078    0.041005      0.100473   \n",
       "2            0.374876     0.300000    0.035381      0.477273   \n",
       "3            0.412281     0.606742    0.319642      0.389861   \n",
       "4            0.518219     0.495050    0.278176      0.383771   \n",
       "5            0.448198     0.325203    0.078870      0.300286   \n",
       "6            0.451923     0.178571    0.201340      0.338727   \n",
       "7            0.220149     0.114286    0.017058      0.026069   \n",
       "8            0.561370     0.421875    0.213403      0.457613   \n",
       "9            0.579079     0.551724    0.227293      0.698551   \n",
       "10           0.416667     0.266667    0.033346      0.200566   \n",
       "11           0.312354     0.206897    0.039934      0.150578   \n",
       "12           0.397790     0.434568    0.097003      0.491812   \n",
       "13           0.704065     0.582781    0.387109      0.731381   \n",
       "14           0.509740     0.531250    0.321033      0.612899   \n",
       "15           0.623482     0.558824    0.386743      0.779003   \n",
       "16           0.588469     0.586207    0.261722      0.733173   \n",
       "17           0.398340     0.222222    0.086747      0.235535   \n",
       "18           0.680312     0.768116    0.649195      0.830568   \n",
       "19           0.670025     0.678899    0.390531      0.749572   \n",
       "\n",
       "    similarity_score                                             reason  \\\n",
       "0           0.690083  The generated answer addresses the user's quer...   \n",
       "1           0.174637  The generated answer does not address the user...   \n",
       "2           0.511543  The generated answer addresses the user's quer...   \n",
       "3           0.676034  The generated answer correctly explains the di...   \n",
       "4           0.587536  The generated answer correctly explains the di...   \n",
       "5           0.213999  The generated answer correctly addresses the u...   \n",
       "6           0.436238  The generated answer provides the correct code...   \n",
       "7           0.154099  The generated answer addresses the user's quer...   \n",
       "8           0.699943  The generated answer correctly states that W&B...   \n",
       "9           0.752566  The generated answer addresses the user's quer...   \n",
       "10          0.379000  The generated answer correctly addresses the u...   \n",
       "11          0.321100  The generated answer correctly directs the use...   \n",
       "12          0.617133  The generated answer provides a similar struct...   \n",
       "13          0.800844  The generated answer provides the correct code...   \n",
       "14          0.720118  The generated answer directly addresses the us...   \n",
       "15          0.867619  The generated answer correctly captures the us...   \n",
       "16          0.629063  The generated answer correctly addresses the u...   \n",
       "17          0.310222  The generated answer correctly addresses the u...   \n",
       "18          0.894306  The generated answer correctly addresses the u...   \n",
       "19          0.857729  The generated answer correctly explains how to...   \n",
       "\n",
       "    final_score   decision  \n",
       "0             3    correct  \n",
       "1             0  incorrect  \n",
       "2             3    correct  \n",
       "3             3    correct  \n",
       "4             3    correct  \n",
       "5             3    correct  \n",
       "6             3    correct  \n",
       "7             2    correct  \n",
       "8             2    correct  \n",
       "9             2    correct  \n",
       "10            2    correct  \n",
       "11            3    correct  \n",
       "12            1  incorrect  \n",
       "13            3    correct  \n",
       "14            3    correct  \n",
       "15            3    correct  \n",
       "16            3    correct  \n",
       "17            3    correct  \n",
       "18            3    correct  \n",
       "19            2    correct  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness_eval_df = pd.DataFrame(llm_judge_correctness_results)\n",
    "response_evals_df = pd.concat([response_scores_df, correctness_eval_df], axis=1)\n",
    "response_evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Judge Response Accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_judge_response_accuracy = (response_evals_df[\"decision\"] == \"correct\").sum()/len(response_evals_df)\n",
    "print(f\"LLM Judge Response Accuracy: {llm_judge_response_accuracy:.4f}\")\n",
    "response_evals_df['final_score'].value_counts().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
