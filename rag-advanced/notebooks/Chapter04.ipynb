{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "\n",
    "## Query Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import cohere\n",
    "import weave\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_ENTITY = \"rag-course\"\n",
    "WANDB_PROJECT = \"dev\"\n",
    "\n",
    "wandb.require(\"core\")\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=WANDB_ENTITY,\n",
    "    project=WANDB_PROJECT,\n",
    "    group=\"Chapter 4\",\n",
    ")\n",
    "\n",
    "\n",
    "weave_client = weave.init(f\"{WANDB_ENTITY}/{WANDB_PROJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data from Chapter 3\n",
    "chunked_artifact = run.use_artifact(\n",
    "    f\"{WANDB_ENTITY}/{WANDB_PROJECT}/chunked_data:latest\", type=\"dataset\"\n",
    ")\n",
    "artifact_dir = chunked_artifact.download()\n",
    "chunked_data_file = pathlib.Path(f\"{artifact_dir}/documents.jsonl\")\n",
    "chunked_data = list(map(json.loads, chunked_data_file.read_text().splitlines()))\n",
    "chunked_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The query enhancer will be used to identify the language, the intent of the query and generate search queries for retrieval\n",
    "# this additional information will be used to inform the response generator and improve the retrieval process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.query_enhancer import QueryEnhancer\n",
    "from scripts.utils import display_source\n",
    "\n",
    "query_enhancer = QueryEnhancer()\n",
    "display_source(query_enhancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_enhancer.predict(\"How do I log images in lightning with wandb?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the retriever remains the same\n",
    "\n",
    "from scripts.retriever import BM25Retriever\n",
    "retriever = BM25Retriever()\n",
    "retriever.index_data(chunked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to improve the Response generator to incorporate the new information from the query enhancer\n",
    "# such as adding in the language identification and the intent action to the prompt\n",
    "\n",
    "from scripts.response_generator import QueryEnhanedResponseGenerator\n",
    "display_source(QueryEnhanedResponseGenerator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.rag_pipeline import QueryEnhancedRAGPipeline\n",
    "display_source(QueryEnhancedRAGPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add the new prompt\n",
    "QUERY_ENHANCED_PROMPT = open(\"prompts/query_enhanced_system.txt\").read()\n",
    "\n",
    "response_generator = QueryEnhanedResponseGenerator(\n",
    "    model=\"command-r-plus\", prompt=QUERY_ENHANCED_PROMPT, client=cohere.AsyncClient()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarily we will also improve the rag pipeline to first call the query enhancer and the use the information\n",
    "# to include logic to aviod retrieval when the query is unrelated, needs more info, etc.\n",
    "# extract the language and intent actions so we can instruct the response generator to use them\n",
    "\n",
    "rag_pipeline = QueryEnhancedRAGPipeline(\n",
    "    query_enhancer=query_enhancer,\n",
    "    retriever=retriever,\n",
    "    response_generator=response_generator,\n",
    ")\n",
    "\n",
    "response = await rag_pipeline.predict(\"How do I log images in lightning with wandb?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = weave.ref(\n",
    "    \"weave:///rag-course/dev/object/Dataset:9O0EmmPINmYjgbXW3kucVrDxlTUQJQs0fVZYJj2mtOk\"\n",
    ").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.response_metrics import ALL_METRICS as RESPONSE_METRICS\n",
    "\n",
    "response_evaluations = weave.Evaluation(\n",
    "    name=\"Response_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=RESPONSE_METRICS,\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"]},\n",
    ")\n",
    "query_enhanced_response_scores = asyncio.run(\n",
    "    response_evaluations.evaluate(rag_pipeline)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
