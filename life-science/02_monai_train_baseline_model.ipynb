{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a51c32-6279-428d-90e8-96be4e4953c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U monai wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78244d6-353b-4dd8-aa51-d6a162ffbd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"brain-tumor-segmentation\",\n",
    "    entity=\"lifesciences\",\n",
    "    job_type=\"train_baseline\",\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e692b9-5f34-4d32-922b-836c92aee0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import set_determinism\n",
    "\n",
    "config.seed = 0\n",
    "set_determinism(seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534ed76-7b3e-4c66-8f5f-4358c8392472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.transforms import MapTransform\n",
    "\n",
    "\n",
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi-channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor), and ET (Enhancing tumor).\n",
    "\n",
    "    Reference: https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data_dict = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # merge label 2 and label 3 to construct Tumor Core\n",
    "            result.append(torch.logical_or(data_dict[key] == 2, data_dict[key] == 3))\n",
    "            # merge labels 1, 2 and 3 to construct Whole Tumor\n",
    "            result.append(\n",
    "                torch.logical_or(\n",
    "                    torch.logical_or(data_dict[key] == 2, data_dict[key] == 3),\n",
    "                    data_dict[key] == 1,\n",
    "                )\n",
    "            )\n",
    "            # label 2 is Enhancing Tumor\n",
    "            result.append(data_dict[key] == 2)\n",
    "            data_dict[key] = torch.stack(result, axis=0).float()\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d511f9-492f-4677-bd1f-e97156144e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "\n",
    "\n",
    "config.roi_size = [224, 224, 144]\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"], roi_size=config.roi_size, random_size=False\n",
    "        ),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce52f78-48d1-4b98-940c-c3cb31ecb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = wandb.use_artifact(\n",
    "    \"lifesciences/brain-tumor-segmentation/decathlon_brain_tumor:v0\", type=\"dataset\"\n",
    ")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ebc99-581b-4acc-853f-dab9c9772592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.apps import DecathlonDataset\n",
    "\n",
    "config.num_workers = 4\n",
    "\n",
    "train_dataset = DecathlonDataset(\n",
    "    root_dir=artifact_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    transform=val_transform,\n",
    "    section=\"training\",\n",
    "    download=False,\n",
    "    cache_rate=0.0,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "val_dataset = DecathlonDataset(\n",
    "    root_dir=artifact_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    transform=val_transform,\n",
    "    section=\"validation\",\n",
    "    download=False,\n",
    "    cache_rate=0.0,\n",
    "    num_workers=config.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2192be-3276-446e-b8c6-65324123a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import DataLoader\n",
    "\n",
    "# apply train_transforms to the training dataset\n",
    "train_dataset.transform = train_transform\n",
    "\n",
    "config.batch_size = 2\n",
    "\n",
    "# create the train_loader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "\n",
    "# create the val_loader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa76d0b-7e9b-4e2b-964e-ca9aada74eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import SegResNet\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "config.model_blocks_down = [1, 2, 2, 4]\n",
    "config.model_blocks_up = [1, 1, 1]\n",
    "config.model_init_filters = 16\n",
    "config.model_in_channels = 4\n",
    "config.model_out_channels = 3\n",
    "config.model_dropout_prob = 0.2\n",
    "\n",
    "# create model\n",
    "model = SegResNet(\n",
    "    blocks_down=config.model_blocks_down,\n",
    "    blocks_up=config.model_blocks_up,\n",
    "    init_filters=config.model_init_filters,\n",
    "    in_channels=config.model_in_channels,\n",
    "    out_channels=config.model_out_channels,\n",
    "    dropout_prob=config.model_dropout_prob,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aba9d-055c-45a8-93c8-5a27c8aab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.initial_learning_rate = 1e-4\n",
    "config.weight_decay = 1e-5\n",
    "config.max_train_epochs = 25\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    config.initial_learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "\n",
    "# create learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=config.max_train_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd11cb2-61a3-435f-9b89-986e459db757",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dice_loss_smoothen_numerator = 0\n",
    "config.dice_loss_smoothen_denominator = 1e-5\n",
    "config.dice_loss_squared_prediction = True\n",
    "config.dice_loss_target_onehot = False\n",
    "config.dice_loss_apply_sigmoid = True\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "loss_function = DiceLoss(\n",
    "    smooth_nr=config.dice_loss_smoothen_numerator,\n",
    "    smooth_dr=config.dice_loss_smoothen_denominator,\n",
    "    squared_pred=config.dice_loss_squared_prediction,\n",
    "    to_onehot_y=config.dice_loss_target_onehot,\n",
    "    sigmoid=config.dice_loss_apply_sigmoid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49cb10-7718-4147-9901-85ee59fbe8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4d531-1db1-4c29-9dfa-8e570665f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use automatic mixed-precision to accelerate training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb4253-3fcd-491d-a378-3a05b999cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "config.inference_roi_size = (240, 240, 160)\n",
    "\n",
    "\n",
    "def inference(model, input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=config.inference_roi_size,\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        return _compute(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de81064-3ef7-4cef-a5ed-6e1fd2733c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.define_metric(\"epoch/epoch_step\")\n",
    "wandb.define_metric(\"epoch/*\", step_metric=\"epoch/epoch_step\")\n",
    "wandb.define_metric(\"batch/batch_step\")\n",
    "wandb.define_metric(\"batch/*\", step_metric=\"batch/batch_step\")\n",
    "wandb.define_metric(\"validation/validation_step\")\n",
    "wandb.define_metric(\"validation/*\", step_metric=\"validation/validation_step\")\n",
    "\n",
    "batch_step = 0\n",
    "validation_step = 0\n",
    "metric_values = []\n",
    "metric_values_tumor_core = []\n",
    "metric_values_whole_tumor = []\n",
    "metric_values_enhanced_tumor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b71668-13c2-4414-9f76-c5d78b99d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from monai.data import decollate_batch\n",
    "\n",
    "config.validation_intervals = 1\n",
    "config.checkpoint_dir = \"./checkpoints\"\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "epoch_progress_bar = tqdm(range(config.max_train_epochs), desc=\"Training:\")\n",
    "\n",
    "for epoch in epoch_progress_bar:\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    total_batch_steps = len(train_dataset) // train_loader.batch_size\n",
    "    batch_progress_bar = tqdm(train_loader, total=total_batch_steps, leave=False)\n",
    "\n",
    "    # Training Step\n",
    "    for batch_data in batch_progress_bar:\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "        batch_progress_bar.set_description(f\"train_loss: {loss.item():.4f}:\")\n",
    "        ## Log batch-wise training loss to W&B\n",
    "        wandb.log({\"batch/batch_step\": batch_step, \"batch/train_loss\": loss.item()})\n",
    "        batch_step += 1\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= total_batch_steps\n",
    "    ## Log batch-wise training loss and learning rate to W&B\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"epoch/epoch_step\": epoch,\n",
    "            \"epoch/mean_train_loss\": epoch_loss,\n",
    "            \"epoch/learning_rate\": lr_scheduler.get_last_lr()[0],\n",
    "        }\n",
    "    )\n",
    "    epoch_progress_bar.set_description(f\"Training: train_loss: {epoch_loss:.4f}:\")\n",
    "\n",
    "    # Validation and model checkpointing step\n",
    "    if (epoch + 1) % config.validation_intervals == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                val_outputs = inference(model, val_inputs)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            metric_values.append(dice_metric.aggregate().item())\n",
    "            metric_batch = dice_metric_batch.aggregate()\n",
    "            metric_values_tumor_core.append(metric_batch[0].item())\n",
    "            metric_values_whole_tumor.append(metric_batch[1].item())\n",
    "            metric_values_enhanced_tumor.append(metric_batch[2].item())\n",
    "            dice_metric.reset()\n",
    "            dice_metric_batch.reset()\n",
    "\n",
    "            checkpoint_path = os.path.join(config.checkpoint_dir, \"model.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "            # Log and versison model checkpoints using W&B artifacts.\n",
    "            wandb.log_model(\n",
    "                checkpoint_path,\n",
    "                name=f\"{wandb.run.id}-checkpoint\",\n",
    "                aliases=[f\"epoch_{epoch}\"],\n",
    "            )\n",
    "\n",
    "            # Log validation metrics to W&B dashboard.\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"validation/validation_step\": validation_step,\n",
    "                    \"validation/mean_dice\": metric_values[-1],\n",
    "                    \"validation/mean_dice_tumor_core\": metric_values_tumor_core[-1],\n",
    "                    \"validation/mean_dice_whole_tumor\": metric_values_whole_tumor[-1],\n",
    "                    \"validation/mean_dice_enhanced_tumor\": metric_values_enhanced_tumor[-1],\n",
    "                }\n",
    "            )\n",
    "            validation_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeee85-8a37-4a85-8808-e12fcb5c7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
