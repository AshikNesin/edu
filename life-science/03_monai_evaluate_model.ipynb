{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Bain Tumor Segmentation Data\n",
    "\n",
    "In this notebook we will learn:\n",
    "- how we can evaluate a pre-trained model checkpoint for brain tumor segmentation using MONAI and Weights & Biases.\n",
    "- how we can visually compare the ground-truth labels with the predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ´ Setup and Installation\n",
    "\n",
    "First, let us install the latest version of both MONAI and Weights and Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U monai wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ³ Initialize a W&B Run\n",
    "\n",
    "We will start a new W&B run to start tracking our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"brain-tumor-segmentation\",\n",
    "    entity=\"lifesciences\",\n",
    "    job_type=\"evaluate\"\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import set_determinism\n",
    "\n",
    "config.seed = 0\n",
    "set_determinism(seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¿ Loading and Transforming the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ConvertToMultiChannelBasedOnBratsClassesd\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "\n",
    "\n",
    "transforms = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # Ensure loaded images are in channels-first format\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        # Ensure the input data to be a PyTorch Tensor or numpy array\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        # Convert labels to multi-channels based on brats18 classes\n",
    "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        # Change the input imageâ€™s orientation into the specified based on axis codes\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Resample the input images to the specified pixel dimension\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        # Normalize input image intensity\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.apps import DecathlonDataset\n",
    "\n",
    "\n",
    "artifact = wandb.use_artifact(\n",
    "    \"lifesciences/brain-tumor-segmentation/decathlon_brain_tumor:latest\", type=\"dataset\"\n",
    ")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Create the dataset for the test split\n",
    "# of the brain tumor segmentation dataset\n",
    "val_dataset = DecathlonDataset(\n",
    "    root_dir=artifact_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    transform=transforms,\n",
    "    section=\"validation\",\n",
    "    download=False,\n",
    "    cache_rate=0.0,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.networks.nets import SegResNet\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "config.model_blocks_down = [1, 2, 2, 4]\n",
    "config.model_blocks_up = [1, 1, 1]\n",
    "config.model_init_filters = 16\n",
    "config.model_in_channels = 4\n",
    "config.model_out_channels = 3\n",
    "config.model_dropout_prob = 0.2\n",
    "\n",
    "# create model\n",
    "model = SegResNet(\n",
    "    blocks_down=config.model_blocks_down,\n",
    "    blocks_up=config.model_blocks_up,\n",
    "    init_filters=config.model_init_filters,\n",
    "    in_channels=config.model_in_channels,\n",
    "    out_channels=config.model_out_channels,\n",
    "    dropout_prob=config.model_dropout_prob,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_artifact = wandb.use_artifact(\n",
    "    \"lifesciences/brain-tumor-segmentation/8vmqcqao-checkpoint:latest\",\n",
    "    type=\"model\",\n",
    ")\n",
    "model_artifact_dir = model_artifact.download()\n",
    "model.load_state_dict(torch.load(os.path.join(model_artifact_dir, \"model.pth\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "config.inference_roi_size = (240, 240, 160)\n",
    "\n",
    "\n",
    "def inference(model, input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=config.inference_roi_size,\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        return _compute(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Activations, AsDiscrete\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "postprocessing_transforms = Compose(\n",
    "    [Activations(sigmoid=True), AsDiscrete(threshold=0.5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_target_area_percentage(segmentation_map):\n",
    "    segmentation_map_list = segmentation_map.flatten().tolist()\n",
    "    return segmentation_map_list.count(1.0) * 100 / len(segmentation_map_list)\n",
    "\n",
    "\n",
    "def log_predictions_into_tables(\n",
    "    sample_image,\n",
    "    sample_label,\n",
    "    predicted_label,\n",
    "    split: str = None,\n",
    "    data_idx: int = None,\n",
    "    table: wandb.Table = None,\n",
    "):\n",
    "    sample_image = sample_image.cpu().numpy()\n",
    "    sample_label = sample_label.cpu().numpy()\n",
    "    predicted_label = predicted_label.cpu().numpy()\n",
    "    _, _, _, num_slices = sample_image.shape\n",
    "    with tqdm(total=num_slices, leave=False) as progress_bar:\n",
    "        for slice_idx in range(num_slices):\n",
    "            wandb_images = [\n",
    "                wandb.Image(\n",
    "                    sample_image[0, :, :, slice_idx],\n",
    "                    masks={\n",
    "                        \"ground-truth/Tumor-Core\": {\n",
    "                            \"mask_data\": sample_label[0, :, :, slice_idx],\n",
    "                            \"class_labels\": {0: \"background\", 1: \"Tumor Core\"},\n",
    "                        },\n",
    "                        \"prediction/Tumor-Core\": {\n",
    "                            \"mask_data\": predicted_label[0, :, :, slice_idx] * 2,\n",
    "                            \"class_labels\": {0: \"background\", 2: \"Tumor Core\"},\n",
    "                        },\n",
    "                    },\n",
    "                ),\n",
    "                wandb.Image(\n",
    "                    sample_image[0, :, :, slice_idx],\n",
    "                    masks={\n",
    "                        \"ground-truth/Whole-Tumor\": {\n",
    "                            \"mask_data\": sample_label[1, :, :, slice_idx],\n",
    "                            \"class_labels\": {0: \"background\", 1: \"Whole Tumor\"},\n",
    "                        },\n",
    "                        \"prediction/Whole-Tumor\": {\n",
    "                            \"mask_data\": predicted_label[1, :, :, slice_idx] * 2,\n",
    "                            \"class_labels\": {0: \"background\", 2: \"Whole Tumor\"},\n",
    "                        },\n",
    "                    },\n",
    "                ),\n",
    "                wandb.Image(\n",
    "                    sample_image[0, :, :, slice_idx],\n",
    "                    masks={\n",
    "                        \"ground-truth/Enhancing-Tumor\": {\n",
    "                            \"mask_data\": sample_label[2, :, :, slice_idx],\n",
    "                            \"class_labels\": {0: \"background\", 1: \"Enhancing Tumor\"},\n",
    "                        },\n",
    "                        \"prediction/Enhancing-Tumor\": {\n",
    "                            \"mask_data\": predicted_label[2, :, :, slice_idx] * 2,\n",
    "                            \"class_labels\": {0: \"background\", 2: \"Enhancing Tumor\"},\n",
    "                        },\n",
    "                    },\n",
    "                ),\n",
    "            ]\n",
    "            tumor_area_percentage = {\n",
    "                \"Ground-Truth\": {\n",
    "                    \"Tumor-Core-Area-Percentage\": get_target_area_percentage(\n",
    "                        sample_label[0, :, :, slice_idx]\n",
    "                    ),\n",
    "                    \"Whole-Tumor-Area-Percentage\": get_target_area_percentage(\n",
    "                        sample_label[1, :, :, slice_idx]\n",
    "                    ),\n",
    "                    \"Enhancing-Tumor-Area-Percentage\": get_target_area_percentage(\n",
    "                        sample_label[2, :, :, slice_idx]\n",
    "                    ),\n",
    "                },\n",
    "                \"Prediction\": {\n",
    "                    \"Tumor-Core-Area-Percentage\": get_target_area_percentage(\n",
    "                        predicted_label[0, :, :, slice_idx]\n",
    "                    ),\n",
    "                    \"Whole-Tumor-Area-Percentage\": get_target_area_percentage(\n",
    "                        predicted_label[1, :, :, slice_idx]\n",
    "                    ),\n",
    "                    \"Enhancing-Tumor-Area-Percentage\": get_target_area_percentage(\n",
    "                        predicted_label[2, :, :, slice_idx]\n",
    "                    ),\n",
    "                },\n",
    "            }\n",
    "            table.add_data(\n",
    "                split, data_idx, slice_idx, tumor_area_percentage, *wandb_images\n",
    "            )\n",
    "            progress_bar.update(1)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prediction table\n",
    "prediction_table = wandb.Table(\n",
    "    columns=[\n",
    "        \"Split\",\n",
    "        \"Data Index\",\n",
    "        \"Slice Index\",\n",
    "        \"Tumor-Area-Pixel-Percentage\",\n",
    "        \"Prediction/Tumor-Core\",\n",
    "        \"Prediction/Whole-Tumor\",\n",
    "        \"Prediction/Enhancing-Tumor\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "config.max_prediction_images_visualized = 1\n",
    "\n",
    "# Perform inference and visualization\n",
    "with torch.no_grad():\n",
    "    config.max_prediction_images_visualized\n",
    "    max_samples = (\n",
    "        min(config.max_prediction_images_visualized, len(val_dataset))\n",
    "        if config.max_prediction_images_visualized > 0\n",
    "        else len(val_dataset)\n",
    "    )\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(val_dataset[:max_samples]),\n",
    "        total=max_samples,\n",
    "        desc=\"Generating Predictions:\",\n",
    "    )\n",
    "    for data_idx, sample in progress_bar:\n",
    "        test_input, test_labels = (\n",
    "            torch.unsqueeze(sample[\"image\"], 0).to(device),\n",
    "            torch.unsqueeze(sample[\"label\"], 0).to(device),\n",
    "        )\n",
    "        test_output = inference(model, test_input)\n",
    "        test_output = postprocessing_transforms(test_output[0])\n",
    "        prediction_table = log_predictions_into_tables(\n",
    "            sample_image=sample[\"image\"],\n",
    "            sample_label=sample[\"label\"],\n",
    "            predicted_label=test_output,\n",
    "            data_idx=data_idx,\n",
    "            split=\"validation\",\n",
    "            table=prediction_table,\n",
    "        )\n",
    "\n",
    "    wandb.log({\"Evaluation/Tumor-Segmentation-Prediction\": prediction_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the experiment\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
