{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b11cdc8b"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch-lightning/Optimize_Pytorch_Lightning_models_with_Weights_&_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{pytorch-lightning-colab} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvc1aywAZb3"
      },
      "source": [
        "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<!--- @wandbcode{pytorch-lightning-colab} -->\n",
        "\n",
        "## Model Registry Tutorial\n",
        "The model registry is a central place to house and organize all the model tasks and their associated artifacts being worked on across an org:\n",
        "- Model checkpoint management\n",
        "- Document your models with rich model cards\n",
        "- Maintain a history of all the models being used/deployed\n",
        "- Facilitate clean hand-offs and stage management of models\n",
        "- Tag and organize various model tasks\n",
        "- Set up automatic notifications when models progress\n",
        "\n",
        "This tutorial will walkthrough how to track the model development lifecycle for a simple image classification task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stprDNedAZb4"
      },
      "source": [
        "### 🛠️ Install `wandb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MqWme-pAZb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0e5e2a-8747-4473-a8a0-760702a1e885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wandb onnx pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBTwaNGPAZb7"
      },
      "source": [
        "## Login to W&B\n",
        "- You can explicitly login using `wandb login` or `wandb.login()` (See below)\n",
        "- Alternatively you can set environment variables. There are several env variables which you can set to change the behavior of W&B logging. The most important are:\n",
        "    - `WANDB_API_KEY` - find this in your \"Settings\" section under your profile\n",
        "    - `WANDB_BASE_URL` - this is the url of the W&B server\n",
        "- Find your API Token in \"Profile\" -> \"Setttings\" in the W&B App\n",
        "\n",
        "![api_token](https://drive.google.com/uc?export=view&id=1Xn7hnn0rfPu_EW0A_-32oCXqDmpA0-kx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_BASE_URL'] = \"https://staging-aws.wandb.io/\"\n",
        "os.environ['WANDB_API_KEY'] = \"local-4e91040ae01217f2e4bda71a609f39585853cbbe\""
      ],
      "metadata": {
        "id": "Yp1Ot0SmGGlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTywCvZIpwb2",
        "outputId": "74f3de55-e579-4346-fe44-b0fe51dfd3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenleewb\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5chx7ARAZb9"
      },
      "source": [
        "## Log Data and Model Checkpoints as Artifacts  \n",
        "W&B Artifacts allows you to track and version arbitrary serialized data (e.g. datasets, model checkpoints, evaluation results). When you create an artifact, you give it a name and a type, and that artifact is forever linked to the experimental system of record. If the underlying data changes, and you log that data asset again, W&B will automatically create new versions through checksummming its contents. W&B Artifacts can be thought of as a lightweight abstraction layer on top of shared unstructured file systems.\n",
        "\n",
        "### Anatomy of an artifact\n",
        "\n",
        "The `Artifact` class will correspond to an entry in the W&B Artifact registry.  The artifact has\n",
        "* a name\n",
        "* a type\n",
        "* metadata\n",
        "* description\n",
        "* files, directory of files, or references\n",
        "\n",
        "Example usage:\n",
        "```\n",
        "run = wandb.init(project = \"my-project\")\n",
        "artifact = wandb.Artifact(name = \"my_artifact\", type = \"data\")\n",
        "artifact.add_file(\"/path/to/my/file.txt\")\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "```\n",
        "\n",
        "In this tutorial, the first thing we will do is download a training dataset and log it as an artifact to be used downstream in the training job."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter your W&B project and entity\n",
        "\n",
        "# FORM VARIABLES\n",
        "PROJECT_NAME = \"model-registry-walkthrough\" #@param {type:\"string\"}\n",
        "ENTITY = \"smle-machine\"#@param {type:\"string\"}\n",
        "\n",
        "# set SIZE to \"TINY\", \"SMALL\", \"MEDIUM\", or \"LARGE\"\n",
        "# to select one of these three datasets\n",
        "# TINY dataset: 100 images, 30MB\n",
        "# SMALL dataset: 1000 images, 312MB\n",
        "# MEDIUM dataset: 5000 images, 1.5GB\n",
        "# LARGE dataset: 12,000 images, 3.6GB\n",
        "\n",
        "SIZE = \"TINY\"\n",
        "\n",
        "if SIZE == \"TINY\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
        "  src_zip = \"nature_100.zip\"\n",
        "  DATA_SRC = \"nature_100\"\n",
        "  IMAGES_PER_LABEL = 10\n",
        "  BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
        "elif SIZE == \"SMALL\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_1K.zip\"\n",
        "  src_zip = \"nature_1K.zip\"\n",
        "  DATA_SRC = \"nature_1K\"\n",
        "  IMAGES_PER_LABEL = 100\n",
        "  BALANCED_SPLITS = {\"train\" : 80, \"val\" : 10, \"test\": 10}\n",
        "elif SIZE == \"MEDIUM\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "  src_zip = \"nature_12K.zip\"\n",
        "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
        "  IMAGES_PER_LABEL = 500\n",
        "  BALANCED_SPLITS = {\"train\" : 400, \"val\" : 50, \"test\": 50}\n",
        "elif SIZE == \"LARGE\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "  src_zip = \"nature_12K.zip\"\n",
        "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
        "  IMAGES_PER_LABEL = 1000\n",
        "  BALANCED_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}"
      ],
      "metadata": {
        "id": "IX1H-FaMljWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!curl -SL $src_url > $src_zip\n",
        "!unzip $src_zip"
      ],
      "metadata": {
        "id": "M-5VTcSblqrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "with wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type='log_datasets') as run:\n",
        "  img_paths = []\n",
        "  for root, dirs, files in os.walk('nature_100', topdown=False):\n",
        "    for name in files:\n",
        "        img_path = os.path.join(root, name)\n",
        "        label = img_path.split('/')[1]\n",
        "        img_paths.append([img_path, label])\n",
        "\n",
        "  index_df = pd.DataFrame(columns=['image_path', 'label'], data=img_paths)\n",
        "  index_df.to_csv('index.csv', index=False)\n",
        "\n",
        "  train_art = wandb.Artifact(name='Nature_100', type='raw_images', description='nature image dataset with 10 classes, 10 images per class')\n",
        "  train_art.add_dir('nature_100')\n",
        "\n",
        "  # Also adding a csv indicating the labels of each image\n",
        "  train_art.add_file('index.csv')\n",
        "  wandb.log_artifact(train_art)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "StZxJQAdtQwP",
        "outputId": "a18d7054-17b8-44d6-9805-c7e488b8ea58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenleewb\u001b[0m (\u001b[33msmle-machine\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230914_145025-wxorcukj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/wxorcukj' target=\"_blank\">rural-sunset-19</a></strong> to <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/wxorcukj' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/wxorcukj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./nature_100)... Done. 0.2s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rural-sunset-19</strong> at: <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/wxorcukj' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/wxorcukj</a><br/> View job at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI4NTM=/version_details/v3' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI4NTM=/version_details/v3</a><br/>Synced 5 W&B file(s), 0 media file(s), 105 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230914_145025-wxorcukj/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Artifact names and aliases to easily hand-off and abstract data assets\n",
        "- By simply referring to the `name:alias` combination of a dataset or model, we can better standardize components of a workflow\n",
        "- For instance, you can build PyTorch `Dataset`'s or `DataModule`'s which take as arguments W&B Artifact names and aliases to load appropriately\n",
        "\n",
        "You can now see all the metadata associated with this dataset, the W&B runs consuming it, and the whole lineage of upstream and downstream artifacts!\n",
        "\n",
        "![api_token](https://drive.google.com/uc?export=view&id=1fEEddXMkabgcgusja0g8zMz8whlP2Y5P)"
      ],
      "metadata": {
        "id": "QIvbYD0RyF9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from skimage import io, transform\n",
        "from torchvision import transforms, utils, models\n",
        "import math\n",
        "\n",
        "class NatureDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 wandb_run,\n",
        "                 artifact_name_alias=\"Nature_100:latest\",\n",
        "                 local_target_dir=\"Nature_100:latest\",\n",
        "                 transform=None):\n",
        "        self.local_target_dir = local_target_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Pull down the artifact locally to load it into memory\n",
        "        art = wandb_run.use_artifact(artifact_name_alias)\n",
        "        path_at = art.download(root=self.local_target_dir)\n",
        "\n",
        "        self.ref_df = pd.read_csv(os.path.join(self.local_target_dir, 'index.csv'))\n",
        "        self.class_names = self.ref_df.iloc[:, 1].unique().tolist()\n",
        "        self.idx_to_class = {k: v for k, v in enumerate(self.class_names)}\n",
        "        self.class_to_idx = {v: k for k, v in enumerate(self.class_names)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ref_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_path = self.ref_df.iloc[idx, 0]\n",
        "\n",
        "        image = io.imread(img_path)\n",
        "        label = self.ref_df.iloc[idx, 1]\n",
        "        label = torch.tensor(self.class_to_idx[label], dtype=torch.long)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class NatureDatasetModule(pl.LightningDataModule):\n",
        "    def __init__(self,\n",
        "                 wandb_run,\n",
        "                 artifact_name_alias: str = \"Nature_100:latest\",\n",
        "                 local_target_dir: str = \"Nature_100:latest\",\n",
        "                 batch_size: int = 16,\n",
        "                 input_size: int = 224,\n",
        "                 seed: int = 42):\n",
        "        super().__init__()\n",
        "        self.wandb_run = wandb_run\n",
        "        self.artifact_name_alias = artifact_name_alias\n",
        "        self.local_target_dir = local_target_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.seed = seed\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.nature_dataset = NatureDataset(wandb_run=self.wandb_run,\n",
        "                                            artifact_name_alias=self.artifact_name_alias,\n",
        "                                            local_target_dir=self.local_target_dir,\n",
        "                                            transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                          transforms.CenterCrop(self.input_size),\n",
        "                                                                          transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                                                                                               (0.229, 0.224, 0.225))]))\n",
        "\n",
        "        nature_length = len(self.nature_dataset)\n",
        "        train_size = math.floor(0.8 * nature_length)\n",
        "        val_size = math.floor(0.2 * nature_length)\n",
        "        self.nature_train, self.nature_val = random_split(self.nature_dataset,\n",
        "                                                          [train_size, val_size],\n",
        "                                                          generator=torch.Generator().manual_seed(self.seed))\n",
        "        return self\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.nature_train, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.nature_val, batch_size=self.batch_size)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        pass\n",
        "\n",
        "    def teardown(self, stage: str):\n",
        "        pass"
      ],
      "metadata": {
        "id": "v2YlZzi8moc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "Xl38Rty61Zwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing the Model Class and Validation Function"
      ],
      "metadata": {
        "id": "zI8jfFe_2k9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import onnx\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = torch.nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = torch.nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = torch.nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = torch.nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "class NaturePyTorchModule(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_name,\n",
        "                 num_classes=10,\n",
        "                 feature_extract=True,\n",
        "                 lr=0.01):\n",
        "        '''method used to define our model parameters'''\n",
        "        super().__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.num_classes = num_classes\n",
        "        self.feature_extract = feature_extract\n",
        "        self.lr = lr\n",
        "        self.model, self.input_size = initialize_model(model_name=self.model_name,\n",
        "                                                       num_classes=self.num_classes,\n",
        "                                                       feature_extract=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''method used for inference input -> output'''\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def evaluate_model(model, eval_data, idx_to_class, class_names, epoch_ndx):\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    preds = []\n",
        "    actual = []\n",
        "\n",
        "    val_table = wandb.Table(columns=['pred', 'actual', 'image'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in eval_data:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(\n",
        "                output, target, reduction=\"sum\"\n",
        "            ).item()  # sum up batch loss\n",
        "            pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "            preds += list(pred.flatten().tolist())\n",
        "            actual += target.numpy().tolist()\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            for idx, img in enumerate(data):\n",
        "                img = img.numpy().transpose(1, 2, 0)\n",
        "                pred_class = idx_to_class[pred.numpy()[idx][0]]\n",
        "                target_class = idx_to_class[target.numpy()[idx]]\n",
        "                val_table.add_data(pred_class, target_class, wandb.Image(img))\n",
        "\n",
        "    test_loss /= len(eval_data.dataset)\n",
        "    accuracy = 100.0 * correct / len(eval_data.dataset)\n",
        "    conf_mat = wandb.plot.confusion_matrix(y_true=actual, preds=preds, class_names=class_names)\n",
        "    return test_loss, accuracy, preds, val_table, conf_mat"
      ],
      "metadata": {
        "id": "f04KD3i5rCq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging Model Checkpoints as part of your Training Loop\n",
        "W&B Artifacts enables users to log and version large serialized files, such as model checkpoints.\n",
        "\n",
        "The `Artifact` class can encapsulate arbitrary files and directories.  The artifact has\n",
        "* a name\n",
        "* a type\n",
        "* metadata\n",
        "* description\n",
        "* files, directory of files, or references to external object stores (e.g. s3)\n",
        "\n",
        "Example usage:\n",
        "```\n",
        "run = wandb.init(project = \"my-project\")\n",
        "artifact = wandb.Artifact(name = \"my_artifact\", type = \"model\")\n",
        "artifact.add_file(\"/path/to/my/file.txt\")\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "WgaXzVaLtoQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%wandb -h 600\n",
        "\n",
        "run = wandb.init(project=PROJECT_NAME,\n",
        "                entity=ENTITY,\n",
        "                job_type='training',\n",
        "                config={'model_type': 'squeezenet',\n",
        "                        'lr': 1.0,\n",
        "                        'gamma': 0.75,\n",
        "                        'batch_size': 16,\n",
        "                        'epochs': 5})\n",
        "\n",
        "model = NaturePyTorchModule(wandb.config['model_type'])\n",
        "wandb.watch(model)\n",
        "\n",
        "wandb.config['input_size'] = 224\n",
        "\n",
        "nature_module = NatureDatasetModule(wandb_run = run,\n",
        "                                    artifact_name_alias=\"Nature_100:latest\",\n",
        "                                    local_target_dir=\"Nature_100:latest\",\n",
        "                                    batch_size=wandb.config['batch_size'],\n",
        "                                    input_size=wandb.config['input_size'])\n",
        "nature_module.setup()\n",
        "\n",
        "# Train the model\n",
        "learning_rate = wandb.config[\"lr\"]\n",
        "gamma = wandb.config[\"gamma\"]\n",
        "epochs = wandb.config[\"epochs\"]\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=wandb.config['lr'])\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=wandb.config['gamma'])\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "best_model = None\n",
        "\n",
        "for epoch_ndx in range(epochs):\n",
        "  model.train()\n",
        "  for batch_ndx, batch in enumerate(nature_module.train_dataloader()):\n",
        "      data, target = batch[0].to(\"cpu\"), batch[1].to(\"cpu\")\n",
        "      optimizer.zero_grad()\n",
        "      preds = model(data)\n",
        "      loss = F.nll_loss(preds, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      ### Log your metrics ###\n",
        "      wandb.log({\n",
        "          \"train/epoch_ndx\": epoch_ndx,\n",
        "          \"train/batch_ndx\": batch_ndx,\n",
        "          \"train/train_loss\": loss,\n",
        "          \"train/learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
        "      })\n",
        "\n",
        "  ### Evaluation at the end of each epoch ###\n",
        "  model.eval()\n",
        "  test_loss, accuracy, preds, val_table, conf_mat = evaluate_model(model,\n",
        "                                                                  nature_module.val_dataloader(),\n",
        "                                                                  nature_module.nature_dataset.idx_to_class,\n",
        "                                                                  nature_module.nature_dataset.class_names,\n",
        "                                                                  epoch_ndx)\n",
        "\n",
        "  is_best = test_loss < best_loss\n",
        "\n",
        "  wandb.log({'eval/test_loss': test_loss,\n",
        "              'eval/accuracy': accuracy,\n",
        "              'eval/conf_mat': conf_mat,\n",
        "              'eval/val_table': val_table})\n",
        "\n",
        "  ### Checkpoing your model weights ###\n",
        "  x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
        "  torch.onnx.export(model,              # model being run\n",
        "            x,                         # model input (or a tuple for multiple inputs)\n",
        "            \"model.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "            export_params=True,        # store the trained parameter weights inside the model file\n",
        "            opset_version=10,          # the ONNX version to export the model to\n",
        "            do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "            input_names = ['input'],   # the model's input names\n",
        "            output_names = ['output'], # the model's output names\n",
        "            dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                          'output' : {0 : 'batch_size'}})\n",
        "\n",
        "  art = wandb.Artifact(f\"anomaly-classifier-{wandb.run.id}\",\n",
        "                        type=\"model\",\n",
        "                        metadata={'format': 'onnx',\n",
        "                                'num_classes': len(nature_module.nature_dataset.class_names),\n",
        "                                'model_type': wandb.config['model_type'],\n",
        "                                'model_input_size': wandb.config['input_size'],\n",
        "                                'index_to_class': nature_module.nature_dataset.idx_to_class})\n",
        "\n",
        "  art.add_file(\"model.onnx\")\n",
        "\n",
        "  ### Add aliases to keep track of your best checkpoints over time\n",
        "  wandb.log_artifact(art, aliases=[\"best\", \"latest\"] if is_best else None)\n",
        "  if is_best:\n",
        "      best_model = art"
      ],
      "metadata": {
        "id": "wTb1Ueh-rKGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manage all your model checkpoints for a project under one roof.\n",
        "\n",
        "![api_token](https://drive.google.com/uc?export=view&id=1z7nXRgqHTPYjfR1SoP-CkezyxklbAZlM)"
      ],
      "metadata": {
        "id": "SqJULhh4zoBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Registered Models and Linking through the **API**\n",
        "You can [link a model via api](https://docs.wandb.ai/guides/models) with `wandb.run.link_artifact` passing in the artifact object, and the name of the **Registered Model**, along with aliases you want to append to it. **Registered Models** are entity (team) scoped in W&B so only members of a team can see and access the **Registered Models** there. You indicate a registered model name via api with `<entity>/model-registry/<registered-model-name>`. If a Registered Model doesn't exist, one will be created automatically."
      ],
      "metadata": {
        "id": "pft_kO36AhSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.run.link_artifact(best_model, 'wandb/model-registry/Model Registry Tutorial', aliases=['staging'])\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "GKlZqzRU8UEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "b05d7402-20b5-4d1f-c475-5ab678c0f017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifact TTL will be disabled for source artifacts that are linked to portfolios.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>eval/test_loss</td><td>█▃▁▁▁</td></tr><tr><td>train/batch_ndx</td><td>▁▃▅▆█▁▃▅▆█▁▃▅▆█▁▃▅▆█▁▃▅▆█</td></tr><tr><td>train/epoch_ndx</td><td>▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_loss</td><td>█▇▇▆▆▃▃▄▃▄▂▁▃▂▃▁▁▃▂▃▁▁▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>5.0</td></tr><tr><td>eval/test_loss</td><td>-6.36682</td></tr><tr><td>train/batch_ndx</td><td>4</td></tr><tr><td>train/epoch_ndx</td><td>4</td></tr><tr><td>train/learning_rate</td><td>0.00075</td></tr><tr><td>train/train_loss</td><td>-7.18066</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peachy-forest-2</strong> at: <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/e1c0ilbw' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/e1c0ilbw</a><br/> View job at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI4NTM=/version_details/v1' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI4NTM=/version_details/v1</a><br/>Synced 5 W&B file(s), 10 media file(s), 32 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230907_164758-e1c0ilbw/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consuming a Registered Model\n",
        "You now can consume any registered model via API by referring the corresponding `name:alias`. Model consumers, whether they are engineers, researchers, or CI/CD processes, can go to the model registry as the central hub for all models that should \"see the light of day\": those that need to go through testing or move to production."
      ],
      "metadata": {
        "id": "yqASj5fUweUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%wandb -h 600\n",
        "\n",
        "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type='inference')\n",
        "artifact = run.use_artifact('wandb/model-registry/Model Registry Tutorial:staging', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "l_rldM-T3cA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "47b59dcff902431089de4456b66f7f06",
            "12f9885246ac45629e53dddc6fb8f174",
            "53c72207fd38467b859032dc19a04fe8",
            "76f66f2192e74c39ad9549afcc755d8f",
            "752dfc1538d443c8b959ff75130eb302",
            "ad6ebca1c9294d59a7b1f127d0623b33",
            "ef4ff7cc33fc43b08408cec44ecb244a",
            "51dbc71023ad408fba519174d7554e19"
          ]
        },
        "outputId": "7990ef9e-c437-4f04-ca81-3bf33cf0489a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112664544444643, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47b59dcff902431089de4456b66f7f06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230907_164924-w3k6jm1e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<wandb.jupyter.IFrame at 0x7e49e2f371c0>"
            ],
            "text/html": [
              "<iframe src='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/w3k6jm1e?jupyter=true' style='border:none;width:100%;height:600px;'></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/w3k6jm1e' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/w3k6jm1e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "CommError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/public.py\u001b[0m in \u001b[0;36martifact\u001b[0;34m(self, name, type)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_artifact_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         artifact = wandb.Artifact._from_name(\n\u001b[0m\u001b[1;32m   1037\u001b[0m             \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/artifacts/artifact.py\u001b[0m in \u001b[0;36m_from_name\u001b[0;34m(cls, entity, project, name, client)\u001b[0m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"project\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"artifact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d87111389c08>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENTITY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0martifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wandb/model-registry/Model Registry Tutorial:staging'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0martifact_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Run\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_finished\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 default_message = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_attaching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36muse_artifact\u001b[0;34m(self, artifact_or_name, type, aliases, use_as)\u001b[0m\n\u001b[1;32m   2732\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martifact_or_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m             \u001b[0mpublic_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m             \u001b[0martifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublic_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_backend_error_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/public.py\u001b[0m in \u001b[0;36martifact\u001b[0;34m(self, name, type)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must specify name= to fetch an artifact.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_artifact_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         artifact = wandb.Artifact._from_name(\n\u001b[0m\u001b[1;32m   1037\u001b[0m             \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/artifacts/artifact.py\u001b[0m in \u001b[0;36m_from_name\u001b[0;34m(cls, entity, project, name, client)\u001b[0m\n\u001b[1;32m    252\u001b[0m             },\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"project\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"artifact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mCommError\u001b[0m: 'NoneType' object has no attribute 'get'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zI8jfFe_2k9N"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47b59dcff902431089de4456b66f7f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12f9885246ac45629e53dddc6fb8f174",
              "IPY_MODEL_53c72207fd38467b859032dc19a04fe8"
            ],
            "layout": "IPY_MODEL_76f66f2192e74c39ad9549afcc755d8f"
          }
        },
        "12f9885246ac45629e53dddc6fb8f174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752dfc1538d443c8b959ff75130eb302",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6ebca1c9294d59a7b1f127d0623b33",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "53c72207fd38467b859032dc19a04fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef4ff7cc33fc43b08408cec44ecb244a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51dbc71023ad408fba519174d7554e19",
            "value": 1
          }
        },
        "76f66f2192e74c39ad9549afcc755d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752dfc1538d443c8b959ff75130eb302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6ebca1c9294d59a7b1f127d0623b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef4ff7cc33fc43b08408cec44ecb244a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51dbc71023ad408fba519174d7554e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}