{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n",
        "!pip install -q wandb\n",
        "!pip install -q ctranslate2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq6qVDaUXKES",
        "outputId": "3c5041e1-8043-4ccd-9920-e7d38c82148a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_BASE_URL'] = \"https://staging-aws.wandb.io/\"\n",
        "os.environ['WANDB_API_KEY'] = \"\""
      ],
      "metadata": {
        "id": "neH5bsKOaHTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "def convert_qlora2ct2(adapter_path='model-registry/OPT-125M:latest',\n",
        "                      full_model_path=\"opt125m-finetuned\",\n",
        "                      offload_path=\"opt125m-offload\",\n",
        "                      ct2_path=\"opt125m-finetuned-ct2\",\n",
        "                      quantization=\"int8\"):\n",
        "\n",
        "\n",
        "    peft_model_id = adapter_path\n",
        "    peftconfig = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      \"facebook/opt-125m\",\n",
        "      offload_folder  = offload_path,\n",
        "      device_map='auto',\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
        "\n",
        "    model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "\n",
        "    print(\"Peft model loaded\")\n",
        "\n",
        "    merged_model = model.merge_and_unload()\n",
        "\n",
        "    merged_model.save_pretrained(full_model_path)\n",
        "    tokenizer.save_pretrained(full_model_path)\n",
        "\n",
        "    if quantization == False:\n",
        "        os.system(f\"ct2-transformers-converter --model {full_model_path} --output_dir {ct2_path} --force\")\n",
        "    else:\n",
        "        os.system(f\"ct2-transformers-converter --model {full_model_path} --output_dir {ct2_path} --quantization {quantization} --force\")\n",
        "    print(\"Convert successfully\")\n",
        "    return merged_model, tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsFUc7lVXvLk",
        "outputId": "f767baf2-cc0c-4758-ba80-b489935ab9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consume a Registered Model\n",
        "- Names and aliases offer a simple handle to retrieve Registered Model versions\n",
        "- Facilitate easy hand-off between teams and processes"
      ],
      "metadata": {
        "id": "5rP6TcEgYxuj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "DHpPaILFWSaT",
        "outputId": "246121cd-4b2e-4015-cd27-1101888587a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenleewb\u001b[0m (\u001b[33msmle-machine\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230907_211436-81a4trny</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/81a4trny' target=\"_blank\">honest-night-18</a></strong> to <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/81a4trny' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/81a4trny</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1 of 8 files downloaded...\r\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model-registry/Review-Summarization:staging'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import ctranslate2\n",
        "import wandb\n",
        "\n",
        "\n",
        "wandb.init(project=\"model-registry-walkthrough\", entity=\"smle-machine\", job_type=\"ctranslate2\")\n",
        "\n",
        "best_model = wandb.use_artifact('smle-machine/model-registry/Review Summarization:staging')\n",
        "best_model.download(root='model-registry/Review-Summarization:staging')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the model\n",
        "- Quantize, convert formats, etc."
      ],
      "metadata": {
        "id": "aqFnvEvGccl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantizing the model to int8\n",
        "merged_model, tokenizer = convert_qlora2ct2(adapter_path='model-registry/Review-Summarization:staging',\n",
        "                                            ct2_path='model-registry/Review-Summarization-quantized')\n",
        "\n",
        "# Log the quantized model to the registry\n",
        "model_art = wandb.Artifact('review-summary-ct2-quantized', type=\"model\")\n",
        "model_art.add_dir('model-registry/Review-Summarization-quantized')\n",
        "wandb.run.link_artifact(model_art, 'smle-machine/model-registry/Review Summarization', aliases=['quantized'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yzrVwPTcaiu",
        "outputId": "f4561a0f-0f20-4764-a48a-2a29973d955c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peft model loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model-registry/Review-Summarization-quantized)... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done. 0.5s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifact TTL will be disabled for source artifacts that are linked to portfolios.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Inference on a Test Dataset\n",
        "- Log the results in a W&B Table"
      ],
      "metadata": {
        "id": "ipl6WcZWclSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on a test set and log results to W&B\n",
        "generator = ctranslate2.Generator(\"model-registry/Review-Summarization-quantized\")\n",
        "\n",
        "reviews = [\n",
        "    \"BlastMaster 3000 Vacuum Cleaner: I never knew cleaning could be this easy until I got the BlastMaster 3000! It glides effortlessly across all surfaces and picks up even the tiniest of dust particles. The only downside is that it's a bit noisy, but the power it packs more than makes up for it.\",\n",
        "    \"Sunrise Organic Facial Cream: I've been using Sunrise Organic Facial Cream for a month now, and the results are astonishing. My skin feels softer, smoother, and looks radiant. However, I wish the fragrance was a bit milder; it's a tad overpowering for my liking.\",\n",
        "    \"MellowTunes Wireless Earbuds: The sound quality of the MellowTunes earbuds is surprisingly good for its price range. They fit comfortably in my ears and the battery life lasts an entire day of listening. Just wish they came with a case that was a bit more durable.\"\n",
        "]\n",
        "\n",
        "prompts = [f\"Summarize this review {review}\" for review in reviews]\n",
        "\n",
        "\n",
        "test_table = wandb.Table(columns=[\"review\", \"summary\"])\n",
        "\n",
        "for r, p in zip(reviews, prompts):\n",
        "  start_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(p))\n",
        "  results = generator.generate_batch([start_tokens], max_length=100)\n",
        "  output = tokenizer.decode(results[0].sequences_ids[0])\n",
        "  test_table.add_data(r, p)\n",
        "\n",
        "wandb.log({\"test_table\": test_table})\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "J-hpE89wci0e",
        "outputId": "bcf4ba32-1883-4db3-9c20-8ac1d2817d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">honest-night-18</strong> at: <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/81a4trny' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/runs/81a4trny</a><br/> View job at <a href='https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI4ODE=/version_details/v1' target=\"_blank\">https://staging-aws.wandb.io/smle-machine/model-registry-walkthrough/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjI4ODE=/version_details/v1</a><br/>Synced 5 W&B file(s), 1 media file(s), 7 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230907_211436-81a4trny/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query a Registered Model's upstream and downstream run data\n",
        "- Walk the pipeline DAG with the API to retrieve upstream training run data or downstream testing data"
      ],
      "metadata": {
        "id": "Va1mDTlvZSRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "api = wandb.Api()\n",
        "\n",
        "registered_model_quantized = api.artifact('smle-machine/model-registry/Review Summarization:quantized')\n",
        "\n",
        "# Get info about the quantization run\n",
        "quantizing_run = registered_model_quantized.logged_by()\n",
        "print(quantizing_run.summary)\n",
        "\n",
        "registered_model_checkpoint = list(filter(lambda x: \"checkpoint\" in x.name,\n",
        "                                     quantizing_run.used_artifacts()))[0]\n",
        "\n",
        "training_run =registered_model_checkpoint.logged_by()\n",
        "print(training_run.history())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek5ZiWtFZXqi",
        "outputId": "aeac734e-4b11-4163-9fed-0bd32845075f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_runtime': 77.95275163650513, '_timestamp': 1694108604.4251437, 'test_table': {'_latest_artifact_path': 'wandb-client-artifact://74yev5ehwetftnu17hgwwupgg2dr4x5g776zzem23nmh2ywvy2p9xeqonnkxwmmrwhrsh3ue95wwnown81cp150k4keqh2dlfvvs24aynurpjs6itmi1d70mqfhrcafm:latest/test_table.table.json', 'path': 'media/table/test_table_0_fbe33428917ff54897bb.table.json', 'size': 1778, '_type': 'table-file', 'ncols': 2, 'nrows': 3, 'sha256': 'fbe33428917ff54897bb274488b7bb0f6fc680dbfe7969f66949ffa4208914c8', 'artifact_path': 'wandb-client-artifact://74yev5ehwetftnu17hgwwupgg2dr4x5g776zzem23nmh2ywvy2p9xeqonnkxwmmrwhrsh3ue95wwnown81cp150k4keqh2dlfvvs24aynurpjs6itmi1d70mqfhrcafm:latest/test_table.table.json'}, '_step': 0, '_wandb': {'runtime': 46}}\n",
            "    _step   _runtime    _timestamp  train/loss  train/epoch  \\\n",
            "0       0  10.073223  1.694105e+09      3.1699         0.01   \n",
            "1       1  11.019853  1.694106e+09      3.1092         0.01   \n",
            "2       2  11.995674  1.694106e+09      3.3207         0.02   \n",
            "3       3  12.924126  1.694106e+09      3.3287         0.03   \n",
            "4       4  13.831480  1.694106e+09      3.2689         0.03   \n",
            "5       5  15.499250  1.694106e+09      3.4853         0.04   \n",
            "6       6  16.611508  1.694106e+09      3.4016         0.04   \n",
            "7       7  17.627450  1.694106e+09      3.1386         0.05   \n",
            "8       8  18.549229  1.694106e+09      3.3931         0.06   \n",
            "9       9  19.517586  1.694106e+09      2.8761         0.06   \n",
            "10     10  21.313174  1.694106e+09      2.8992         0.07   \n",
            "11     11  23.024345  1.694106e+09      3.5666         0.08   \n",
            "12     12  23.913184  1.694106e+09      3.0197         0.08   \n",
            "13     13  24.819732  1.694106e+09      3.0034         0.09   \n",
            "14     14  25.713616  1.694106e+09      3.1882         0.10   \n",
            "15     15  27.538380  1.694106e+09      3.1593         0.10   \n",
            "16     16  28.634648  1.694106e+09      3.2443         0.11   \n",
            "17     17  29.582529  1.694106e+09      3.0838         0.11   \n",
            "18     18  30.867941  1.694106e+09      3.1232         0.12   \n",
            "19     19  31.863602  1.694106e+09      3.0842         0.13   \n",
            "20     20  33.543199  1.694106e+09      2.8676         0.13   \n",
            "21     21  34.542794  1.694106e+09      3.3844         0.14   \n",
            "22     22  35.451618  1.694106e+09      3.2143         0.15   \n",
            "23     23  36.387455  1.694106e+09      3.2346         0.15   \n",
            "24     24  37.268702  1.694106e+09      3.5055         0.16   \n",
            "25     25  38.066943  1.694106e+09         NaN         0.16   \n",
            "\n",
            "    train/global_step  train/learning_rate  train/total_flos  \\\n",
            "0                   1              0.00004               NaN   \n",
            "1                   2              0.00008               NaN   \n",
            "2                   3              0.00012               NaN   \n",
            "3                   4              0.00016               NaN   \n",
            "4                   5              0.00020               NaN   \n",
            "5                   6              0.00019               NaN   \n",
            "6                   7              0.00018               NaN   \n",
            "7                   8              0.00017               NaN   \n",
            "8                   9              0.00016               NaN   \n",
            "9                  10              0.00015               NaN   \n",
            "10                 11              0.00014               NaN   \n",
            "11                 12              0.00013               NaN   \n",
            "12                 13              0.00012               NaN   \n",
            "13                 14              0.00011               NaN   \n",
            "14                 15              0.00010               NaN   \n",
            "15                 16              0.00009               NaN   \n",
            "16                 17              0.00008               NaN   \n",
            "17                 18              0.00007               NaN   \n",
            "18                 19              0.00006               NaN   \n",
            "19                 20              0.00005               NaN   \n",
            "20                 21              0.00004               NaN   \n",
            "21                 22              0.00003               NaN   \n",
            "22                 23              0.00002               NaN   \n",
            "23                 24              0.00001               NaN   \n",
            "24                 25              0.00000               NaN   \n",
            "25                 25                  NaN      1.775130e+13   \n",
            "\n",
            "    train/train_loss  train/train_runtime  train/train_steps_per_second  \\\n",
            "0                NaN                  NaN                           NaN   \n",
            "1                NaN                  NaN                           NaN   \n",
            "2                NaN                  NaN                           NaN   \n",
            "3                NaN                  NaN                           NaN   \n",
            "4                NaN                  NaN                           NaN   \n",
            "5                NaN                  NaN                           NaN   \n",
            "6                NaN                  NaN                           NaN   \n",
            "7                NaN                  NaN                           NaN   \n",
            "8                NaN                  NaN                           NaN   \n",
            "9                NaN                  NaN                           NaN   \n",
            "10               NaN                  NaN                           NaN   \n",
            "11               NaN                  NaN                           NaN   \n",
            "12               NaN                  NaN                           NaN   \n",
            "13               NaN                  NaN                           NaN   \n",
            "14               NaN                  NaN                           NaN   \n",
            "15               NaN                  NaN                           NaN   \n",
            "16               NaN                  NaN                           NaN   \n",
            "17               NaN                  NaN                           NaN   \n",
            "18               NaN                  NaN                           NaN   \n",
            "19               NaN                  NaN                           NaN   \n",
            "20               NaN                  NaN                           NaN   \n",
            "21               NaN                  NaN                           NaN   \n",
            "22               NaN                  NaN                           NaN   \n",
            "23               NaN                  NaN                           NaN   \n",
            "24               NaN                  NaN                           NaN   \n",
            "25          3.202816              32.1851                         0.777   \n",
            "\n",
            "    train/train_samples_per_second  \n",
            "0                              NaN  \n",
            "1                              NaN  \n",
            "2                              NaN  \n",
            "3                              NaN  \n",
            "4                              NaN  \n",
            "5                              NaN  \n",
            "6                              NaN  \n",
            "7                              NaN  \n",
            "8                              NaN  \n",
            "9                              NaN  \n",
            "10                             NaN  \n",
            "11                             NaN  \n",
            "12                             NaN  \n",
            "13                             NaN  \n",
            "14                             NaN  \n",
            "15                             NaN  \n",
            "16                             NaN  \n",
            "17                             NaN  \n",
            "18                             NaN  \n",
            "19                             NaN  \n",
            "20                             NaN  \n",
            "21                             NaN  \n",
            "22                             NaN  \n",
            "23                             NaN  \n",
            "24                             NaN  \n",
            "25                          12.428  \n"
          ]
        }
      ]
    }
  ]
}