{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109531d8",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeddf6b",
   "metadata": {},
   "source": [
    "In this notebook we will prepare the data to later train our deep learning model. To do so, \n",
    "- we will first upload a copy of our raw dataset as a `wandb.Artifact`\n",
    "- preprocess the dataset and setup the target column to train a classifier\n",
    "- split the data and save the splits into a `wandb.Artifact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e54f3-dcf7-4283-8e85-5d837f57c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85047277-a0b1-4e42-8642-894a95091936",
   "metadata": {},
   "source": [
    "We will define some global configuration parameters. `ENTITY` should correspond to your W&B Team name if you work in a team, replace it with `None` if you work individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c01357-8f14-4e11-9f59-b7ec9744f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'lemon-project'\n",
    "ENTITY = 'wandb_course'\n",
    "RAW_DATA_FOLDER = 'lemon-dataset/images'\n",
    "ANNOTATIONS_FILE = 'lemon-dataset/annotations/instances_default.json'\n",
    "PREFIX = 'lemon_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44089644",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_AT = f'{PREFIX}_raw_data'\n",
    "RAW_DATA_AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40275d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_AT = f'{PREFIX}_split_data'\n",
    "PROCESSED_DATA_AT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a02d56",
   "metadata": {},
   "source": [
    "## Register raw data as an artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc56a9-44a7-43ba-9e75-ffd2c4104feb",
   "metadata": {},
   "source": [
    "It is a good practice to save a copy of the raw dataset so that you can reproduce your experiments later and track the model lineage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82903be-e380-414a-9ef6-b5f40eade0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d15e66-e21a-4430-ad84-4aab6a9d4fc8",
   "metadata": {},
   "source": [
    "create an artifact for all the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23a2cf-cad2-4544-acb9-2c9b70fa30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ed010-3104-46ae-99de-6c537ec662d5",
   "metadata": {},
   "source": [
    "add all images in the directory to the artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657fc82-5ddc-4e8d-a9c3-ee28c908e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at.add_dir(RAW_DATA_FOLDER, name='images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190b592-69d0-4379-80ca-37ebf2bdd9bd",
   "metadata": {},
   "source": [
    "add annotations file to the artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa77b6-d518-4c52-a35e-c4f6a942e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at.add_file(ANNOTATIONS_FILE, name='annotations/instances_default.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc247b12-d422-4f4d-92c4-7650374081e8",
   "metadata": {},
   "source": [
    "save artifact to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e593d-e159-4ead-a244-553b93beda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(raw_data_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f720ee-2892-4da2-ae29-c56178bb526c",
   "metadata": {},
   "source": [
    "finalize run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af061826-a8f9-4b65-9534-c7fa10feed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3ed78",
   "metadata": {},
   "source": [
    "## Pre-process data for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf742b-b3a8-4947-8d7c-d73245a87c9a",
   "metadata": {},
   "source": [
    "The image annotations live in this `instances_default.json` file, we will select the interesting columns and create a new file to store our target col.\n",
    "\n",
    "We will first grab a copy of the `raw_dataset` from the previously logged `wandb.Artifact`. Why we do this? Don't worry, wandb automatically realizes that the dataset is already here. Doing this, will link the data lineage to point to the raw dataset version that was used to create the preprocessed *new* dataset. This is very handy for dataset traceability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645008c-ea3c-4052-9740-ecf42776d8db",
   "metadata": {},
   "source": [
    "We first create a new run, we can specify the `job_type` so we can filter later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968bdd02-5996-41f1-b59c-c8ab12860b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"data_split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7121f-9087-4657-87d1-77b6f2bfea2e",
   "metadata": {},
   "source": [
    "find the most recent (\"latest\") version of the full raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad2fc4-7c6d-4a5f-ade6-caf52feeb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_at = run.use_artifact(f'{RAW_DATA_AT}:latest')\n",
    "dataset_dir = Path(raw_data_at.download())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008944cd-52ac-468f-9ed3-8fe38b46d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(dataset_dir / 'annotations/instances_default.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a1f5a-79cb-4239-b90e-e2fcc37b7c99",
   "metadata": {},
   "source": [
    "we then open and convert the `json` file to a pandas `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c705f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.DataFrame.from_dict(data['annotations'])\n",
    "images = pd.DataFrame.from_dict(data['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6047891",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotations[['image_id', 'category_id']].groupby('image_id')['category_id'].apply(lambda x: list(set(x))).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mold'] = df['category_id'].apply(lambda x: 4 in x)\n",
    "df['mold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0256708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, images[['id', 'file_name']], left_on='image_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87657133",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7860fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fruit_id'] = df['file_name'].apply(lambda x: x.split('/')[1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3646d-118d-42f9-9234-959342f56ac4",
   "metadata": {},
   "source": [
    "## Train / validation / test split\n",
    "\n",
    "Now we will split the data into train (80%), validation (10%) and test (10%) sets. As we do that, we need to be careful to: \n",
    "- *avoid leakage*: for that reason we are grouping data according to each fruit id (we don't want the classifier to memorize which individual fruit contains mold, but generalize across different lemons)\n",
    "- handle the *label imbalance*: for that reason we stratify data with our target column\n",
    "\n",
    "We will use sklearn's `StratifiedGroupKFold` to split the data into 10 folds and assign 1 fold for test, 1 for validation and the rest for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fold'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a84e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "X = df.index.values\n",
    "y = df.mold.values\n",
    "groups = df.fruit_id.values\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "for i, (train_idxs, test_idxs) in enumerate(cv.split(X, y, groups)):\n",
    "    df['fold'].iloc[test_idxs] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f146b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stage'] = df['fold'].apply(lambda x: 'test' if x == 0 else ('valid' if x == 1 else 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531be5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_split.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fae579",
   "metadata": {},
   "source": [
    "create an artifact for all the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at = wandb.Artifact(PROCESSED_DATA_AT, type=\"split_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147218f",
   "metadata": {},
   "source": [
    "add data split file to the artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31326ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at.add_file('data_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60820f11",
   "metadata": {},
   "source": [
    "add images to the artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at.add_dir(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b93f7",
   "metadata": {},
   "source": [
    "Let's also enrich our EDA table with the split data so we can inspect it visually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb6921",
   "metadata": {},
   "source": [
    "First, we will fetch original EDA table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_eda = run.use_artifact(\"run-v9s47qhv-table_coco_sample:latest\")\n",
    "orig_eda_table = orig_eda.get(\"table_coco_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584c50e",
   "metadata": {},
   "source": [
    "create data split table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97990ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_table = wandb.Table(dataframe=df[['file_name', 'stage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111266c7",
   "metadata": {},
   "source": [
    "join tables on `file_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e09a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_table = wandb.JoinedTable(orig_eda_table, data_split_table, \"file_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec2758",
   "metadata": {},
   "source": [
    "add table to artifact and log to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8937c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at.add(join_table, \"table_coco_data_split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fbc14",
   "metadata": {},
   "source": [
    "save artifact to W&B and finalize run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee27d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(processed_data_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c037b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
