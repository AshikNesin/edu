{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ca5c18",
   "metadata": {},
   "source": [
    "# Baseline solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8dcd9-8c0c-4d04-a590-17b9c30c6ea2",
   "metadata": {},
   "source": [
    "In this notebooks we will create a baseline solution to our lemon problem. To iterate fast a notebook is a handy solution. We will then refactor this code into a script to be able to use hyperparameter sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6f2ee-ada7-45cd-b3f0-c108f866356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42, reproducible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b45571-9bbc-4121-ac71-35d53b0d1147",
   "metadata": {},
   "source": [
    "We will define some global configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381ccb4-2e23-4609-89f2-7c2be2a951c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'lemon-project'\n",
    "ENTITY = 'wandb_course'\n",
    "PROCESSED_DATA_AT = 'lemon_dataset_split_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ce3a3-515c-4d39-968c-e6198635cd19",
   "metadata": {},
   "source": [
    "Let's grab the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841952fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d002b0f5-2f2f-4335-b14b-b1d4f5bc1de6",
   "metadata": {},
   "source": [
    "find the most recent (\"latest\") version of the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcadd7-ad5f-4154-9465-2d12c414ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_at = run.use_artifact(f'{PROCESSED_DATA_AT}:latest')\n",
    "processed_dataset_dir = Path(processed_data_at.download())\n",
    "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723b777-91a0-4ca6-a077-d58140949248",
   "metadata": {},
   "source": [
    "we will not use the hold out dataset stage at this moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ffea7-f42c-471f-9411-105d193488d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.stage != 'test'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "(processed_dataset_dir/'images').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a138606-dba2-470b-8942-e0b43f553fc9",
   "metadata": {},
   "source": [
    "this will tell our trainer how we want to split data between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c6a37-9702-4205-ab6e-dc0786591a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valid'] = df.stage == 'valid'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad325b3-6333-4ed9-a156-26db1987e2d7",
   "metadata": {},
   "source": [
    "## Using a configuration dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7457c89-5cf8-4aae-a40c-07afac8d1406",
   "metadata": {},
   "source": [
    "We will use `ml_collections` here, which is a handy way of expressing configurations of experiments and models. Here we will define some global configuration parameters to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5db144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import config_dict\n",
    "\n",
    "cfg = config_dict.ConfigDict()\n",
    "cfg.img_size = 256\n",
    "cfg.target_column = 'mold'\n",
    "cfg.bs = 32\n",
    "cfg.seed = 42\n",
    "cfg.arch = 'resnet18'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024353cf-3b28-4eab-83f4-eac6578443a0",
   "metadata": {},
   "source": [
    "We will udpate the config of the run, it is a simple as adding the new entries to the `wandb.config` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(cfg.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24ab1a-8675-4200-b00a-e1f222a8a428",
   "metadata": {},
   "source": [
    "We are using fastai, so creating a Dataloader pipeline from a dataframe is straightforward using the `ImageDataLoaders` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_df(df, path=processed_dataset_dir, seed=cfg.seed, fn_col='file_name', \n",
    "                               label_col=cfg.target_column, valid_col='valid', \n",
    "                               item_tfms=Resize(cfg.img_size), bs=cfg.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35855a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75589784-7ae2-49c7-b34a-1d0cbe46f8c5",
   "metadata": {},
   "source": [
    "Let's check how many images have mold on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.valid == True]['mold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df99a91-f89e-43ee-b818-e810c9d68d90",
   "metadata": {},
   "source": [
    "this is the baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86771d3-7538-458b-9954-f946f913bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.valid == True]['mold'].value_counts()[0] / len(df[df.valid == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c78610-3a49-4a83-b256-1ae8e3e30350",
   "metadata": {},
   "source": [
    "In `fastai` we already have a callback that integrates tightly with W&B, we only need to pass the `WandbCallback` to the learner and we are ready to go. The callback will log all the useful variables for us. For example, whatever metric we pass to the learner will be tracked by the callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.wandb import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a859e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       cfg.arch,\n",
    "                       metrics=[accuracy, Precision(), Recall(), F1Score()],\n",
    "                       cbs=[WandbCallback(log_preds=False, log_model=True), SaveModelCallback(monitor='f1_score')])\n",
    "\n",
    "learn.fine_tune(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029bb15-f2a7-4dc6-8f11-47d6865ffc5b",
   "metadata": {},
   "source": [
    "We can log a table with all the predictions on the validation dataset using `learn.get_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e1a65-b3f6-4eca-bfdc-8756a6f60123",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp,preds,targs,out = learn.get_preds(with_input=True, with_decoded=True)\n",
    "inp.shape, preds.shape, targs.shape, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f085b-9cf0-488b-94dc-77d6a8e8198a",
   "metadata": {},
   "source": [
    "We will create a Table with 4 columns: (Images, probabilities, targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ccefd-d3de-442a-91e1-ab75f48ce6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [wandb.Image(t.permute(1,2,0)) for t in inp] # we need to put as channels last for wandb.Image \n",
    "pred_proba = preds[:,1].numpy().tolist()\n",
    "targets = targs.numpy().tolist()\n",
    "predictions = out.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37985242-fd70-4bb6-9d09-69a5482cc4f2",
   "metadata": {},
   "source": [
    "we create an intermediate `pd.DataFrame` to then create a Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc44130-9d40-4a9d-8694-de8618301fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(list(zip(imgs, pred_proba, predictions, targets)),\n",
    "                        columns =['image', 'probability', 'prediction', 'target'])\n",
    "\n",
    "run.log({'predictions_table': wandb.Table(dataframe=preds_df)})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ab3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
