{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weave\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # TODO: replace with getpass\n",
    "\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: ayut.\n",
      "View Weave data at https://wandb.ai/eval-course/eval-course-dev/weave\n"
     ]
    }
   ],
   "source": [
    "# initialize weave\n",
    "weave_client =weave.init(project_name=\"eval-course/eval-course-dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essay Writer\n",
    "\n",
    "Imagine a task, where you are using an LLM to write an essay. \n",
    "\n",
    "query ----> [LLM based essay writer] ----> essay # TODO: simple diagram\n",
    "\n",
    "- You have built an evaluation set of query-essay pairs.\n",
    "- You have a set of human evaluators who have labeled the essays based on some criteria.\n",
    "\n",
    "Now you don't want to always rely on human evaluators to label the essays. You want to build an LLM based evaluator. # TODO: improve framing\n",
    "\n",
    "Let's start with building a simple evaluator and then we will see how we can align it with human evaluators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prompt\n",
    "\n",
    "Any LLM evaluator needs a prompt. A \"judge's\" prompt will have three key components: # TODO: expand of these three components\n",
    "1. A task description\n",
    "2. Measuring criteria(s)\n",
    "3. Scoring rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_PROMPT = \"\"\"You are an expert essay evaluator. \n",
    "Please evaluate the following essay according to the Holistic Rating for Source-Based Writing rubric on a scale of 1-6.\n",
    "First give a reason for the score and return the result as a valid JSON object.\n",
    "\n",
    "Example:\n",
    "```json\n",
    "{{\"score\": 4, \"reason\": \"The essay demonstrates a clear understanding of the source text and effectively uses it to support its points.\"}}\n",
    "```\n",
    "\n",
    "Essay:\n",
    "{full_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Evaluator\n",
    "\n",
    "The LLM evaluator takes in the system prompt, initialize an LLM and pass the system prompt along with \"generated\" content to the LLM.\n",
    "\n",
    "We expect the evaluator to return a judgement which can be in the form of raw text or a JSON object.\n",
    "\n",
    "Here we are using the `weave.Model` class which under the hood is a Pydantic `BaseModel`. By structuring your code to be compatible with this API, you benefit from a structured way to version your application so you can more systematically keep track of your experiments.\n",
    "\n",
    "In this case, we are passing the `full_text` to the evaluator and expect it to return a JSON object with `score` and `reason` keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave import Model, Evaluation\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "\n",
    "class EssayEvaluator(Model):\n",
    "    model: genai.GenerativeModel = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    judge_prompt: str = JUDGE_PROMPT\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, full_text: str) -> dict:\n",
    "        response = self.model.generate_content(self.judge_prompt.format(full_text=full_text))\n",
    "        try:\n",
    "            result = response.text.strip()\n",
    "            result = json.loads(result)\n",
    "            return result\n",
    "        except:\n",
    "            return {\"score\": 0, \"reason\": \"Failed to parse JSON\"}  # Default to lowest score if parsing fails\n",
    "\n",
    "# Initialize evaluator\n",
    "essay_evaluator = EssayEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The evaluation dataset\n",
    "\n",
    "To simulate this imaginary scenario, we use a small subset of the `train.csv` file from the \"[Learning Agency Lab - Automated Essay Scoring 2.0](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/data?select=train.csv)\" Kaggle competition.\n",
    "\n",
    "Specifically, we have two columns of interest: `full_text` and `score`. The `full_text` should be essay generated from our LLM based essay writer. The `score` is the score given by the human evaluators.\n",
    "\n",
    "Each essay was scored on a scale of 1 to 6 using the \"[Holistic Rating for Source-Based Writing](https://storage.googleapis.com/kaggle-forum-message-attachments/2733927/20538/Rubric_%20Holistic%20Essay%20Scoring.pdf)\" code book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: ayut.\n",
      "View Weave data at https://wandb.ai/eval-course/eval-course-dev/weave\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "weave.init('eval-course/eval-course-dev')\n",
    "essay_scorer_small = weave.ref('essay_scorer_small:v0').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The evaluation metric\n",
    "\n",
    "We want to evaluate the evaluator's performance using the `score` column from the dataset. We are using the `exact_match` metric to check if the evaluator's prediction matches the human score.\n",
    "\n",
    "The `weave.op()` decorator allows us to track the metric as an operation in the weave graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple exact match metric\n",
    "@weave.op()\n",
    "def exact_match(score: dict, model_output: dict) -> float:\n",
    "    \"\"\"Check if predicted score matches human score\"\"\"\n",
    "    return model_output['score'] == score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: The evaluation\n",
    "\n",
    "Should we expand of this section?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'exact_match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.5987855195999146</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'exact_match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m5.5987855195999146\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/eval-course/eval-course-dev/r/call/0192d27d-2e5d-7450-8c90-1eae8eedaaa8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'score': {'mean': 0.0}},\n",
       " 'exact_match': {'true_count': 0, 'true_fraction': 0.0},\n",
       " 'model_latency': {'mean': 5.5987855195999146}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create evaluation\n",
    "evaluation = Evaluation(\n",
    "    dataset=essay_scorer_small,\n",
    "    scorers=[exact_match]\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "asyncio.run(evaluation.evaluate(essay_evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better JSON parsing\n",
    "\n",
    "We need to improve the JSON parsing to handle cases where the LLM returns a JSON object with extra markdown formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'exact_match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.9505390405654905</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m2.2\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'exact_match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m4.9505390405654905\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/eval-course/eval-course-dev/r/call/0192d27d-843a-7261-a237-8fc9af01a31a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'score': {'mean': 2.2}},\n",
       " 'exact_match': {'true_count': 2, 'true_fraction': 0.2},\n",
       " 'model_latency': {'mean': 4.9505390405654905}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@weave.op()\n",
    "def parse_json(result: str) -> dict:\n",
    "    if \"```json\" in result:\n",
    "        result = result.split(\"```json\\n\")[1].split(\"\\n```\")[0]\n",
    "    # Clean up any remaining markdown formatting\n",
    "    result = result.strip()\n",
    "    return json.loads(result)\n",
    "\n",
    "\n",
    "class EssayEvaluator(Model):\n",
    "    model: genai.GenerativeModel = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    judge_prompt: str = JUDGE_PROMPT\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, full_text: str) -> dict:\n",
    "        response = self.model.generate_content(self.judge_prompt.format(full_text=full_text))\n",
    "        try:\n",
    "            result = response.text.strip()\n",
    "            return parse_json(result)\n",
    "        except:\n",
    "            return {\"score\": 0, \"reason\": \"Failed to parse JSON\"}  # Default to lowest score if parsing fails\n",
    "\n",
    "# Initialize evaluator\n",
    "essay_evaluator = EssayEvaluator()\n",
    "\n",
    "# Run evaluation\n",
    "asyncio.run(evaluation.evaluate(essay_evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output\n",
    "\n",
    "Most frontier LLM providers support structured outputs. Using this forces the LLM to return/predict a specific schema.\n",
    "\n",
    "Note: If you have complex \"reasoning\" to be done via your LLM evaluator, you should use two API calls. Use the first API call to do the reasoning and use the second API call to output the structured response. Reference: https://arxiv.org/abs/2408.02442v1\n",
    "\n",
    "Learn more about structured outputs in this free course by Jason Liu: https://www.wandb.courses/courses/steering-language-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'exact_match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1608036756515503</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m2.2\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'exact_match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.1608036756515503\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/eval-course/eval-course-dev/r/call/0192d27d-b0f7-7032-bf9c-84d293adfa96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'score': {'mean': 2.2}},\n",
       " 'exact_match': {'true_count': 2, 'true_fraction': 0.2},\n",
       " 'model_latency': {'mean': 3.1608036756515503}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing_extensions as typing\n",
    "\n",
    "class Judgement(typing.TypedDict):\n",
    "    reason: str\n",
    "    score: int\n",
    "\n",
    "\n",
    "class EssayEvaluator(Model):\n",
    "    model: genai.GenerativeModel = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    judge_prompt: str = JUDGE_PROMPT\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, full_text: str) -> dict:\n",
    "        response = self.model.generate_content(\n",
    "            self.judge_prompt.format(full_text=full_text),\n",
    "            generation_config=genai.GenerationConfig(\n",
    "                response_mime_type=\"application/json\", response_schema=Judgement\n",
    "            ),\n",
    "        )\n",
    "        try:\n",
    "            result = json.loads(response.text.strip(\"\\n\"))\n",
    "            return result\n",
    "        except:\n",
    "            return {\"score\": 0, \"reason\": \"Failed to parse JSON\"}  # Default to lowest score if parsing fails\n",
    "\n",
    "# Initialize evaluator\n",
    "essay_evaluator = EssayEvaluator()\n",
    "\n",
    "# Run evaluation\n",
    "asyncio.run(evaluation.evaluate(essay_evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning LLM evaluators with human evaluators\n",
    "\n",
    "One of the most important aspects of building an LLM evaluator is to align it with human evaluators. This ensures that the evaluator is consistent with human beliefs ensuring higher confidence in the evaluator's predictions.\n",
    "\n",
    "In our case, we have human annotations. Let's see how we can align the LLM evaluator and in turn improve the evaluator's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The alignment metric\n",
    "\n",
    "Cohen Kappa # TODO: add more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad85676</td>\n",
       "      <td>Venus is one of the brightest point in the sky...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241077a</td>\n",
       "      <td>Driverless cars may be the future but it would...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b7e42c</td>\n",
       "      <td>Alien Landform?\\n\\nDo you think that the face ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b6df5c</td>\n",
       "      <td>Emotions in the classroom? This is a question ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f92d35c</td>\n",
       "      <td>dear state senator, im writting this letter to...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  \\\n",
       "0  ad85676  Venus is one of the brightest point in the sky...      1   \n",
       "1  241077a  Driverless cars may be the future but it would...      4   \n",
       "2  1b7e42c  Alien Landform?\\n\\nDo you think that the face ...      1   \n",
       "3  0b6df5c  Emotions in the classroom? This is a question ...      3   \n",
       "4  f92d35c  dear state senator, im writting this letter to...      2   \n",
       "\n",
       "   pred_score  \n",
       "0           2  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_evaluation_predictions(eval_call_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves evaluation predictions from a Weave call and returns them as a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        eval_call_id (str): The ID of the Weave evaluation call to analyze\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the evaluation data with predictions\n",
    "    \"\"\"\n",
    "    eval_calls = weave_client.get_call(eval_call_id)\n",
    "\n",
    "    predictions = []\n",
    "    for eval_call in eval_calls.children():\n",
    "        if eval_call.op_name.split(\"/\")[-1].split(\":\")[0] == \"Evaluation.predict_and_score\":\n",
    "            _eval_call = weave_client.get_call(eval_call.id)\n",
    "            data = dict(_eval_call.inputs[\"example\"])\n",
    "            data.update({\"pred_score\": dict(_eval_call.output)[\"model_output\"][\"score\"]})\n",
    "            predictions.append(data)\n",
    "\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# Get evaluation predictions\n",
    "eval_df = get_evaluation_predictions(\"0192d20a-d23a-7461-8c1a-528820d8d0a2\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment between human and LLM evaluator: 0.156\n"
     ]
    }
   ],
   "source": [
    "def calculate_cohen_kappa(df: pd.DataFrame, labels: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Cohen's Kappa score between human scores and model predictions.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'score' and 'pred_score' columns\n",
    "        labels (list): List of label values to consider in the calculation\n",
    "\n",
    "    Returns:\n",
    "        float: Cohen's Kappa score with linear weights\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If required columns 'score' or 'pred_score' are missing from DataFrame\n",
    "    \"\"\"\n",
    "    required_cols = ['score', 'pred_score']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    assert len(missing_cols) == 0, (\n",
    "        f\"DataFrame is missing required columns: {missing_cols}. \"\n",
    "        f\"Please ensure DataFrame contains both 'score' and 'pred_score' columns.\"\n",
    "    )\n",
    "    \n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    return cohen_kappa_score(\n",
    "        df['score'], \n",
    "        df['pred_score'],\n",
    "        labels=labels, \n",
    "        weights='linear'\n",
    "    )\n",
    "\n",
    "# Calculate Cohen's Kappa score for scores 1-6\n",
    "kappa = calculate_cohen_kappa(eval_df, labels=list(range(1,7)))\n",
    "print(f\"Alignment between human and LLM evaluator: {kappa:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the LLM evaluator\n",
    "\n",
    "### Part 1: Improve the criteria definition\n",
    "\n",
    "Here we will improve the evaluator by improving the criteria used to evaluate the essays. Since the human annotators used the [Holistic Rating for Source-Based Writing](https://storage.googleapis.com/kaggle-forum-message-attachments/2733927/20538/Rubric_%20Holistic%20Essay%20Scoring.pdf)\" code book we will use similar criteria to evaluate the essays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_PROMPT = \"\"\"You are an expert essay evaluator.\n",
    "Please evaluate the following essay according to the Holistic Rating for Source-Based Writing rubric on a scale of 1-6 as shown below:\n",
    "\n",
    "Score 6: Demonstrates clear and consistent mastery with minor errors. Effectively and insightfully develops a point of view with outstanding critical thinking. Uses appropriate examples and evidence to support its stance. The essay is highly organized and coherent, showing smooth idea progression, skillful language use, and varied, accurate vocabulary. Free of significant errors in grammar and mechanics.\n",
    "\n",
    "Score 5: Shows reasonably consistent mastery with occasional errors. Develops a strong point of view with good critical thinking, supported by relevant examples and evidence. Generally organized and coherent, the essay uses language well, with appropriate vocabulary and sentence structure variety. Mostly free of errors in grammar and mechanics.\n",
    "\n",
    "Score 4: Demonstrates adequate mastery but has some lapses. Develops a point of view with competent critical thinking, supported by adequate examples and evidence. Generally organized and coherent, though may show inconsistency in language use or vocabulary choice. May have occasional grammar and mechanics errors.\n",
    "\n",
    "Score 3: Shows developing mastery with weaknesses, such as inconsistent critical thinking or inadequate support. Organization or focus may be limited, with possible lapses in coherence. Language use may be basic, with weak vocabulary and/or issues in sentence structure. Contains multiple grammar and mechanics errors.\n",
    "\n",
    "Score 2: Demonstrates little mastery and is flawed by vague or weak critical thinking, poor organization, or insufficient evidence. Language use is limited, with frequent vocabulary and sentence structure issues. Grammar and mechanics errors may obscure meaning.\n",
    "\n",
    "Score 1: Displays very little or no mastery. Lacks a viable point of view or relevant evidence, is highly disorganized or incoherent. Contains severe vocabulary and structure issues, with pervasive grammar and mechanics errors that obscure meaning.\n",
    "\n",
    "First give a reason for the score and return the result as a valid JSON object.\n",
    "\n",
    "Example:\n",
    "```json\n",
    "{{\"score\": 4, \"reason\": \"The reason for the score...\"}}\n",
    "```\n",
    "\n",
    "Essay:\n",
    "{full_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_output'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.7</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'exact_match'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.343193602561951</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model_output'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m2.7\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'exact_match'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.4\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.343193602561951\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/eval-course/eval-course-dev/r/call/0192d298-dd9c-74c1-9afc-f3a422da996e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_output': {'score': {'mean': 2.7}},\n",
       " 'exact_match': {'true_count': 4, 'true_fraction': 0.4},\n",
       " 'model_latency': {'mean': 3.343193602561951}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EssayEvaluator(Model):\n",
    "    model: genai.GenerativeModel = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    judge_prompt: str = JUDGE_PROMPT\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, full_text: str) -> dict:\n",
    "        response = self.model.generate_content(\n",
    "            self.judge_prompt.format(full_text=full_text),\n",
    "            generation_config=genai.GenerationConfig(\n",
    "                response_mime_type=\"application/json\", response_schema=Judgement\n",
    "            ),\n",
    "        )\n",
    "        try:\n",
    "            result = json.loads(response.text.strip(\"\\n\"))\n",
    "            return result\n",
    "        except:\n",
    "            return {\"score\": 0, \"reason\": \"Failed to parse JSON\"}  # Default to lowest score if parsing fails\n",
    "\n",
    "# Initialize evaluator\n",
    "essay_evaluator = EssayEvaluator()\n",
    "\n",
    "# Run evaluation\n",
    "asyncio.run(evaluation.evaluate(essay_evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment between human and LLM evaluator: 0.444\n"
     ]
    }
   ],
   "source": [
    "eval_df = get_evaluation_predictions(\"0192d298-dd9c-74c1-9afc-f3a422da996e\")\n",
    "kappa = calculate_cohen_kappa(eval_df, labels=list(range(1,7)))\n",
    "print(f\"Alignment between human and LLM evaluator: {kappa:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Add few-shot examples\n",
    "\n",
    "Adding few-show examples can help the LLM evaluator understand the task better. It can help guide the LLM towards the correct answer. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>86f807f</td>\n",
       "      <td>In \"The Challeneges of Exploring Venus\", the a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16078</th>\n",
       "      <td>ecfadac</td>\n",
       "      <td>The concept of aliens is a topic that some of ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11065</th>\n",
       "      <td>a346bdd</td>\n",
       "      <td>Driverless cars are a thing of the future.\\n\\n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16721</th>\n",
       "      <td>f6932e7</td>\n",
       "      <td>I believe there is life on mars. I believe the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11785</th>\n",
       "      <td>ad0a779</td>\n",
       "      <td>I beleive that the development of self driving...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "9139   86f807f  In \"The Challeneges of Exploring Venus\", the a...      6\n",
       "16078  ecfadac  The concept of aliens is a topic that some of ...      6\n",
       "11065  a346bdd  Driverless cars are a thing of the future.\\n\\n...      3\n",
       "16721  f6932e7  I believe there is life on mars. I believe the...      1\n",
       "11785  ad0a779  I beleive that the development of self driving...      3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/essay_scorer_full.csv\")\n",
    "\n",
    "# Get essays that are only in train set\n",
    "train_only = train_df[~train_df[\"essay_id\"].isin(test_df[\"essay_id\"])]\n",
    "\n",
    "# Sample examples\n",
    "score_6_examples = train_only[train_only[\"score\"] == 6].sample(n=2, random_state=42)\n",
    "other_scores = train_only[train_only[\"score\"] != 6].sample(n=3, random_state=42)\n",
    "\n",
    "# Combine examples\n",
    "few_shot_examples = pd.concat([score_6_examples, other_scores])\n",
    "few_shot_examples.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot examples:\n",
      "In \"The Challeneges of Exploring Venus\", the author claims that the obstacles that stand on the way of studying Venus should not be the reason why scientists don't explore it. The author is not consistent throughout the article and does not present solid information or evidence that convinces the reader that exploring Venus is worth risking lives.\n",
      "\n",
      "The author begins the article by comparing Venus to Earth and says that both of them are similar both in density and in size, but then moves on to stating that \"not a single spaceship has touched down on Venus in more than three decadaes\" (paragraph 2). After that statement the author lists all of the dangers that would come with exploring Venus: \"A thick atmosphere of almost 97 percent carbon dioxide blankets Venus. Even more challenging are the clouds of highly corrosive sulfuric acid in Venuss atmosphere. On the planets surface, temperatures average over 800 degrees Fahrenheit, and the atmospheric pressure is 90 times greater than what we experience on our own planet\" (paragraph 3). By that point the author has made clear that Venus is incredibly dangerous and that studying it means sending researchers to an highly risky zone, and may result in devastating failure.\n",
      "\n",
      "The contraditiction begins as soon as the author begins to explain the reasoning behind even considering visits to the planet's surface. By that point, the author was using real data and solid information to explain the dangers of the planet's surface, however, as soon as the author started reasoning on why the expedition should happen, his arguments were not as solid and were based on assumptions: \"It may well once have been the most Earth-like planet in our solar system. Long ago, Venus was probably covered largely with oceans and could have supported various forms of life, just like Earth\"(paragraph 4). The use of terms such as \"it may well once have been\" or \"was probably\" do not give the reader the confidence that they need to believe in the author's claims, that is based on \"probably\" and \"most likely\" expressions.\n",
      "\n",
      "By the end of paragraph 6 the author even writes about his own contradiction: \"Venus would need to get up close and personal despite the risks. Or maybe we should think of them as challenges.\" Such passage shows the reader that even the writer doesn't seem to believe in this mission and that the author needs to keep telling himself that the risks of sending someone to Venus are, in reality, simply \"challenges\" that need to be overcome. After explaining NASA's work on other approaches to studying Venus, the author actually refers to Venus's surface as chaos, and then concludes the article by claiming that \"Our travels on Earth and beyond should not be limited by dangers and doubts but should be expanded to meet the very edges of imagination and innovation\" (paragraph 8), a claim that contradicts previous statements made by the author himself.\n",
      "\n",
      "In conclusion, the author contradicts himself a series of times and does not present nearly enough evidence to support his main claim. By using expression such as \"was probably\" to explain the history of Venus and why NASA should explore it, the author creates a statement based on assumptions and not based on real data. Claims that Venus is a very challenging place to examine closely are consistent throughout the article and the author never discredits them, on the contrary, he reinforces them. With that being said, the author is not consistent and does not make valid claims or statements that make the reader feel the need to support explorations and studies on Venus.\n",
      "\n",
      "{\"score\": 6, \"reason\": \"This essay demonstrates excellent writing quality.\"}\n",
      "\n",
      "The concept of aliens is a topic that some of us believe and some of us do not. Whether it has to do with how aliens may have affected how Earth was created or that there are other living organisms on planets other than Earth. Most scientists have used reasonable research to discover that aliens are not real, but yet there are still some scientists that believe they are in fact real. Based on the photos taken of the Face, aliens did not create this structure, it is simply just a natural landform.\n",
      "\n",
      "In 1976, NASA's Viking 1 spacecraft visited Mars and discovered the Face while snatching photos for landing areas for the Viking 2 ship. It looked as though it was the shape of a head, which is why it is known as the Face. This formation was gigantic, measuring almost two miles across. Something so giant couldn't have been formed from aliens, especially if it resembles a head, symbolizing that it may be an imprint of an actual alien. As they studied the photos of the Face, they began to realize how similar its features were to those of a human's face, or this case, what could be an alien. These facial features were then recognized to be just shadows, which adds to the fact that the imprint of a human, or alien face, could not have been formed. A formation this large cannot resemble that of a human, nethertheless an alien.\n",
      "\n",
      "For twenty-five years, \"The Face of Mars\" was a famous attraction, attracting many people to be interested and cause an even broader range of thoughts about how this landform was created. As more people become engaged in this unusual formation, NASA continued to snap photos of the Face to uncover more information about what it really was and how it was really created. Later on, Michael Malin and his Mars Orbiter Camera team took one more picture that had ten times the resolution that the orginal Viking images had. When this picture was viewed by many on a web site, it then revealed that it was, indeed, a natural landform and there was no evidence of aliens, as many people thought. Information from the several images that were taken establish that this structure is a natural landform, and not a creation from aliens.\n",
      "\n",
      "Even though images proved that the Face was a natural landform and not something created by aliens, there still remained people who didn't believe this concept. At the time the most recent photo was taken, it was winter on the planet, and the Face on Mars was located in an area that consisted of a cloudy region. Those who still believed that aliens created the Face also believed that this area of clouds could have affected the picture that was taken during that time. The scientists claimed that it isn't an easy task to find the Face and capture a decent picture of it when possible, but still yearned to capture another shot to prove that aliens had not created it. So, on a summer day that consisted of no clouds, the team captured another photo with the maximum resolution. Because of the outstanding resoluation of the photo, it then again proved that it was simply anatural landform and that aliens did not play a part in it's creation.\n",
      "\n",
      "Throughout the journey of discovering whether this creation was formed by aliens or that it was a natural landform the scientists and photos taken proved that there were no aliens. Although somemay still believe that there were aliens, these photos demonstrate real evidence that there was not. Like the scientists said, it was very similar to a landform on Earth, that is created naturally. Because of this discovery of the Face, scientists have been given the chance to explore the realmsof creations on other planets and prove that they cannot be formed by aliens, but simply by the natural occurences that take place on that planet.                \n",
      "\n",
      "{\"score\": 6, \"reason\": \"This essay demonstrates excellent writing quality.\"}\n",
      "\n",
      "Driverless cars are a thing of the future.\n",
      "\n",
      "With as many companies working towards driverless cars: Google, Toyota, BMW, GM, Mercedes-Benz, Audi, and Nissan, I think we'll have streets full of the in no time.\n",
      "\n",
      "I think driverless cars are a fantastic idea.\n",
      "\n",
      "Humans have flaws, and machines do too, but if we could manufacture a car smart enough to know how to navigate in traffic on its own, and when and where to stop a humans flaws would not be an issue.\n",
      "\n",
      "We have too many distractions in our lives, and needless to say we're thinking about those things while we're driving.\n",
      "\n",
      "\"The information from the sensors can cause the car to apply brakes on individual wheels and reduce power from the engine, allowing far better response and control than a human driver could manage alone. Further improvements in sensors and computer hardware and software to make driving safer are also leading to cars that can handle more and more driving tasks on their own.\" -paragraph 5.\n",
      "\n",
      "This indicates that driverless cars are safer than manual ones, and that they use less energy.\n",
      "\n",
      "With cars as sensitive as these, there would be fewer accidents as well.\n",
      "\n",
      "There are a few issues with the case: \"If the technology fails and someone is injured, who is at faultthe driver or the manufacturer?\" -paragraph 9.\n",
      "\n",
      "On the other hand, by the time driverless cars are on the streets we should have most legal issues worked out.\n",
      "\n",
      "All in all, I think self-driving cars are safer than manual ones.\n",
      "\n",
      "With as many distractions as we have in our lives, we really do not need another thing to be worrying about.\n",
      "\n",
      "{\"score\": 3, \"reason\": \"This essay demonstrates moderate writing quality.\"}\n",
      "\n",
      "I believe there is life on mars. I believe there is life on mars because of the photos because of the talk around town. On May 24,2001 NASA sent Viking 1 in to outer space but what it found were still trying to figure out could there be life on Mars. The Viking sent back pictures of mars carved into it was a illusion of eyes nose and mouth so let me say again can there be life not just on earth but on Mars the question is still to be answerd. NASA says the have witness alot of things up that we dont know or could even imagin there could be life on every plant and if there is I know we all want to witness it one day. I know I am not the only one who would want to explore through out the box through out the earth but may I say the question is still out there for me for you for the future. So let that be known that you and me and what ever is out there are alike curious to seek and craving for advanture. You and me both will fly out of here hand by hand sister to brother to find whats on mars in the future qustion that is waiting to be answerd will be seen head smelled by the ones who are seeking that adventure to answer that qustion that we all what to know. Is there life on mars.                                             \n",
      "\n",
      "{\"score\": 1, \"reason\": \"This essay demonstrates poor writing quality.\"}\n",
      "\n",
      "I beleive that the development of self driving cars would better our future. The introduction of self driving cars is a positive because they give the driver more freedom to do other productive things, they still give the driver some control over the car incase bad condition come up, and they use many different sensors to ensure the passengers safety.\n",
      "\n",
      "Self driving cars give people the freedom to do more productive things instead of driving. This is helpful because people could get more work done in the car. Which in some cases people can commute many hours, giving them valuable time to work. A concern with this could be distracting the driver from being alert incase the car needs assistance. Although as stated in the article \"Some manufacturers hope to do that by bringing in-car entertainment and information systems that use heads-up display. Such displays can be turned off instantly when the driver needs to take over\". This means that drivers could use the systems already put in the cars that are regulated by the car itself so that if there is an emergency, the car can shut down the devices.\n",
      "\n",
      "The cars are smart enough to know when they should let the passeneger take over. This is important because it shows you that the cars still give you control in certain situations, and they only drive in conditions that would otherwise be easy. Stated in the article, it says \"In 2013, BMW announced the development of \"Traffic Jam Assistant\". Th car can handle driving functions at speeds of up to 25 mph, but special touch sensors make sure the driver keeps hold of the wheel. In fact, none of the cars developed so far are completely driverless\". This means that if the car starts to lose control or go into bad conditions, the passenger can take over.\n",
      "\n",
      "The cars that are modified to be self driven are highly equipped with technology to help the car. Stated in the article \"Google's modified Toyota Prius uses position-estimating sensors on the left rear wheel, a rotating sensor on the roof, a video camera mounted near the rearview mirror, four automotive radar sensors, a GPS reciever, and a inertial motion sensor... The most important bit of technology in this system is the spinning sensor on the roof. Dubbed LIDAR, it uses laser beams to form a constantly updating 3-D model of the cars surroundings\" These sensors all make the car have the important information to make decisions just like a human would when behind the wheel.\n",
      "\n",
      "I think that self driving cars would be a positive because they give the driver free time to be productive, they still give the driver control in certain situations, and they use many sensors to ensure the safety of the passengers. \n",
      "\n",
      "{\"score\": 3, \"reason\": \"This essay demonstrates moderate writing quality.\"}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create few-shot prompt\n",
    "few_shot_prompt = \"\"\n",
    "\n",
    "for _, row in few_shot_examples.iterrows():\n",
    "    few_shot_prompt += f\"\"\"{row['full_text']}\n",
    "\n",
    "{{\"score\": {row['score']}, \"reason\": \"This essay demonstrates {'excellent' if row['score'] == 6 else 'moderate' if row['score'] >= 3 else 'poor'} writing quality.\"}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"Few-shot examples:\")\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
