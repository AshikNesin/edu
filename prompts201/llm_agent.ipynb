{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LLM Agents: A Tutorial\n",
    "\n",
    "Welcome to this tutorial on building LLM agents. In this tutorial, we will use W&B Prompts to monitor and debug our experiments. This agent will be a great tool to help us prepare for machine learning interviews.\n",
    "\n",
    "Our agent will be using OpenAI GPT 3.5 LLM, so we need to provide it with OpenAI API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter password in the VS Code prompt at the top of your VS Code window!\n",
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "import openai\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking and debugging with W&B\n",
    "\n",
    "Let's be honest - LLM agents can be very brittle! We'll use W&B to trace agent execution chains, track our experiments and debug errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc619ebdb1fc46879275f0571bb065c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0167526506999972, max=1.0))â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/darek/Projects/prompts-tutorial/wandb/run-20230914_134137-e7cr68xl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/darek-kleczek/llm-agent/runs/e7cr68xl' target=\"_blank\">happy-resonance-2</a></strong> to <a href='https://wandb.ai/darek-kleczek/llm-agent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/darek-kleczek/llm-agent' target=\"_blank\">https://wandb.ai/darek-kleczek/llm-agent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/darek-kleczek/llm-agent/runs/e7cr68xl' target=\"_blank\">https://wandb.ai/darek-kleczek/llm-agent/runs/e7cr68xl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/darek-kleczek/llm-agent/runs/e7cr68xl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1543920d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"llm-agent\")\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "\n",
    "To make our life easier, we'll use Langchain agent implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Tools\n",
    "\n",
    "To give our agent some agency, let's define a tool that will track the user status for us. It will accept a recap of user message, retrieve previous summary from file, and update it using an LLM. This is a very naive implementation, but our goal is to learn about agents, so let's not worry about that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserStatusSummaryTool(BaseTool):\n",
    "    name = \"user_status_summary\"\n",
    "    description = \"Input a summary of the users' message. Return an updated summary of the user's status.\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        # Read a previous user summary from a local text file\n",
    "        with open('user_summary.txt', 'r') as file:\n",
    "            previous_summary = file.read()\n",
    "        \n",
    "        # Concatenate it in a prompt with the recap\n",
    "        prompt = \\\n",
    "f\"\"\"Please update the user summary based on the new information.\\n\n",
    "Previous summary: \\n\n",
    "{previous_summary}\\n\n",
    "{query}\\n\n",
    "Updated summary: \\n\"\"\"\n",
    "\n",
    "        # LLM to update the summary\n",
    "        llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\"You're a concise writer that summarizes user status in the shortest way possible, without missing relevant details.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=prompt\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        # Pass the prompt to OpenAI LLM to get an updated summary\n",
    "        response = llm(messages)\n",
    "        \n",
    "        # Save the updated summary back to the same text file\n",
    "        with open('user_summary.txt', 'w') as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "        return response.content\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"pick_world does not support async\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if the tool works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advanced MLE with specific interest in NLP. No new information available.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recap = \"user is a advanced MLE interested in NLP\"\n",
    "tool = UserStatusSummaryTool()\n",
    "tool.run(recap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "Now we'll initialize a zero shot agent with OpenAI LLM and our `user_status_summary` tool. The agent should figure out what to do given a user message, and understanding user status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)\n",
    "tools = [UserStatusSummaryTool()]\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Prompt Template\n",
    "\n",
    "Remember our tutorial about Prompt Engineering? If you check out the basic agent prompt template, it's very modest, so we'll update it based on our prompt engineering experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "user_status_summary: Input a summary of the users' message. Return an updated summary of the user's status.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [user_status_summary]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI tutor helping students prepare for machine learning coding interviews.\n",
    "Your goal is understand the user needs, and to come up with learning assignments that will help students pass interviews. Specifically:\n",
    "- Prompt students to solve a task that involves a simple machine learning concept and a coding exercise\n",
    "- The task should be possible to solve in 30 minutes using a simple algorithm in Python\n",
    "- The instruction should be minimal. Don't provide hints at this stage. \n",
    "- The task should be solvable by a student who has taken a machine learning course and has some coding experience\n",
    "- The task should be interesting and fun to solve\n",
    "- The task should advance the student's knowledge of machine learning\n",
    "\n",
    "Example tasks by level:\n",
    "- Beginner: calculate probability of 3 heads in 5 coin flips, count the number of times a word appears in a text\n",
    "- Intermediate: implement a single neuron in Python, implement a simple decision tree in Python\n",
    "- Advanced: implement backpropagation of a simple MLP in Python, implement a simple CNN in Python\n",
    "\n",
    "You'll be evaluated on:\n",
    "- your ability to summarize the user's status\n",
    "- properly using the tools and passing appropriate inputs\n",
    "- conciseness of the task description\n",
    "- clarity of the task description\n",
    "- creativity of the task\n",
    "- matching the task to the student's level\n",
    "- learning value of the task\n",
    "\n",
    "You have access to the following tools:\n",
    "user_status_summary: summarize the user status based on the agent's learning. Action input: recap of user message.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the message you get from a user\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [user_status_summary]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the task to suggest to a user\n",
    "Final Answer: the final response consisting of a task or suggestion for the user\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "agent.agent.llm_chain.prompt.template = system_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the agent\n",
    "\n",
    "Now we can pass user messages to the agent and see how it uses the tools and responds. Make sure to check out the traces in W&B!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should ask the user for more information to understand their level and provide an appropriate assignment.\n",
      "Action: user_status_summary\n",
      "Action Input: Hi, can you give me an assignment? I'm just getting started.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mUser is a beginner and requesting an assignment.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user is a beginner and requesting an assignment. I should provide a simple task that introduces a basic machine learning concept and can be solved in 30 minutes using a simple algorithm in Python.\n",
      "\n",
      "Final Answer: Sure! Here's an assignment for you: calculate the probability of getting 3 heads in 5 coin flips. You can use a simple algorithm in Python to solve this. Good luck!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's an assignment for you: calculate the probability of getting 3 heads in 5 coin flips. You can use a simple algorithm in Python to solve this. Good luck!\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"Hi, can you give me an assignment? I'm just getting started.\"\n",
    "agent.run(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should suggest a task related to NLP for this user who is interested in NLP problems. I can start with a beginner-level task that involves counting the number of times a word appears in a text. This task will help the user practice basic string manipulation and counting techniques in Python, which are fundamental skills in NLP.\n",
      "Action: user_status_summary\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mUser is a beginner in NLP and has requested an assignment. No new information is available.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user is a beginner in NLP and is interested in NLP problems. I should suggest a task related to NLP that is suitable for beginners. \n",
      "\n",
      "Final Answer: Sure! Here's a task for you: Write a Python function that takes in a text string and a word, and returns the number of times the word appears in the text. This task will help you practice basic string manipulation and counting techniques in Python, which are fundamental skills in NLP. Let me know if you have any questions or need further guidance!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a task for you: Write a Python function that takes in a text string and a word, and returns the number of times the word appears in the text. This task will help you practice basic string manipulation and counting techniques in Python, which are fundamental skills in NLP. Let me know if you have any questions or need further guidance!\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"I'm actually interested in NLP problems\"\n",
    "agent.run(user_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finish our experimentation here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca863d9d91274250806e7a97e3a04d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-resonance-2</strong> at: <a href='https://wandb.ai/darek-kleczek/llm-agent/runs/e7cr68xl' target=\"_blank\">https://wandb.ai/darek-kleczek/llm-agent/runs/e7cr68xl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230914_134137-e7cr68xl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, we developed a simple LLM agent using Langchain. The agent uses a tool to store user status and builds on our previous prompt engineeering experiments to recommend AI assignments to students. We've also shown how to use W&B Tracer to monitor and debug LLM Agents!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
